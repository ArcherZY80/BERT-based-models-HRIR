{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "transformer_tss.ipynb（副本）",
      "provenance": [],
      "collapsed_sections": [
        "gW34gr1AC24p",
        "4EFStMG-C_VK",
        "778IHpqiucan",
        "3_4-GQLyNlKF",
        "dX57L4kV45Ws",
        "RaznU02IDUOE",
        "9NznGR6uuecY",
        "HJ16y1t2SMwU",
        "ugENBLMrEHoi",
        "LFdPun0rDLgm",
        "H9OWeTn4DWOs",
        "Jpl2BgcHug76",
        "B6nIoYBiSRH_",
        "pF-XbWBGSUUj"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f337e4649d7f4113900a1d4531adea18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_25c195e8a34d4ddda720b50d2ff6412b",
              "IPY_MODEL_3f0c7b09e2884ac2913f8088c6bcede7",
              "IPY_MODEL_b8504da6b672465cbc10c6660cde41fa"
            ],
            "layout": "IPY_MODEL_7c88779c39d6499781f9dc8658adf618"
          }
        },
        "25c195e8a34d4ddda720b50d2ff6412b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_941bde71701a44e28f2ad2ddd7977c04",
            "placeholder": "​",
            "style": "IPY_MODEL_7821939494bf40cb9aa219d49e68d3bc",
            "value": "Downloading: 100%"
          }
        },
        "3f0c7b09e2884ac2913f8088c6bcede7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b767a77ed8b545b5ac8a81c297533c43",
            "max": 227845,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_829312ba828944ac98dcfbd177991447",
            "value": 227845
          }
        },
        "b8504da6b672465cbc10c6660cde41fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf1877ccf3264f85992271fad3df9c2c",
            "placeholder": "​",
            "style": "IPY_MODEL_f034ff6c1b9649f48c96b0ee0fcdc978",
            "value": " 223k/223k [00:00&lt;00:00, 673kB/s]"
          }
        },
        "7c88779c39d6499781f9dc8658adf618": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "941bde71701a44e28f2ad2ddd7977c04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7821939494bf40cb9aa219d49e68d3bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b767a77ed8b545b5ac8a81c297533c43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "829312ba828944ac98dcfbd177991447": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bf1877ccf3264f85992271fad3df9c2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f034ff6c1b9649f48c96b0ee0fcdc978": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "463153055cbc4c55930865f1543a9865": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_839c22e76a834864b65719b2270e23c1",
              "IPY_MODEL_467b413d3e6b4d4d9f31fc99747cd8ec",
              "IPY_MODEL_da0c5b6e21a4468fbd6e1fc1a1e0e867"
            ],
            "layout": "IPY_MODEL_3b942eda89dc43ea8c223db10d3db0fb"
          }
        },
        "839c22e76a834864b65719b2270e23c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7894643ae3d41bea4a670f6967eb328",
            "placeholder": "​",
            "style": "IPY_MODEL_1a07bc06f9be4b7083d8596528f5b56a",
            "value": "Downloading: 100%"
          }
        },
        "467b413d3e6b4d4d9f31fc99747cd8ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b12c1b83bd34189a350f07fcc2a4401",
            "max": 385,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d2e6e026e9be4f0fb5255855c8326bf8",
            "value": 385
          }
        },
        "da0c5b6e21a4468fbd6e1fc1a1e0e867": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_005708287db74219bba3194b6ca5c387",
            "placeholder": "​",
            "style": "IPY_MODEL_fa786c361ba1415e867e67aa3eb817e6",
            "value": " 385/385 [00:00&lt;00:00, 8.39kB/s]"
          }
        },
        "3b942eda89dc43ea8c223db10d3db0fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7894643ae3d41bea4a670f6967eb328": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a07bc06f9be4b7083d8596528f5b56a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2b12c1b83bd34189a350f07fcc2a4401": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2e6e026e9be4f0fb5255855c8326bf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "005708287db74219bba3194b6ca5c387": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa786c361ba1415e867e67aa3eb817e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "53c3280d17e243eba6de8225dadb6b1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_18431646f88a450cb2f019446e9f4c49",
              "IPY_MODEL_8bd90f56f9c340b2aef525a0244308ac",
              "IPY_MODEL_b72ea18364c24de1b407737454a8b688"
            ],
            "layout": "IPY_MODEL_dc567aeda57545c493d9201660a1006b"
          }
        },
        "18431646f88a450cb2f019446e9f4c49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd5d089ebcf44415b507fad286ea0dd7",
            "placeholder": "​",
            "style": "IPY_MODEL_8c499ed674694fa8ba26ab101915e96d",
            "value": "Downloading: 100%"
          }
        },
        "8bd90f56f9c340b2aef525a0244308ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8236514d1dbe4ac89215ab44ada82ab8",
            "max": 442221694,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_293baec9016c41cd99f3c5280f7387e8",
            "value": 442221694
          }
        },
        "b72ea18364c24de1b407737454a8b688": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85d0b4a61f094219bc16e56ff5941f44",
            "placeholder": "​",
            "style": "IPY_MODEL_3f31bfc8a92740fb8810f3768a19e718",
            "value": " 422M/422M [00:14&lt;00:00, 41.0MB/s]"
          }
        },
        "dc567aeda57545c493d9201660a1006b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd5d089ebcf44415b507fad286ea0dd7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c499ed674694fa8ba26ab101915e96d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8236514d1dbe4ac89215ab44ada82ab8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "293baec9016c41cd99f3c5280f7387e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "85d0b4a61f094219bc16e56ff5941f44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f31bfc8a92740fb8810f3768a19e718": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e17f9c04c4214d278a5e0d28bbc8b6c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1dbb1745be4b4bc9ac2e9af7c7fedb36",
              "IPY_MODEL_3c5589109161491bbac6e76819e83e37",
              "IPY_MODEL_1adcae19bdef4c94a3ca3d196152c598"
            ],
            "layout": "IPY_MODEL_6f2b91fc66c342f2b3d0dcb68c3e37fa"
          }
        },
        "1dbb1745be4b4bc9ac2e9af7c7fedb36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45c66780e0074209b470b8a941387007",
            "placeholder": "​",
            "style": "IPY_MODEL_c193ae916c034865946883a37a495e5f",
            "value": "Downloading: 100%"
          }
        },
        "3c5589109161491bbac6e76819e83e37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83edaffae99448ed8a06e50ba55e3878",
            "max": 227845,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_328a7138093f45e9867aa811af9e105c",
            "value": 227845
          }
        },
        "1adcae19bdef4c94a3ca3d196152c598": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dcd520cb21504bcbb0d5a9c714b82a13",
            "placeholder": "​",
            "style": "IPY_MODEL_f82ec87bcc704b89a664c7a66eca9410",
            "value": " 223k/223k [00:00&lt;00:00, 247kB/s]"
          }
        },
        "6f2b91fc66c342f2b3d0dcb68c3e37fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45c66780e0074209b470b8a941387007": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c193ae916c034865946883a37a495e5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "83edaffae99448ed8a06e50ba55e3878": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "328a7138093f45e9867aa811af9e105c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dcd520cb21504bcbb0d5a9c714b82a13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f82ec87bcc704b89a664c7a66eca9410": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "28fcf8cb8a2f4dd9898f428d21d0a05c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_74f399b4a18b4590a8ec903cb7f75814",
              "IPY_MODEL_132c54db44eb4c908367869419528d2b",
              "IPY_MODEL_6e430d1e1f4b4cb099a57e8f8b1d8aab"
            ],
            "layout": "IPY_MODEL_ba0235cb184f4c0caa9da5f1b402b722"
          }
        },
        "74f399b4a18b4590a8ec903cb7f75814": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06a560680f1640d3bc0521a5fd67a0fb",
            "placeholder": "​",
            "style": "IPY_MODEL_ceb8055f6ac94d0e937736f71a1fa403",
            "value": "Downloading: 100%"
          }
        },
        "132c54db44eb4c908367869419528d2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_965c7dde61ae4f70bceb14baa4938802",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_50704384983044ff93374323c8234fc3",
            "value": 112
          }
        },
        "6e430d1e1f4b4cb099a57e8f8b1d8aab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19db577511d64542af73cdcca1a3edb3",
            "placeholder": "​",
            "style": "IPY_MODEL_88daadf30f5d4e0eb3c27adfddb2a94e",
            "value": " 112/112 [00:00&lt;00:00, 1.82kB/s]"
          }
        },
        "ba0235cb184f4c0caa9da5f1b402b722": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06a560680f1640d3bc0521a5fd67a0fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ceb8055f6ac94d0e937736f71a1fa403": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "965c7dde61ae4f70bceb14baa4938802": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50704384983044ff93374323c8234fc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "19db577511d64542af73cdcca1a3edb3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88daadf30f5d4e0eb3c27adfddb2a94e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e480b59ea283402497506a82a39e3006": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_04246ed25bb34cbfa452c33d674cdd44",
              "IPY_MODEL_dd9af9d55ac2426fa40571d8db43339c",
              "IPY_MODEL_0ca32f91a4864fb9b701d24dbc08495f"
            ],
            "layout": "IPY_MODEL_9572e2df63a3482f8c92a02b458c447f"
          }
        },
        "04246ed25bb34cbfa452c33d674cdd44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_816ba8bf81b546a99c95ca1d394d5fa5",
            "placeholder": "​",
            "style": "IPY_MODEL_9ed7e9c1b39f47a0bffedbaf6b05333c",
            "value": "Downloading: 100%"
          }
        },
        "dd9af9d55ac2426fa40571d8db43339c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77151d9618b2411898637a4388d98787",
            "max": 323,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_657d956f82994008889195b80d31c114",
            "value": 323
          }
        },
        "0ca32f91a4864fb9b701d24dbc08495f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76d8a6608b68415592f64d1d696d4aad",
            "placeholder": "​",
            "style": "IPY_MODEL_f5f52d94826f444cba68f90c4ab8b7b9",
            "value": " 323/323 [00:00&lt;00:00, 7.05kB/s]"
          }
        },
        "9572e2df63a3482f8c92a02b458c447f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "816ba8bf81b546a99c95ca1d394d5fa5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ed7e9c1b39f47a0bffedbaf6b05333c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "77151d9618b2411898637a4388d98787": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "657d956f82994008889195b80d31c114": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "76d8a6608b68415592f64d1d696d4aad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5f52d94826f444cba68f90c4ab8b7b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a2bd55b6013f4f85a3c1ed95bc1d5fd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fb6e56a3cebe4deb85d67044dcb2959c",
              "IPY_MODEL_66138112381f4de9a847b6e7878a0f49",
              "IPY_MODEL_74ae514f022c4f94bd1a22a6f9292635"
            ],
            "layout": "IPY_MODEL_52b82e0003434c59966af74d97401b5f"
          }
        },
        "fb6e56a3cebe4deb85d67044dcb2959c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8cfefe741fb48f987fe44fe26fe573c",
            "placeholder": "​",
            "style": "IPY_MODEL_e47e166d420040ae974d3f8b1721b3a3",
            "value": "Downloading: 100%"
          }
        },
        "66138112381f4de9a847b6e7878a0f49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b28331e3fb5492d839d74a3ed8a1a67",
            "max": 620,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_850c63eac8a3427ca995e82b49076607",
            "value": 620
          }
        },
        "74ae514f022c4f94bd1a22a6f9292635": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb27f6de0a43482786657c8b9b63dedf",
            "placeholder": "​",
            "style": "IPY_MODEL_1d03a76c5bec4d2bbf649e00e7692376",
            "value": " 620/620 [00:00&lt;00:00, 7.26kB/s]"
          }
        },
        "52b82e0003434c59966af74d97401b5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8cfefe741fb48f987fe44fe26fe573c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e47e166d420040ae974d3f8b1721b3a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7b28331e3fb5492d839d74a3ed8a1a67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "850c63eac8a3427ca995e82b49076607": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fb27f6de0a43482786657c8b9b63dedf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d03a76c5bec4d2bbf649e00e7692376": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "62fad4e7caac4453aa119cd114e7b784": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0832e5ea4dc54ef394b45288c6db1ba3",
              "IPY_MODEL_c2697a5e97284badbcafe4069847a1a2",
              "IPY_MODEL_0be0bd300a414181858d4c21830f3664"
            ],
            "layout": "IPY_MODEL_43b507f676b14029a4352a695bf0d430"
          }
        },
        "0832e5ea4dc54ef394b45288c6db1ba3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1fb7fe081a974e8dafb8be54e655b4ce",
            "placeholder": "​",
            "style": "IPY_MODEL_9171815e2e2346f68692c4fe0c80b228",
            "value": "Downloading: 100%"
          }
        },
        "c2697a5e97284badbcafe4069847a1a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef912d9656604cc6bcb446d3e9712bfc",
            "max": 439894482,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_81a5e9ade7de4de18acc8a67d310963c",
            "value": 439894482
          }
        },
        "0be0bd300a414181858d4c21830f3664": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da086a4188b74a04bb3416f31d26d55c",
            "placeholder": "​",
            "style": "IPY_MODEL_e4e2d6dff939431ca35a20853e103d0d",
            "value": " 420M/420M [00:22&lt;00:00, 22.4MB/s]"
          }
        },
        "43b507f676b14029a4352a695bf0d430": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fb7fe081a974e8dafb8be54e655b4ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9171815e2e2346f68692c4fe0c80b228": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ef912d9656604cc6bcb446d3e9712bfc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81a5e9ade7de4de18acc8a67d310963c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "da086a4188b74a04bb3416f31d26d55c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4e2d6dff939431ca35a20853e103d0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Import"
      ],
      "metadata": {
        "id": "gW34gr1AC24p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eN0PVKZDLSuy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c93d13b-5f65-4de3-cc32-5101811853f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.17.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 8.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.2)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 3.9 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 59.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 41.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Collecting tokenizers!=0.11.3,>=0.11.1\n",
            "  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.5 MB 39.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.49 tokenizers-0.11.6 transformers-4.17.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import logging\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "transformers_logger = logging.getLogger(\"transformers\")\n",
        "transformers_logger.setLevel(logging.WARNING)"
      ],
      "metadata": {
        "id": "cdaE_5fyC6Lj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!/opt/bin/nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpBIvX3fC8Ou",
        "outputId": "00884b7a-d936-4bdd-f687-b9912eca739c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Mar 16 14:17:49 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "import torch\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from transformers import EarlyStoppingCallback"
      ],
      "metadata": {
        "id": "Jhk5tAz2DO7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#read dataset"
      ],
      "metadata": {
        "id": "4EFStMG-C_VK"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8db6960c-a135-4978-e820-0f01547644f1",
        "id": "oKZTJuEnqphe"
      },
      "source": [
        "\n",
        "train_df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/project/4192/Data/DirectCompare/train_df.csv\")\n",
        "\n",
        "train_df = train_df[['selftext','Expert-label']]\n",
        "train_df[['Expert-label']] = train_df[['Expert-label']].astype(int)\n",
        "train_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               selftext  Expert-label\n",
              "0     I posted this on Piazza but thought I might as...             1\n",
              "1     Hi i’ve applied for arts from Vancouver,BC as ...             0\n",
              "2     i'm an international student and i've been tak...             1\n",
              "3     i'm an international student and the midterm w...             1\n",
              "4     they think i wouldnt be able to handle the str...             0\n",
              "...                                                 ...           ...\n",
              "997   My boyfriend is Canadian and I’m American. Obv...             0\n",
              "998   Do you need to be vaccinated to travel domesti...             0\n",
              "999   Hello, are there any International students he...             1\n",
              "1000  Will you guys take a leave of absence? Or are ...             0\n",
              "1001  I posted this on Piazza but thought I might as...             1\n",
              "\n",
              "[1002 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5e1bec79-405f-462d-b7d3-2e09937fb82f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>selftext</th>\n",
              "      <th>Expert-label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I posted this on Piazza but thought I might as...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hi i’ve applied for arts from Vancouver,BC as ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i'm an international student and i've been tak...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i'm an international student and the midterm w...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>they think i wouldnt be able to handle the str...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>My boyfriend is Canadian and I’m American. Obv...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>Do you need to be vaccinated to travel domesti...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>Hello, are there any International students he...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1000</th>\n",
              "      <td>Will you guys take a leave of absence? Or are ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1001</th>\n",
              "      <td>I posted this on Piazza but thought I might as...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1002 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5e1bec79-405f-462d-b7d3-2e09937fb82f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5e1bec79-405f-462d-b7d3-2e09937fb82f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5e1bec79-405f-462d-b7d3-2e09937fb82f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##train test split"
      ],
      "metadata": {
        "id": "TWg5DSUmEmVh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = train_df[\"selftext\"].values.tolist()\n",
        "y = train_df[\"Expert-label\"].values.tolist()\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)\n"
      ],
      "metadata": {
        "id": "H9brgjQ3DgRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##torch dataset"
      ],
      "metadata": {
        "id": "WzMZb4CvEkO3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels=None):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        if self.labels:\n",
        "            item[\"labels\"] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings[\"input_ids\"])\n",
        "\n"
      ],
      "metadata": {
        "id": "zB7XnQRPDrUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Metrics"
      ],
      "metadata": {
        "id": "gQfBpCsPDvkt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(p):\n",
        "    pred, labels = p\n",
        "    pred = np.argmax(pred, axis=1)\n",
        "\n",
        "    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n",
        "    recall = recall_score(y_true=labels, y_pred=pred)\n",
        "    precision = precision_score(y_true=labels, y_pred=pred)\n",
        "    f1 = f1_score(y_true=labels, y_pred=pred)\n",
        "\n",
        "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}"
      ],
      "metadata": {
        "id": "0ptdaWxZDxy7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Models"
      ],
      "metadata": {
        "id": "TkoA5HxpDFE5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##SciBERT"
      ],
      "metadata": {
        "id": "o3WR8yFJDR6k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"allenai/scibert_scivocab_uncased\"\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "model = BertForSequenceClassification.from_pretrained(model_name,num_labels =2 )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220,
          "referenced_widgets": [
            "f337e4649d7f4113900a1d4531adea18",
            "25c195e8a34d4ddda720b50d2ff6412b",
            "3f0c7b09e2884ac2913f8088c6bcede7",
            "b8504da6b672465cbc10c6660cde41fa",
            "7c88779c39d6499781f9dc8658adf618",
            "941bde71701a44e28f2ad2ddd7977c04",
            "7821939494bf40cb9aa219d49e68d3bc",
            "b767a77ed8b545b5ac8a81c297533c43",
            "829312ba828944ac98dcfbd177991447",
            "bf1877ccf3264f85992271fad3df9c2c",
            "f034ff6c1b9649f48c96b0ee0fcdc978",
            "463153055cbc4c55930865f1543a9865",
            "839c22e76a834864b65719b2270e23c1",
            "467b413d3e6b4d4d9f31fc99747cd8ec",
            "da0c5b6e21a4468fbd6e1fc1a1e0e867",
            "3b942eda89dc43ea8c223db10d3db0fb",
            "e7894643ae3d41bea4a670f6967eb328",
            "1a07bc06f9be4b7083d8596528f5b56a",
            "2b12c1b83bd34189a350f07fcc2a4401",
            "d2e6e026e9be4f0fb5255855c8326bf8",
            "005708287db74219bba3194b6ca5c387",
            "fa786c361ba1415e867e67aa3eb817e6",
            "53c3280d17e243eba6de8225dadb6b1a",
            "18431646f88a450cb2f019446e9f4c49",
            "8bd90f56f9c340b2aef525a0244308ac",
            "b72ea18364c24de1b407737454a8b688",
            "dc567aeda57545c493d9201660a1006b",
            "cd5d089ebcf44415b507fad286ea0dd7",
            "8c499ed674694fa8ba26ab101915e96d",
            "8236514d1dbe4ac89215ab44ada82ab8",
            "293baec9016c41cd99f3c5280f7387e8",
            "85d0b4a61f094219bc16e56ff5941f44",
            "3f31bfc8a92740fb8810f3768a19e718"
          ]
        },
        "id": "Pq1SwqHyDGo9",
        "outputId": "1d03c14e-d287-4922-c55c-817e7f9be9d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/223k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f337e4649d7f4113900a1d4531adea18"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/385 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "463153055cbc4c55930865f1543a9865"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/422M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "53c3280d17e243eba6de8225dadb6b1a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tokenized = tokenizer(X_train, padding=True, truncation=True, max_length=512)\n",
        "X_val_tokenized = tokenizer(X_val, padding=True, truncation=True, max_length=512)"
      ],
      "metadata": {
        "id": "m8kZyGElEeT8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = Dataset(X_train_tokenized, y_train)\n",
        "val_dataset = Dataset(X_val_tokenized, y_val)"
      ],
      "metadata": {
        "id": "SC5Lbit-EiNA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###epoch=3"
      ],
      "metadata": {
        "id": "778IHpqiucan"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "args = TrainingArguments(\n",
        "    output_dir=\"output\",\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=25,\n",
        "    per_device_train_batch_size=2,\n",
        "    per_device_eval_batch_size=2,\n",
        "    num_train_epochs=3,\n",
        "    seed=0,\n",
        "    load_best_model_at_end=True,\n",
        "    overwrite_output_dir=True,\n",
        "    learning_rate=3e-5,\n",
        "    gradient_accumulation_steps=16\n",
        ")"
      ],
      "metadata": {
        "id": "diReFCzPD2V_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_sci = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
        ")"
      ],
      "metadata": {
        "id": "Rirdn7NED3pM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_sci.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570
        },
        "id": "vBUe1O6sD47-",
        "outputId": "02ac5229-4473-4aea-9c3a-538826285435"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 801\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 2\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 16\n",
            "  Total optimization steps = 75\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='75' max='75' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [75/75 02:37, Epoch 2/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.641874</td>\n",
              "      <td>0.616915</td>\n",
              "      <td>0.569106</td>\n",
              "      <td>0.744681</td>\n",
              "      <td>0.645161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.611659</td>\n",
              "      <td>0.661692</td>\n",
              "      <td>0.616071</td>\n",
              "      <td>0.734043</td>\n",
              "      <td>0.669903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.598196</td>\n",
              "      <td>0.681592</td>\n",
              "      <td>0.633929</td>\n",
              "      <td>0.755319</td>\n",
              "      <td>0.689320</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=75, training_loss=0.6003725687662761, metrics={'train_runtime': 159.9043, 'train_samples_per_second': 15.028, 'train_steps_per_second': 0.469, 'total_flos': 631992754974720.0, 'train_loss': 0.6003725687662761, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###epoch=6"
      ],
      "metadata": {
        "id": "3_4-GQLyNlKF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "args = TrainingArguments(\n",
        "    output_dir=\"output\",\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=25,\n",
        "    per_device_train_batch_size=2,\n",
        "    per_device_eval_batch_size=2,\n",
        "    num_train_epochs=6,\n",
        "    seed=0,\n",
        "    load_best_model_at_end=True,\n",
        "    overwrite_output_dir=True,\n",
        "    learning_rate=3e-5,\n",
        "    gradient_accumulation_steps=16\n",
        ")"
      ],
      "metadata": {
        "id": "HT6GLeg0Nlea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eff84641-ca6f-41eb-ce2a-f9e1da677f9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_sci_6 = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
        ")"
      ],
      "metadata": {
        "id": "Kd6_9hYlNpJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_sci_6.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHWxM8OYNrxY",
        "outputId": "e61dced2-c791-40bc-ba3e-5138b6908c57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 801\n",
            "  Num Epochs = 6\n",
            "  Instantaneous batch size per device = 2\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 16\n",
            "  Total optimization steps = 150\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='150' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [150/150 05:19, Epoch 5/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.070263</td>\n",
              "      <td>0.716418</td>\n",
              "      <td>0.646552</td>\n",
              "      <td>0.824176</td>\n",
              "      <td>0.724638</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.180760</td>\n",
              "      <td>0.721393</td>\n",
              "      <td>0.654867</td>\n",
              "      <td>0.813187</td>\n",
              "      <td>0.725490</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.002043</td>\n",
              "      <td>0.711443</td>\n",
              "      <td>0.689655</td>\n",
              "      <td>0.659341</td>\n",
              "      <td>0.674157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.898822</td>\n",
              "      <td>0.751244</td>\n",
              "      <td>0.746988</td>\n",
              "      <td>0.681319</td>\n",
              "      <td>0.712644</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.221045</td>\n",
              "      <td>0.726368</td>\n",
              "      <td>0.655172</td>\n",
              "      <td>0.835165</td>\n",
              "      <td>0.734300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.206330</td>\n",
              "      <td>0.721393</td>\n",
              "      <td>0.652174</td>\n",
              "      <td>0.824176</td>\n",
              "      <td>0.728155</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=150, training_loss=0.046296250025431314, metrics={'train_runtime': 321.1983, 'train_samples_per_second': 14.963, 'train_steps_per_second': 0.467, 'total_flos': 1264248621004800.0, 'train_loss': 0.046296250025431314, 'epoch': 6.0})"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###epoch=9"
      ],
      "metadata": {
        "id": "dX57L4kV45Ws"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "args = TrainingArguments(\n",
        "    output_dir=\"output\",\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=25,\n",
        "    per_device_train_batch_size=2,\n",
        "    per_device_eval_batch_size=2,\n",
        "    num_train_epochs=9,\n",
        "    seed=0,\n",
        "    load_best_model_at_end=True,\n",
        "    overwrite_output_dir=True,\n",
        "    learning_rate=3e-5,\n",
        "    gradient_accumulation_steps=16\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OqDNEMa47DL",
        "outputId": "4b164ad9-2885-493a-d52c-afbcf7d904de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_sci_9 = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
        ")"
      ],
      "metadata": {
        "id": "565Ro1nJ492M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_sci_9.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4h6WUUz4_WR",
        "outputId": "1d177eb8-71d9-405e-ce91-b1fd955cec89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 801\n",
            "  Num Epochs = 9\n",
            "  Instantaneous batch size per device = 2\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 16\n",
            "  Total optimization steps = 225\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='225' max='225' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [225/225 07:59, Epoch 8/9]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.601378</td>\n",
              "      <td>0.621891</td>\n",
              "      <td>0.548387</td>\n",
              "      <td>0.934066</td>\n",
              "      <td>0.691057</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.804664</td>\n",
              "      <td>0.736318</td>\n",
              "      <td>0.697917</td>\n",
              "      <td>0.736264</td>\n",
              "      <td>0.716578</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.141430</td>\n",
              "      <td>0.731343</td>\n",
              "      <td>0.712644</td>\n",
              "      <td>0.681319</td>\n",
              "      <td>0.696629</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.926750</td>\n",
              "      <td>0.741294</td>\n",
              "      <td>0.705263</td>\n",
              "      <td>0.736264</td>\n",
              "      <td>0.720430</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.935593</td>\n",
              "      <td>0.731343</td>\n",
              "      <td>0.663717</td>\n",
              "      <td>0.824176</td>\n",
              "      <td>0.735294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.896723</td>\n",
              "      <td>0.731343</td>\n",
              "      <td>0.683168</td>\n",
              "      <td>0.758242</td>\n",
              "      <td>0.718750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>175</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.262177</td>\n",
              "      <td>0.716418</td>\n",
              "      <td>0.639344</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.732394</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.933741</td>\n",
              "      <td>0.746269</td>\n",
              "      <td>0.681818</td>\n",
              "      <td>0.824176</td>\n",
              "      <td>0.746269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>225</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.907876</td>\n",
              "      <td>0.721393</td>\n",
              "      <td>0.684211</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.698925</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=225, training_loss=0.037092408074273005, metrics={'train_runtime': 481.5907, 'train_samples_per_second': 14.969, 'train_steps_per_second': 0.467, 'total_flos': 1896504487034880.0, 'train_loss': 0.037092408074273005, 'epoch': 9.0})"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##PSY"
      ],
      "metadata": {
        "id": "RaznU02IDUOE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"nlp4good/psych-search\"\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "model = BertForSequenceClassification.from_pretrained(model_name,num_labels =2 )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283,
          "referenced_widgets": [
            "e17f9c04c4214d278a5e0d28bbc8b6c8",
            "1dbb1745be4b4bc9ac2e9af7c7fedb36",
            "3c5589109161491bbac6e76819e83e37",
            "1adcae19bdef4c94a3ca3d196152c598",
            "6f2b91fc66c342f2b3d0dcb68c3e37fa",
            "45c66780e0074209b470b8a941387007",
            "c193ae916c034865946883a37a495e5f",
            "83edaffae99448ed8a06e50ba55e3878",
            "328a7138093f45e9867aa811af9e105c",
            "dcd520cb21504bcbb0d5a9c714b82a13",
            "f82ec87bcc704b89a664c7a66eca9410",
            "28fcf8cb8a2f4dd9898f428d21d0a05c",
            "74f399b4a18b4590a8ec903cb7f75814",
            "132c54db44eb4c908367869419528d2b",
            "6e430d1e1f4b4cb099a57e8f8b1d8aab",
            "ba0235cb184f4c0caa9da5f1b402b722",
            "06a560680f1640d3bc0521a5fd67a0fb",
            "ceb8055f6ac94d0e937736f71a1fa403",
            "965c7dde61ae4f70bceb14baa4938802",
            "50704384983044ff93374323c8234fc3",
            "19db577511d64542af73cdcca1a3edb3",
            "88daadf30f5d4e0eb3c27adfddb2a94e",
            "e480b59ea283402497506a82a39e3006",
            "04246ed25bb34cbfa452c33d674cdd44",
            "dd9af9d55ac2426fa40571d8db43339c",
            "0ca32f91a4864fb9b701d24dbc08495f",
            "9572e2df63a3482f8c92a02b458c447f",
            "816ba8bf81b546a99c95ca1d394d5fa5",
            "9ed7e9c1b39f47a0bffedbaf6b05333c",
            "77151d9618b2411898637a4388d98787",
            "657d956f82994008889195b80d31c114",
            "76d8a6608b68415592f64d1d696d4aad",
            "f5f52d94826f444cba68f90c4ab8b7b9",
            "a2bd55b6013f4f85a3c1ed95bc1d5fd8",
            "fb6e56a3cebe4deb85d67044dcb2959c",
            "66138112381f4de9a847b6e7878a0f49",
            "74ae514f022c4f94bd1a22a6f9292635",
            "52b82e0003434c59966af74d97401b5f",
            "c8cfefe741fb48f987fe44fe26fe573c",
            "e47e166d420040ae974d3f8b1721b3a3",
            "7b28331e3fb5492d839d74a3ed8a1a67",
            "850c63eac8a3427ca995e82b49076607",
            "fb27f6de0a43482786657c8b9b63dedf",
            "1d03a76c5bec4d2bbf649e00e7692376",
            "62fad4e7caac4453aa119cd114e7b784",
            "0832e5ea4dc54ef394b45288c6db1ba3",
            "c2697a5e97284badbcafe4069847a1a2",
            "0be0bd300a414181858d4c21830f3664",
            "43b507f676b14029a4352a695bf0d430",
            "1fb7fe081a974e8dafb8be54e655b4ce",
            "9171815e2e2346f68692c4fe0c80b228",
            "ef912d9656604cc6bcb446d3e9712bfc",
            "81a5e9ade7de4de18acc8a67d310963c",
            "da086a4188b74a04bb3416f31d26d55c",
            "e4e2d6dff939431ca35a20853e103d0d"
          ]
        },
        "id": "7AfI2q-UDVWR",
        "outputId": "c710d674-3202-4082-ffa2-2b9cb31e6224"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/223k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e17f9c04c4214d278a5e0d28bbc8b6c8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "28fcf8cb8a2f4dd9898f428d21d0a05c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/323 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e480b59ea283402497506a82a39e3006"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/620 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a2bd55b6013f4f85a3c1ed95bc1d5fd8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "62fad4e7caac4453aa119cd114e7b784"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at nlp4good/psych-search were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at nlp4good/psych-search and are newly initialized: ['classifier.weight', 'classifier.bias', 'bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tokenized = tokenizer(X_train, padding=True, truncation=True, max_length=512)\n",
        "X_val_tokenized = tokenizer(X_val, padding=True, truncation=True, max_length=512)"
      ],
      "metadata": {
        "id": "ZVk46haNFvc1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = Dataset(X_train_tokenized, y_train)\n",
        "val_dataset = Dataset(X_val_tokenized, y_val)"
      ],
      "metadata": {
        "id": "CPYDA-zvFvxv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###epoch=3"
      ],
      "metadata": {
        "id": "9NznGR6uuecY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "args = TrainingArguments(\n",
        "    output_dir=\"output\",\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=25,\n",
        "    per_device_train_batch_size=2,\n",
        "    per_device_eval_batch_size=2,\n",
        "    num_train_epochs=3,\n",
        "    seed=0,\n",
        "    load_best_model_at_end=True,\n",
        "    overwrite_output_dir=True,\n",
        "    learning_rate=3e-5,\n",
        "    gradient_accumulation_steps=16\n",
        ")"
      ],
      "metadata": {
        "id": "k8PQWi8XFv-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_psy = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
        ")"
      ],
      "metadata": {
        "id": "O1ynfE5HF0YC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_psy.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QAYTIy4F4C2",
        "outputId": "ef6e36ef-321c-4712-86c5-321633af389e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 801\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 2\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 16\n",
            "  Total optimization steps = 75\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='75' max='75' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [75/75 04:15, Epoch 2/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.631535</td>\n",
              "      <td>0.636816</td>\n",
              "      <td>0.558140</td>\n",
              "      <td>0.307692</td>\n",
              "      <td>0.396694</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.622105</td>\n",
              "      <td>0.621891</td>\n",
              "      <td>0.511905</td>\n",
              "      <td>0.551282</td>\n",
              "      <td>0.530864</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.641439</td>\n",
              "      <td>0.597015</td>\n",
              "      <td>0.486239</td>\n",
              "      <td>0.679487</td>\n",
              "      <td>0.566845</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=75, training_loss=0.5854359944661458, metrics={'train_runtime': 258.6812, 'train_samples_per_second': 9.289, 'train_steps_per_second': 0.29, 'total_flos': 631992754974720.0, 'train_loss': 0.5854359944661458, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###epoch=6"
      ],
      "metadata": {
        "id": "HJ16y1t2SMwU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "args = TrainingArguments(\n",
        "    output_dir=\"output\",\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=25,\n",
        "    per_device_train_batch_size=2,\n",
        "    per_device_eval_batch_size=2,\n",
        "    num_train_epochs=6,\n",
        "    seed=0,\n",
        "    load_best_model_at_end=True,\n",
        "    overwrite_output_dir=True,\n",
        "    learning_rate=3e-5,\n",
        "    gradient_accumulation_steps=16\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21fc1a4b-b867-4177-c7c1-f012167a7e84",
        "id": "IWvEfPt2SMwU"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_psy_6 = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
        ")"
      ],
      "metadata": {
        "id": "6GPLobc5SMwV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_psy_6.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4deaf22f-afca-4bfe-d14e-762d5a55eb1e",
        "id": "i0aYKltdSMwV"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 801\n",
            "  Num Epochs = 6\n",
            "  Instantaneous batch size per device = 2\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 16\n",
            "  Total optimization steps = 150\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='150' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [150/150 05:19, Epoch 5/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.490442</td>\n",
              "      <td>0.781095</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>0.827957</td>\n",
              "      <td>0.777778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.375540</td>\n",
              "      <td>0.711443</td>\n",
              "      <td>0.657658</td>\n",
              "      <td>0.784946</td>\n",
              "      <td>0.715686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.580385</td>\n",
              "      <td>0.731343</td>\n",
              "      <td>0.675676</td>\n",
              "      <td>0.806452</td>\n",
              "      <td>0.735294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.785634</td>\n",
              "      <td>0.736318</td>\n",
              "      <td>0.678571</td>\n",
              "      <td>0.817204</td>\n",
              "      <td>0.741463</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.534417</td>\n",
              "      <td>0.776119</td>\n",
              "      <td>0.740000</td>\n",
              "      <td>0.795699</td>\n",
              "      <td>0.766839</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.583016</td>\n",
              "      <td>0.766169</td>\n",
              "      <td>0.721154</td>\n",
              "      <td>0.806452</td>\n",
              "      <td>0.761421</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=150, training_loss=0.02686001141866048, metrics={'train_runtime': 321.1493, 'train_samples_per_second': 14.965, 'train_steps_per_second': 0.467, 'total_flos': 1264248621004800.0, 'train_loss': 0.02686001141866048, 'epoch': 6.0})"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###epoch=9"
      ],
      "metadata": {
        "id": "ugENBLMrEHoi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "args = TrainingArguments(\n",
        "    output_dir=\"output\",\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=25,\n",
        "    per_device_train_batch_size=2,\n",
        "    per_device_eval_batch_size=2,\n",
        "    num_train_epochs=9,\n",
        "    seed=0,\n",
        "    load_best_model_at_end=True,\n",
        "    overwrite_output_dir=True,\n",
        "    learning_rate=3e-5,\n",
        "    gradient_accumulation_steps=16\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PE3nrEWjEJbw",
        "outputId": "7e4e1000-1e04-4ff0-f985-23bf7784c647"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_psy_9 = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
        ")"
      ],
      "metadata": {
        "id": "KQlhUip8EJlJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_psy_9.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8kaHI7aEJyM",
        "outputId": "a2c278a4-6179-40de-94f5-ab0118390155"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 801\n",
            "  Num Epochs = 9\n",
            "  Instantaneous batch size per device = 2\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 16\n",
            "  Total optimization steps = 225\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='225' max='225' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [225/225 07:59, Epoch 8/9]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.616690</td>\n",
              "      <td>0.796020</td>\n",
              "      <td>0.782609</td>\n",
              "      <td>0.774194</td>\n",
              "      <td>0.778378</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.075152</td>\n",
              "      <td>0.721393</td>\n",
              "      <td>0.643411</td>\n",
              "      <td>0.892473</td>\n",
              "      <td>0.747748</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.613216</td>\n",
              "      <td>0.746269</td>\n",
              "      <td>0.687500</td>\n",
              "      <td>0.827957</td>\n",
              "      <td>0.751220</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.621726</td>\n",
              "      <td>0.786070</td>\n",
              "      <td>0.828947</td>\n",
              "      <td>0.677419</td>\n",
              "      <td>0.745562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.940256</td>\n",
              "      <td>0.701493</td>\n",
              "      <td>0.638655</td>\n",
              "      <td>0.817204</td>\n",
              "      <td>0.716981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.072261</td>\n",
              "      <td>0.701493</td>\n",
              "      <td>0.632000</td>\n",
              "      <td>0.849462</td>\n",
              "      <td>0.724771</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>175</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.897928</td>\n",
              "      <td>0.716418</td>\n",
              "      <td>0.655172</td>\n",
              "      <td>0.817204</td>\n",
              "      <td>0.727273</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.658141</td>\n",
              "      <td>0.756219</td>\n",
              "      <td>0.707547</td>\n",
              "      <td>0.806452</td>\n",
              "      <td>0.753769</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>225</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.571159</td>\n",
              "      <td>0.771144</td>\n",
              "      <td>0.728155</td>\n",
              "      <td>0.806452</td>\n",
              "      <td>0.765306</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=225, training_loss=0.02859132766723633, metrics={'train_runtime': 481.6038, 'train_samples_per_second': 14.969, 'train_steps_per_second': 0.467, 'total_flos': 1896504487034880.0, 'train_loss': 0.02859132766723633, 'epoch': 9.0})"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Outputs"
      ],
      "metadata": {
        "id": "LFdPun0rDLgm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##SciBERT"
      ],
      "metadata": {
        "id": "H9OWeTn4DWOs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###epoch=3"
      ],
      "metadata": {
        "id": "Jpl2BgcHug76"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_sci.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "id": "L5aMNte6DX3o",
        "outputId": "22e81dcc-19f3-40ad-9071-4e1162d576d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='101' max='101' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [101/101 00:04]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epoch': 3.0,\n",
              " 'eval_accuracy': 0.681592039800995,\n",
              " 'eval_f1': 0.6893203883495145,\n",
              " 'eval_loss': 0.5981957316398621,\n",
              " 'eval_precision': 0.6339285714285714,\n",
              " 'eval_recall': 0.7553191489361702,\n",
              " 'eval_runtime': 4.2902,\n",
              " 'eval_samples_per_second': 46.851,\n",
              " 'eval_steps_per_second': 23.542}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###epoch=6"
      ],
      "metadata": {
        "id": "B6nIoYBiSRH_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_sci_6.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "id": "xDChAPbpSSiO",
        "outputId": "efd3fb49-64b1-4a61-d654-59ce35f40f21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='101' max='101' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [101/101 00:04]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epoch': 6.0,\n",
              " 'eval_accuracy': 0.7213930348258707,\n",
              " 'eval_f1': 0.7281553398058253,\n",
              " 'eval_loss': 2.2063302993774414,\n",
              " 'eval_precision': 0.6521739130434783,\n",
              " 'eval_recall': 0.8241758241758241,\n",
              " 'eval_runtime': 4.3236,\n",
              " 'eval_samples_per_second': 46.489,\n",
              " 'eval_steps_per_second': 23.36}"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###epoch=9"
      ],
      "metadata": {
        "id": "S2cYtjpB5HSU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_sci_9.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "id": "oljDjoIy5IsS",
        "outputId": "8ed1ab7f-acb1-4841-8b3f-0d66f0f003d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='101' max='101' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [101/101 00:04]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epoch': 9.0,\n",
              " 'eval_accuracy': 0.7213930348258707,\n",
              " 'eval_f1': 0.6989247311827957,\n",
              " 'eval_loss': 1.9078761339187622,\n",
              " 'eval_precision': 0.6842105263157895,\n",
              " 'eval_recall': 0.7142857142857143,\n",
              " 'eval_runtime': 4.3249,\n",
              " 'eval_samples_per_second': 46.475,\n",
              " 'eval_steps_per_second': 23.353}"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##PSY"
      ],
      "metadata": {
        "id": "4gje3ApODYFg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###epoch=3"
      ],
      "metadata": {
        "id": "UO8YLjAqujCW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_psy.evaluate()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3csZDM0DZj_",
        "outputId": "80d4dd80-f25b-41a3-aa01-3009563d7dc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='101' max='101' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [101/101 00:07]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epoch': 3.0,\n",
              " 'eval_accuracy': 0.5970149253731343,\n",
              " 'eval_f1': 0.5668449197860963,\n",
              " 'eval_loss': 0.641438901424408,\n",
              " 'eval_precision': 0.48623853211009177,\n",
              " 'eval_recall': 0.6794871794871795,\n",
              " 'eval_runtime': 7.5822,\n",
              " 'eval_samples_per_second': 26.51,\n",
              " 'eval_steps_per_second': 13.321}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###epoch=6"
      ],
      "metadata": {
        "id": "pF-XbWBGSUUj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_psy_6.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "id": "eITDiO6WST7b",
        "outputId": "7b45562a-857d-4a42-8438-c81412d73db8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='101' max='101' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [101/101 00:04]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epoch': 6.0,\n",
              " 'eval_accuracy': 0.7661691542288557,\n",
              " 'eval_f1': 0.7614213197969544,\n",
              " 'eval_loss': 1.5830156803131104,\n",
              " 'eval_precision': 0.7211538461538461,\n",
              " 'eval_recall': 0.8064516129032258,\n",
              " 'eval_runtime': 4.3324,\n",
              " 'eval_samples_per_second': 46.395,\n",
              " 'eval_steps_per_second': 23.313}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###epoch=9"
      ],
      "metadata": {
        "id": "NGFnNGyeD_0X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_psy_9.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "id": "412EmhatEBBU",
        "outputId": "b9153edd-3140-4909-b94b-89250937cadd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='101' max='101' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [101/101 00:04]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epoch': 9.0,\n",
              " 'eval_accuracy': 0.7711442786069652,\n",
              " 'eval_f1': 0.7653061224489796,\n",
              " 'eval_loss': 1.571158528327942,\n",
              " 'eval_precision': 0.7281553398058253,\n",
              " 'eval_recall': 0.8064516129032258,\n",
              " 'eval_runtime': 4.3211,\n",
              " 'eval_samples_per_second': 46.516,\n",
              " 'eval_steps_per_second': 23.374}"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#epoch-test"
      ],
      "metadata": {
        "id": "l2kptAGvGYPh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "psy_epoch_range = range(3,61,3)\n",
        "recall_list = []\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for i in psy_epoch_range:\n",
        "\n",
        "  tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "  model = BertForSequenceClassification.from_pretrained(model_name,num_labels =2 )\n",
        "\n",
        "\n",
        "  args = TrainingArguments(\n",
        "    output_dir=\"output\",\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=25,\n",
        "    per_device_train_batch_size=2,\n",
        "    per_device_eval_batch_size=2,\n",
        "    num_train_epochs=i,\n",
        "    seed=0,\n",
        "    load_best_model_at_end=True,\n",
        "    overwrite_output_dir=True,\n",
        "    learning_rate=3e-5,\n",
        "    gradient_accumulation_steps=16\n",
        "  )\n",
        "\n",
        "  trainer_psy_tmp = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
        "  ) \n",
        "\n",
        "  trainer_psy_tmp.train()\n",
        "  tmp_eval = trainer_psy_tmp.evaluate()\n",
        "  recall_list.append(tmp_eval['eval_recall'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XxXHHY10GfuI",
        "outputId": "355126a1-fcca-4413-919f-4580b33eacec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file https://huggingface.co/nlp4good/psych-search/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/daeea662c4b48e2b660049ca9c884af1818b56fa516e63fe8d4674fbd72c421c.38339d84e6e392addd730fd85fae32652c4cc7c5423633d6fa73e5f7937bbc38\n",
            "loading file https://huggingface.co/nlp4good/psych-search/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/nlp4good/psych-search/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/4a6fc3ad007c72a596ffe4cf1d5dfa0fa19dbb098481747e6757d602eedc30c3.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
            "loading file https://huggingface.co/nlp4good/psych-search/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/a861b08ab06b2a37194482cab468fe6bdfa40d1d760b4ae79744356068b102d7.e096ff0acc3183b627fd32953445a2a87dcb1eb6082c2897afd3dbb797efb7ba\n",
            "loading configuration file https://huggingface.co/nlp4good/psych-search/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/a42c5e0dd944d4c0f84302cc85db6e659bc597e8a136b4dfb3d89050b0f4d87b.f7ba9a920664090c977953cde41ea6bc638ce420772a754c2ed95eabb530437d\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"nlp4good/psych-search\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "loading configuration file https://huggingface.co/nlp4good/psych-search/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/a42c5e0dd944d4c0f84302cc85db6e659bc597e8a136b4dfb3d89050b0f4d87b.f7ba9a920664090c977953cde41ea6bc638ce420772a754c2ed95eabb530437d\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"allenai/scibert_scivocab_uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/nlp4good/psych-search/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/21798e87574f2b37c028397e50c0c48cfe13782c956dff552da851fc5529b72a.40462569c9b9f3a2812ab87853c873a9d14cdbb8d5170beb3a233440985753fa\n",
            "Some weights of the model checkpoint at nlp4good/psych-search were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at nlp4good/psych-search and are newly initialized: ['classifier.weight', 'classifier.bias', 'bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 801\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 2\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 16\n",
            "  Total optimization steps = 75\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='75' max='75' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [75/75 04:22, Epoch 2/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.681670</td>\n",
              "      <td>0.502488</td>\n",
              "      <td>0.427632</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.565217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.671249</td>\n",
              "      <td>0.542289</td>\n",
              "      <td>0.446970</td>\n",
              "      <td>0.756410</td>\n",
              "      <td>0.561905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.682867</td>\n",
              "      <td>0.567164</td>\n",
              "      <td>0.465116</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.579710</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='101' max='101' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [101/101 00:07]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file https://huggingface.co/nlp4good/psych-search/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/daeea662c4b48e2b660049ca9c884af1818b56fa516e63fe8d4674fbd72c421c.38339d84e6e392addd730fd85fae32652c4cc7c5423633d6fa73e5f7937bbc38\n",
            "loading file https://huggingface.co/nlp4good/psych-search/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/nlp4good/psych-search/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/4a6fc3ad007c72a596ffe4cf1d5dfa0fa19dbb098481747e6757d602eedc30c3.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
            "loading file https://huggingface.co/nlp4good/psych-search/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/a861b08ab06b2a37194482cab468fe6bdfa40d1d760b4ae79744356068b102d7.e096ff0acc3183b627fd32953445a2a87dcb1eb6082c2897afd3dbb797efb7ba\n",
            "loading configuration file https://huggingface.co/nlp4good/psych-search/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/a42c5e0dd944d4c0f84302cc85db6e659bc597e8a136b4dfb3d89050b0f4d87b.f7ba9a920664090c977953cde41ea6bc638ce420772a754c2ed95eabb530437d\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"nlp4good/psych-search\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "loading configuration file https://huggingface.co/nlp4good/psych-search/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/a42c5e0dd944d4c0f84302cc85db6e659bc597e8a136b4dfb3d89050b0f4d87b.f7ba9a920664090c977953cde41ea6bc638ce420772a754c2ed95eabb530437d\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"allenai/scibert_scivocab_uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/nlp4good/psych-search/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/21798e87574f2b37c028397e50c0c48cfe13782c956dff552da851fc5529b72a.40462569c9b9f3a2812ab87853c873a9d14cdbb8d5170beb3a233440985753fa\n",
            "Some weights of the model checkpoint at nlp4good/psych-search were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at nlp4good/psych-search and are newly initialized: ['classifier.weight', 'classifier.bias', 'bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 801\n",
            "  Num Epochs = 6\n",
            "  Instantaneous batch size per device = 2\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 16\n",
            "  Total optimization steps = 150\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='150' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [150/150 08:46, Epoch 5/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.611241</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.641026</td>\n",
              "      <td>0.320513</td>\n",
              "      <td>0.427350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.629563</td>\n",
              "      <td>0.681592</td>\n",
              "      <td>0.557377</td>\n",
              "      <td>0.871795</td>\n",
              "      <td>0.680000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.539053</td>\n",
              "      <td>0.731343</td>\n",
              "      <td>0.633333</td>\n",
              "      <td>0.730769</td>\n",
              "      <td>0.678571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.612847</td>\n",
              "      <td>0.766169</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.794872</td>\n",
              "      <td>0.725146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.674489</td>\n",
              "      <td>0.781095</td>\n",
              "      <td>0.688889</td>\n",
              "      <td>0.794872</td>\n",
              "      <td>0.738095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.742900</td>\n",
              "      <td>0.761194</td>\n",
              "      <td>0.663043</td>\n",
              "      <td>0.782051</td>\n",
              "      <td>0.717647</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='101' max='101' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [101/101 00:07]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file https://huggingface.co/nlp4good/psych-search/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/daeea662c4b48e2b660049ca9c884af1818b56fa516e63fe8d4674fbd72c421c.38339d84e6e392addd730fd85fae32652c4cc7c5423633d6fa73e5f7937bbc38\n",
            "loading file https://huggingface.co/nlp4good/psych-search/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/nlp4good/psych-search/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/4a6fc3ad007c72a596ffe4cf1d5dfa0fa19dbb098481747e6757d602eedc30c3.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
            "loading file https://huggingface.co/nlp4good/psych-search/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/a861b08ab06b2a37194482cab468fe6bdfa40d1d760b4ae79744356068b102d7.e096ff0acc3183b627fd32953445a2a87dcb1eb6082c2897afd3dbb797efb7ba\n",
            "loading configuration file https://huggingface.co/nlp4good/psych-search/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/a42c5e0dd944d4c0f84302cc85db6e659bc597e8a136b4dfb3d89050b0f4d87b.f7ba9a920664090c977953cde41ea6bc638ce420772a754c2ed95eabb530437d\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"nlp4good/psych-search\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "loading configuration file https://huggingface.co/nlp4good/psych-search/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/a42c5e0dd944d4c0f84302cc85db6e659bc597e8a136b4dfb3d89050b0f4d87b.f7ba9a920664090c977953cde41ea6bc638ce420772a754c2ed95eabb530437d\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"allenai/scibert_scivocab_uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/nlp4good/psych-search/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/21798e87574f2b37c028397e50c0c48cfe13782c956dff552da851fc5529b72a.40462569c9b9f3a2812ab87853c873a9d14cdbb8d5170beb3a233440985753fa\n",
            "Some weights of the model checkpoint at nlp4good/psych-search were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at nlp4good/psych-search and are newly initialized: ['classifier.weight', 'classifier.bias', 'bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 801\n",
            "  Num Epochs = 9\n",
            "  Instantaneous batch size per device = 2\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 16\n",
            "  Total optimization steps = 225\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='225' max='225' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [225/225 13:11, Epoch 8/9]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.611757</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.720000</td>\n",
              "      <td>0.230769</td>\n",
              "      <td>0.349515</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.626197</td>\n",
              "      <td>0.651741</td>\n",
              "      <td>0.532258</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>0.653465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.563470</td>\n",
              "      <td>0.756219</td>\n",
              "      <td>0.659341</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.710059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.821967</td>\n",
              "      <td>0.746269</td>\n",
              "      <td>0.645161</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.701754</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.837730</td>\n",
              "      <td>0.726368</td>\n",
              "      <td>0.616162</td>\n",
              "      <td>0.782051</td>\n",
              "      <td>0.689266</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.079398</td>\n",
              "      <td>0.741294</td>\n",
              "      <td>0.627451</td>\n",
              "      <td>0.820513</td>\n",
              "      <td>0.711111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>175</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.161636</td>\n",
              "      <td>0.741294</td>\n",
              "      <td>0.630000</td>\n",
              "      <td>0.807692</td>\n",
              "      <td>0.707865</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.275421</td>\n",
              "      <td>0.721393</td>\n",
              "      <td>0.601852</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.698925</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>225</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.195110</td>\n",
              "      <td>0.746269</td>\n",
              "      <td>0.642105</td>\n",
              "      <td>0.782051</td>\n",
              "      <td>0.705202</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='101' max='101' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [101/101 00:07]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file https://huggingface.co/nlp4good/psych-search/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/daeea662c4b48e2b660049ca9c884af1818b56fa516e63fe8d4674fbd72c421c.38339d84e6e392addd730fd85fae32652c4cc7c5423633d6fa73e5f7937bbc38\n",
            "loading file https://huggingface.co/nlp4good/psych-search/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/nlp4good/psych-search/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/4a6fc3ad007c72a596ffe4cf1d5dfa0fa19dbb098481747e6757d602eedc30c3.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
            "loading file https://huggingface.co/nlp4good/psych-search/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/a861b08ab06b2a37194482cab468fe6bdfa40d1d760b4ae79744356068b102d7.e096ff0acc3183b627fd32953445a2a87dcb1eb6082c2897afd3dbb797efb7ba\n",
            "loading configuration file https://huggingface.co/nlp4good/psych-search/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/a42c5e0dd944d4c0f84302cc85db6e659bc597e8a136b4dfb3d89050b0f4d87b.f7ba9a920664090c977953cde41ea6bc638ce420772a754c2ed95eabb530437d\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"nlp4good/psych-search\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "loading configuration file https://huggingface.co/nlp4good/psych-search/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/a42c5e0dd944d4c0f84302cc85db6e659bc597e8a136b4dfb3d89050b0f4d87b.f7ba9a920664090c977953cde41ea6bc638ce420772a754c2ed95eabb530437d\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"allenai/scibert_scivocab_uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/nlp4good/psych-search/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/21798e87574f2b37c028397e50c0c48cfe13782c956dff552da851fc5529b72a.40462569c9b9f3a2812ab87853c873a9d14cdbb8d5170beb3a233440985753fa\n",
            "Some weights of the model checkpoint at nlp4good/psych-search were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at nlp4good/psych-search and are newly initialized: ['classifier.weight', 'classifier.bias', 'bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 801\n",
            "  Num Epochs = 12\n",
            "  Instantaneous batch size per device = 2\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 16\n",
            "  Total optimization steps = 300\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 17:35, Epoch 11/12]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.623095</td>\n",
              "      <td>0.641791</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.192308</td>\n",
              "      <td>0.294118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.630731</td>\n",
              "      <td>0.626866</td>\n",
              "      <td>0.512195</td>\n",
              "      <td>0.807692</td>\n",
              "      <td>0.626866</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.583585</td>\n",
              "      <td>0.696517</td>\n",
              "      <td>0.591398</td>\n",
              "      <td>0.705128</td>\n",
              "      <td>0.643275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.654476</td>\n",
              "      <td>0.751244</td>\n",
              "      <td>0.655556</td>\n",
              "      <td>0.756410</td>\n",
              "      <td>0.702381</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.810503</td>\n",
              "      <td>0.751244</td>\n",
              "      <td>0.648936</td>\n",
              "      <td>0.782051</td>\n",
              "      <td>0.709302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.232874</td>\n",
              "      <td>0.696517</td>\n",
              "      <td>0.570248</td>\n",
              "      <td>0.884615</td>\n",
              "      <td>0.693467</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>175</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.986672</td>\n",
              "      <td>0.751244</td>\n",
              "      <td>0.662791</td>\n",
              "      <td>0.730769</td>\n",
              "      <td>0.695122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.072077</td>\n",
              "      <td>0.741294</td>\n",
              "      <td>0.647727</td>\n",
              "      <td>0.730769</td>\n",
              "      <td>0.686747</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>225</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.227763</td>\n",
              "      <td>0.741294</td>\n",
              "      <td>0.630000</td>\n",
              "      <td>0.807692</td>\n",
              "      <td>0.707865</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.289153</td>\n",
              "      <td>0.746269</td>\n",
              "      <td>0.636364</td>\n",
              "      <td>0.807692</td>\n",
              "      <td>0.711864</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>275</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.311777</td>\n",
              "      <td>0.741294</td>\n",
              "      <td>0.635417</td>\n",
              "      <td>0.782051</td>\n",
              "      <td>0.701149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.264872</td>\n",
              "      <td>0.756219</td>\n",
              "      <td>0.662921</td>\n",
              "      <td>0.756410</td>\n",
              "      <td>0.706587</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='101' max='101' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [101/101 00:07]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file https://huggingface.co/nlp4good/psych-search/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/daeea662c4b48e2b660049ca9c884af1818b56fa516e63fe8d4674fbd72c421c.38339d84e6e392addd730fd85fae32652c4cc7c5423633d6fa73e5f7937bbc38\n",
            "loading file https://huggingface.co/nlp4good/psych-search/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/nlp4good/psych-search/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/4a6fc3ad007c72a596ffe4cf1d5dfa0fa19dbb098481747e6757d602eedc30c3.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
            "loading file https://huggingface.co/nlp4good/psych-search/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/a861b08ab06b2a37194482cab468fe6bdfa40d1d760b4ae79744356068b102d7.e096ff0acc3183b627fd32953445a2a87dcb1eb6082c2897afd3dbb797efb7ba\n",
            "loading configuration file https://huggingface.co/nlp4good/psych-search/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/a42c5e0dd944d4c0f84302cc85db6e659bc597e8a136b4dfb3d89050b0f4d87b.f7ba9a920664090c977953cde41ea6bc638ce420772a754c2ed95eabb530437d\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"nlp4good/psych-search\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "loading configuration file https://huggingface.co/nlp4good/psych-search/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/a42c5e0dd944d4c0f84302cc85db6e659bc597e8a136b4dfb3d89050b0f4d87b.f7ba9a920664090c977953cde41ea6bc638ce420772a754c2ed95eabb530437d\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"allenai/scibert_scivocab_uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/nlp4good/psych-search/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/21798e87574f2b37c028397e50c0c48cfe13782c956dff552da851fc5529b72a.40462569c9b9f3a2812ab87853c873a9d14cdbb8d5170beb3a233440985753fa\n",
            "Some weights of the model checkpoint at nlp4good/psych-search were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at nlp4good/psych-search and are newly initialized: ['classifier.weight', 'classifier.bias', 'bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 801\n",
            "  Num Epochs = 15\n",
            "  Instantaneous batch size per device = 2\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 16\n",
            "  Total optimization steps = 375\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='375' max='375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [375/375 22:01, Epoch 14/15]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.611906</td>\n",
              "      <td>0.696517</td>\n",
              "      <td>0.680851</td>\n",
              "      <td>0.410256</td>\n",
              "      <td>0.512000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.643488</td>\n",
              "      <td>0.661692</td>\n",
              "      <td>0.540984</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>0.660000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.578855</td>\n",
              "      <td>0.731343</td>\n",
              "      <td>0.622449</td>\n",
              "      <td>0.782051</td>\n",
              "      <td>0.693182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.818633</td>\n",
              "      <td>0.706468</td>\n",
              "      <td>0.606742</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.646707</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.032930</td>\n",
              "      <td>0.711443</td>\n",
              "      <td>0.590909</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.691489</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.982322</td>\n",
              "      <td>0.736318</td>\n",
              "      <td>0.640449</td>\n",
              "      <td>0.730769</td>\n",
              "      <td>0.682635</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>175</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.280890</td>\n",
              "      <td>0.696517</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.871795</td>\n",
              "      <td>0.690355</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.312691</td>\n",
              "      <td>0.751244</td>\n",
              "      <td>0.640000</td>\n",
              "      <td>0.820513</td>\n",
              "      <td>0.719101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>225</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.582865</td>\n",
              "      <td>0.681592</td>\n",
              "      <td>0.554688</td>\n",
              "      <td>0.910256</td>\n",
              "      <td>0.689320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.461441</td>\n",
              "      <td>0.731343</td>\n",
              "      <td>0.603448</td>\n",
              "      <td>0.897436</td>\n",
              "      <td>0.721649</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>275</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.270710</td>\n",
              "      <td>0.766169</td>\n",
              "      <td>0.659794</td>\n",
              "      <td>0.820513</td>\n",
              "      <td>0.731429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.307037</td>\n",
              "      <td>0.771144</td>\n",
              "      <td>0.670213</td>\n",
              "      <td>0.807692</td>\n",
              "      <td>0.732558</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>325</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.353940</td>\n",
              "      <td>0.761194</td>\n",
              "      <td>0.663043</td>\n",
              "      <td>0.782051</td>\n",
              "      <td>0.717647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.380666</td>\n",
              "      <td>0.771144</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.820513</td>\n",
              "      <td>0.735632</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>375</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.396822</td>\n",
              "      <td>0.776119</td>\n",
              "      <td>0.670103</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.742857</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='101' max='101' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [101/101 00:07]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file https://huggingface.co/nlp4good/psych-search/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/daeea662c4b48e2b660049ca9c884af1818b56fa516e63fe8d4674fbd72c421c.38339d84e6e392addd730fd85fae32652c4cc7c5423633d6fa73e5f7937bbc38\n",
            "loading file https://huggingface.co/nlp4good/psych-search/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/nlp4good/psych-search/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/4a6fc3ad007c72a596ffe4cf1d5dfa0fa19dbb098481747e6757d602eedc30c3.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
            "loading file https://huggingface.co/nlp4good/psych-search/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/a861b08ab06b2a37194482cab468fe6bdfa40d1d760b4ae79744356068b102d7.e096ff0acc3183b627fd32953445a2a87dcb1eb6082c2897afd3dbb797efb7ba\n",
            "loading configuration file https://huggingface.co/nlp4good/psych-search/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/a42c5e0dd944d4c0f84302cc85db6e659bc597e8a136b4dfb3d89050b0f4d87b.f7ba9a920664090c977953cde41ea6bc638ce420772a754c2ed95eabb530437d\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"nlp4good/psych-search\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "loading configuration file https://huggingface.co/nlp4good/psych-search/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/a42c5e0dd944d4c0f84302cc85db6e659bc597e8a136b4dfb3d89050b0f4d87b.f7ba9a920664090c977953cde41ea6bc638ce420772a754c2ed95eabb530437d\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"allenai/scibert_scivocab_uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/nlp4good/psych-search/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/21798e87574f2b37c028397e50c0c48cfe13782c956dff552da851fc5529b72a.40462569c9b9f3a2812ab87853c873a9d14cdbb8d5170beb3a233440985753fa\n",
            "Some weights of the model checkpoint at nlp4good/psych-search were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at nlp4good/psych-search and are newly initialized: ['classifier.weight', 'classifier.bias', 'bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 801\n",
            "  Num Epochs = 18\n",
            "  Instantaneous batch size per device = 2\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 16\n",
            "  Total optimization steps = 450\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='450' max='450' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [450/450 26:27, Epoch 17/18]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.613945</td>\n",
              "      <td>0.711443</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.461538</td>\n",
              "      <td>0.553846</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.601042</td>\n",
              "      <td>0.651741</td>\n",
              "      <td>0.532787</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.650000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.594654</td>\n",
              "      <td>0.696517</td>\n",
              "      <td>0.584158</td>\n",
              "      <td>0.756410</td>\n",
              "      <td>0.659218</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.875021</td>\n",
              "      <td>0.696517</td>\n",
              "      <td>0.575221</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.680628</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.012808</td>\n",
              "      <td>0.716418</td>\n",
              "      <td>0.612903</td>\n",
              "      <td>0.730769</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.151524</td>\n",
              "      <td>0.721393</td>\n",
              "      <td>0.598214</td>\n",
              "      <td>0.858974</td>\n",
              "      <td>0.705263</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>175</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.130252</td>\n",
              "      <td>0.766169</td>\n",
              "      <td>0.678161</td>\n",
              "      <td>0.756410</td>\n",
              "      <td>0.715152</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.295415</td>\n",
              "      <td>0.706468</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.730769</td>\n",
              "      <td>0.658960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>225</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.327184</td>\n",
              "      <td>0.731343</td>\n",
              "      <td>0.617647</td>\n",
              "      <td>0.807692</td>\n",
              "      <td>0.700000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.484580</td>\n",
              "      <td>0.721393</td>\n",
              "      <td>0.594828</td>\n",
              "      <td>0.884615</td>\n",
              "      <td>0.711340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>275</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.360106</td>\n",
              "      <td>0.746269</td>\n",
              "      <td>0.631068</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.718232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.376133</td>\n",
              "      <td>0.736318</td>\n",
              "      <td>0.640449</td>\n",
              "      <td>0.730769</td>\n",
              "      <td>0.682635</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>325</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.424166</td>\n",
              "      <td>0.731343</td>\n",
              "      <td>0.622449</td>\n",
              "      <td>0.782051</td>\n",
              "      <td>0.693182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.465166</td>\n",
              "      <td>0.731343</td>\n",
              "      <td>0.630435</td>\n",
              "      <td>0.743590</td>\n",
              "      <td>0.682353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>375</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.496498</td>\n",
              "      <td>0.731343</td>\n",
              "      <td>0.633333</td>\n",
              "      <td>0.730769</td>\n",
              "      <td>0.678571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.485185</td>\n",
              "      <td>0.746269</td>\n",
              "      <td>0.633663</td>\n",
              "      <td>0.820513</td>\n",
              "      <td>0.715084</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>425</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.501152</td>\n",
              "      <td>0.741294</td>\n",
              "      <td>0.622642</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>0.717391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.487873</td>\n",
              "      <td>0.741294</td>\n",
              "      <td>0.632653</td>\n",
              "      <td>0.794872</td>\n",
              "      <td>0.704545</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='101' max='101' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [101/101 00:07]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file https://huggingface.co/nlp4good/psych-search/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/daeea662c4b48e2b660049ca9c884af1818b56fa516e63fe8d4674fbd72c421c.38339d84e6e392addd730fd85fae32652c4cc7c5423633d6fa73e5f7937bbc38\n",
            "loading file https://huggingface.co/nlp4good/psych-search/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/nlp4good/psych-search/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/4a6fc3ad007c72a596ffe4cf1d5dfa0fa19dbb098481747e6757d602eedc30c3.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
            "loading file https://huggingface.co/nlp4good/psych-search/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/a861b08ab06b2a37194482cab468fe6bdfa40d1d760b4ae79744356068b102d7.e096ff0acc3183b627fd32953445a2a87dcb1eb6082c2897afd3dbb797efb7ba\n",
            "loading configuration file https://huggingface.co/nlp4good/psych-search/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/a42c5e0dd944d4c0f84302cc85db6e659bc597e8a136b4dfb3d89050b0f4d87b.f7ba9a920664090c977953cde41ea6bc638ce420772a754c2ed95eabb530437d\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"nlp4good/psych-search\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "loading configuration file https://huggingface.co/nlp4good/psych-search/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/a42c5e0dd944d4c0f84302cc85db6e659bc597e8a136b4dfb3d89050b0f4d87b.f7ba9a920664090c977953cde41ea6bc638ce420772a754c2ed95eabb530437d\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"allenai/scibert_scivocab_uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/nlp4good/psych-search/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/21798e87574f2b37c028397e50c0c48cfe13782c956dff552da851fc5529b72a.40462569c9b9f3a2812ab87853c873a9d14cdbb8d5170beb3a233440985753fa\n",
            "Some weights of the model checkpoint at nlp4good/psych-search were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at nlp4good/psych-search and are newly initialized: ['classifier.weight', 'classifier.bias', 'bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 801\n",
            "  Num Epochs = 21\n",
            "  Instantaneous batch size per device = 2\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 16\n",
            "  Total optimization steps = 525\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [525/525 30:56, Epoch 20/21]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.615282</td>\n",
              "      <td>0.661692</td>\n",
              "      <td>0.608696</td>\n",
              "      <td>0.358974</td>\n",
              "      <td>0.451613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.625142</td>\n",
              "      <td>0.681592</td>\n",
              "      <td>0.561404</td>\n",
              "      <td>0.820513</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.536335</td>\n",
              "      <td>0.751244</td>\n",
              "      <td>0.659091</td>\n",
              "      <td>0.743590</td>\n",
              "      <td>0.698795</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.749827</td>\n",
              "      <td>0.736318</td>\n",
              "      <td>0.631579</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.693642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.898856</td>\n",
              "      <td>0.756219</td>\n",
              "      <td>0.659341</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.710059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.080506</td>\n",
              "      <td>0.731343</td>\n",
              "      <td>0.615385</td>\n",
              "      <td>0.820513</td>\n",
              "      <td>0.703297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>175</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.268054</td>\n",
              "      <td>0.746269</td>\n",
              "      <td>0.631068</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.718232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.311802</td>\n",
              "      <td>0.721393</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.705128</td>\n",
              "      <td>0.662651</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>225</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.179180</td>\n",
              "      <td>0.736318</td>\n",
              "      <td>0.631579</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.693642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.283782</td>\n",
              "      <td>0.766169</td>\n",
              "      <td>0.656566</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.734463</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>275</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.320964</td>\n",
              "      <td>0.721393</td>\n",
              "      <td>0.614583</td>\n",
              "      <td>0.756410</td>\n",
              "      <td>0.678161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.521904</td>\n",
              "      <td>0.736318</td>\n",
              "      <td>0.628866</td>\n",
              "      <td>0.782051</td>\n",
              "      <td>0.697143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>325</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.468713</td>\n",
              "      <td>0.751244</td>\n",
              "      <td>0.637255</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.722222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.567905</td>\n",
              "      <td>0.746269</td>\n",
              "      <td>0.623853</td>\n",
              "      <td>0.871795</td>\n",
              "      <td>0.727273</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>375</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.423304</td>\n",
              "      <td>0.731343</td>\n",
              "      <td>0.642857</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.503132</td>\n",
              "      <td>0.746269</td>\n",
              "      <td>0.639175</td>\n",
              "      <td>0.794872</td>\n",
              "      <td>0.708571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>425</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.527676</td>\n",
              "      <td>0.726368</td>\n",
              "      <td>0.611650</td>\n",
              "      <td>0.807692</td>\n",
              "      <td>0.696133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.488565</td>\n",
              "      <td>0.736318</td>\n",
              "      <td>0.640449</td>\n",
              "      <td>0.730769</td>\n",
              "      <td>0.682635</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>475</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.525638</td>\n",
              "      <td>0.736318</td>\n",
              "      <td>0.634409</td>\n",
              "      <td>0.756410</td>\n",
              "      <td>0.690058</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.122000</td>\n",
              "      <td>1.538376</td>\n",
              "      <td>0.741294</td>\n",
              "      <td>0.638298</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.697674</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>525</td>\n",
              "      <td>0.122000</td>\n",
              "      <td>1.546782</td>\n",
              "      <td>0.746269</td>\n",
              "      <td>0.636364</td>\n",
              "      <td>0.807692</td>\n",
              "      <td>0.711864</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "Saving model checkpoint to output/checkpoint-500\n",
            "Configuration saved in output/checkpoint-500/config.json\n",
            "Model weights saved in output/checkpoint-500/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from output/checkpoint-500 (score: 1.5383756160736084).\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='101' max='101' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [101/101 00:07]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file https://huggingface.co/nlp4good/psych-search/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/daeea662c4b48e2b660049ca9c884af1818b56fa516e63fe8d4674fbd72c421c.38339d84e6e392addd730fd85fae32652c4cc7c5423633d6fa73e5f7937bbc38\n",
            "loading file https://huggingface.co/nlp4good/psych-search/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/nlp4good/psych-search/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/4a6fc3ad007c72a596ffe4cf1d5dfa0fa19dbb098481747e6757d602eedc30c3.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
            "loading file https://huggingface.co/nlp4good/psych-search/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/a861b08ab06b2a37194482cab468fe6bdfa40d1d760b4ae79744356068b102d7.e096ff0acc3183b627fd32953445a2a87dcb1eb6082c2897afd3dbb797efb7ba\n",
            "loading configuration file https://huggingface.co/nlp4good/psych-search/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/a42c5e0dd944d4c0f84302cc85db6e659bc597e8a136b4dfb3d89050b0f4d87b.f7ba9a920664090c977953cde41ea6bc638ce420772a754c2ed95eabb530437d\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"nlp4good/psych-search\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "loading configuration file https://huggingface.co/nlp4good/psych-search/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/a42c5e0dd944d4c0f84302cc85db6e659bc597e8a136b4dfb3d89050b0f4d87b.f7ba9a920664090c977953cde41ea6bc638ce420772a754c2ed95eabb530437d\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"allenai/scibert_scivocab_uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/nlp4good/psych-search/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/21798e87574f2b37c028397e50c0c48cfe13782c956dff552da851fc5529b72a.40462569c9b9f3a2812ab87853c873a9d14cdbb8d5170beb3a233440985753fa\n",
            "Some weights of the model checkpoint at nlp4good/psych-search were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at nlp4good/psych-search and are newly initialized: ['classifier.weight', 'classifier.bias', 'bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 801\n",
            "  Num Epochs = 24\n",
            "  Instantaneous batch size per device = 2\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 16\n",
            "  Total optimization steps = 600\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='575' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [575/600 33:54 < 01:28, 0.28 it/s, Epoch 22/24]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.637668</td>\n",
              "      <td>0.636816</td>\n",
              "      <td>0.551020</td>\n",
              "      <td>0.346154</td>\n",
              "      <td>0.425197</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.705886</td>\n",
              "      <td>0.552239</td>\n",
              "      <td>0.455882</td>\n",
              "      <td>0.794872</td>\n",
              "      <td>0.579439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.630204</td>\n",
              "      <td>0.716418</td>\n",
              "      <td>0.620690</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.654545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.949845</td>\n",
              "      <td>0.706468</td>\n",
              "      <td>0.592233</td>\n",
              "      <td>0.782051</td>\n",
              "      <td>0.674033</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.964317</td>\n",
              "      <td>0.731343</td>\n",
              "      <td>0.627660</td>\n",
              "      <td>0.756410</td>\n",
              "      <td>0.686047</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.278176</td>\n",
              "      <td>0.686567</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.655738</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>175</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.227233</td>\n",
              "      <td>0.726368</td>\n",
              "      <td>0.626374</td>\n",
              "      <td>0.730769</td>\n",
              "      <td>0.674556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.386260</td>\n",
              "      <td>0.721393</td>\n",
              "      <td>0.630952</td>\n",
              "      <td>0.679487</td>\n",
              "      <td>0.654321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>225</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.519457</td>\n",
              "      <td>0.686567</td>\n",
              "      <td>0.563025</td>\n",
              "      <td>0.858974</td>\n",
              "      <td>0.680203</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.561675</td>\n",
              "      <td>0.701493</td>\n",
              "      <td>0.586538</td>\n",
              "      <td>0.782051</td>\n",
              "      <td>0.670330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>275</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.703982</td>\n",
              "      <td>0.671642</td>\n",
              "      <td>0.561224</td>\n",
              "      <td>0.705128</td>\n",
              "      <td>0.625000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.605178</td>\n",
              "      <td>0.696517</td>\n",
              "      <td>0.591398</td>\n",
              "      <td>0.705128</td>\n",
              "      <td>0.643275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>325</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.621595</td>\n",
              "      <td>0.691542</td>\n",
              "      <td>0.581633</td>\n",
              "      <td>0.730769</td>\n",
              "      <td>0.647727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.995479</td>\n",
              "      <td>0.646766</td>\n",
              "      <td>0.529915</td>\n",
              "      <td>0.794872</td>\n",
              "      <td>0.635897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>375</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.924912</td>\n",
              "      <td>0.651741</td>\n",
              "      <td>0.533898</td>\n",
              "      <td>0.807692</td>\n",
              "      <td>0.642857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.737335</td>\n",
              "      <td>0.711443</td>\n",
              "      <td>0.616279</td>\n",
              "      <td>0.679487</td>\n",
              "      <td>0.646341</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>425</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.726294</td>\n",
              "      <td>0.691542</td>\n",
              "      <td>0.585106</td>\n",
              "      <td>0.705128</td>\n",
              "      <td>0.639535</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.808586</td>\n",
              "      <td>0.696517</td>\n",
              "      <td>0.579439</td>\n",
              "      <td>0.794872</td>\n",
              "      <td>0.670270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>475</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.727792</td>\n",
              "      <td>0.716418</td>\n",
              "      <td>0.620690</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.654545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.126400</td>\n",
              "      <td>1.801694</td>\n",
              "      <td>0.701493</td>\n",
              "      <td>0.584906</td>\n",
              "      <td>0.794872</td>\n",
              "      <td>0.673913</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>525</td>\n",
              "      <td>0.126400</td>\n",
              "      <td>1.881065</td>\n",
              "      <td>0.701493</td>\n",
              "      <td>0.584906</td>\n",
              "      <td>0.794872</td>\n",
              "      <td>0.673913</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.126400</td>\n",
              "      <td>1.806542</td>\n",
              "      <td>0.701493</td>\n",
              "      <td>0.595745</td>\n",
              "      <td>0.717949</td>\n",
              "      <td>0.651163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>575</td>\n",
              "      <td>0.126400</td>\n",
              "      <td>1.833994</td>\n",
              "      <td>0.706468</td>\n",
              "      <td>0.590476</td>\n",
              "      <td>0.794872</td>\n",
              "      <td>0.677596</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "Saving model checkpoint to output/checkpoint-500\n",
            "Configuration saved in output/checkpoint-500/config.json\n",
            "Model weights saved in output/checkpoint-500/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from output/checkpoint-500 (score: 1.8016937971115112).\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='101' max='101' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [101/101 00:07]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file https://huggingface.co/nlp4good/psych-search/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/daeea662c4b48e2b660049ca9c884af1818b56fa516e63fe8d4674fbd72c421c.38339d84e6e392addd730fd85fae32652c4cc7c5423633d6fa73e5f7937bbc38\n",
            "loading file https://huggingface.co/nlp4good/psych-search/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/nlp4good/psych-search/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/4a6fc3ad007c72a596ffe4cf1d5dfa0fa19dbb098481747e6757d602eedc30c3.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
            "loading file https://huggingface.co/nlp4good/psych-search/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/a861b08ab06b2a37194482cab468fe6bdfa40d1d760b4ae79744356068b102d7.e096ff0acc3183b627fd32953445a2a87dcb1eb6082c2897afd3dbb797efb7ba\n",
            "loading configuration file https://huggingface.co/nlp4good/psych-search/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/a42c5e0dd944d4c0f84302cc85db6e659bc597e8a136b4dfb3d89050b0f4d87b.f7ba9a920664090c977953cde41ea6bc638ce420772a754c2ed95eabb530437d\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"nlp4good/psych-search\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "loading configuration file https://huggingface.co/nlp4good/psych-search/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/a42c5e0dd944d4c0f84302cc85db6e659bc597e8a136b4dfb3d89050b0f4d87b.f7ba9a920664090c977953cde41ea6bc638ce420772a754c2ed95eabb530437d\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"allenai/scibert_scivocab_uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/nlp4good/psych-search/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/21798e87574f2b37c028397e50c0c48cfe13782c956dff552da851fc5529b72a.40462569c9b9f3a2812ab87853c873a9d14cdbb8d5170beb3a233440985753fa\n",
            "Some weights of the model checkpoint at nlp4good/psych-search were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at nlp4good/psych-search and are newly initialized: ['classifier.weight', 'classifier.bias', 'bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 801\n",
            "  Num Epochs = 27\n",
            "  Instantaneous batch size per device = 2\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 16\n",
            "  Total optimization steps = 675\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='675' max='675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [675/675 39:48, Epoch 26/27]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.628395</td>\n",
              "      <td>0.641791</td>\n",
              "      <td>0.537500</td>\n",
              "      <td>0.551282</td>\n",
              "      <td>0.544304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.586052</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.563218</td>\n",
              "      <td>0.628205</td>\n",
              "      <td>0.593939</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.545722</td>\n",
              "      <td>0.741294</td>\n",
              "      <td>0.651163</td>\n",
              "      <td>0.717949</td>\n",
              "      <td>0.682927</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.754052</td>\n",
              "      <td>0.746269</td>\n",
              "      <td>0.648352</td>\n",
              "      <td>0.756410</td>\n",
              "      <td>0.698225</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.833784</td>\n",
              "      <td>0.741294</td>\n",
              "      <td>0.618182</td>\n",
              "      <td>0.871795</td>\n",
              "      <td>0.723404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.920709</td>\n",
              "      <td>0.736318</td>\n",
              "      <td>0.634409</td>\n",
              "      <td>0.756410</td>\n",
              "      <td>0.690058</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>175</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.079493</td>\n",
              "      <td>0.756219</td>\n",
              "      <td>0.670588</td>\n",
              "      <td>0.730769</td>\n",
              "      <td>0.699387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.161939</td>\n",
              "      <td>0.716418</td>\n",
              "      <td>0.603960</td>\n",
              "      <td>0.782051</td>\n",
              "      <td>0.681564</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>225</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.040186</td>\n",
              "      <td>0.751244</td>\n",
              "      <td>0.652174</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.705882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.356008</td>\n",
              "      <td>0.726368</td>\n",
              "      <td>0.611650</td>\n",
              "      <td>0.807692</td>\n",
              "      <td>0.696133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>275</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.291128</td>\n",
              "      <td>0.771144</td>\n",
              "      <td>0.663265</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.738636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.111077</td>\n",
              "      <td>0.756219</td>\n",
              "      <td>0.652632</td>\n",
              "      <td>0.794872</td>\n",
              "      <td>0.716763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>325</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.314186</td>\n",
              "      <td>0.721393</td>\n",
              "      <td>0.634146</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.650000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.629958</td>\n",
              "      <td>0.721393</td>\n",
              "      <td>0.598214</td>\n",
              "      <td>0.858974</td>\n",
              "      <td>0.705263</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>375</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.272168</td>\n",
              "      <td>0.751244</td>\n",
              "      <td>0.659091</td>\n",
              "      <td>0.743590</td>\n",
              "      <td>0.698795</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.308807</td>\n",
              "      <td>0.786070</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>0.705128</td>\n",
              "      <td>0.718954</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>425</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.438022</td>\n",
              "      <td>0.756219</td>\n",
              "      <td>0.679012</td>\n",
              "      <td>0.705128</td>\n",
              "      <td>0.691824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.504270</td>\n",
              "      <td>0.741294</td>\n",
              "      <td>0.620370</td>\n",
              "      <td>0.858974</td>\n",
              "      <td>0.720430</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>475</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.494804</td>\n",
              "      <td>0.736318</td>\n",
              "      <td>0.631579</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.693642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.130400</td>\n",
              "      <td>1.532328</td>\n",
              "      <td>0.751244</td>\n",
              "      <td>0.652174</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.705882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>525</td>\n",
              "      <td>0.130400</td>\n",
              "      <td>1.523623</td>\n",
              "      <td>0.751244</td>\n",
              "      <td>0.655556</td>\n",
              "      <td>0.756410</td>\n",
              "      <td>0.702381</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.130400</td>\n",
              "      <td>1.494695</td>\n",
              "      <td>0.756219</td>\n",
              "      <td>0.659341</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.710059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>575</td>\n",
              "      <td>0.130400</td>\n",
              "      <td>1.513623</td>\n",
              "      <td>0.751244</td>\n",
              "      <td>0.642857</td>\n",
              "      <td>0.807692</td>\n",
              "      <td>0.715909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.130400</td>\n",
              "      <td>1.514011</td>\n",
              "      <td>0.766169</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.794872</td>\n",
              "      <td>0.725146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>625</td>\n",
              "      <td>0.130400</td>\n",
              "      <td>1.526485</td>\n",
              "      <td>0.761194</td>\n",
              "      <td>0.659574</td>\n",
              "      <td>0.794872</td>\n",
              "      <td>0.720930</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>0.130400</td>\n",
              "      <td>1.536294</td>\n",
              "      <td>0.766169</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.794872</td>\n",
              "      <td>0.725146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>675</td>\n",
              "      <td>0.130400</td>\n",
              "      <td>1.543270</td>\n",
              "      <td>0.766169</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.794872</td>\n",
              "      <td>0.725146</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "Saving model checkpoint to output/checkpoint-500\n",
            "Configuration saved in output/checkpoint-500/config.json\n",
            "Model weights saved in output/checkpoint-500/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from output/checkpoint-500 (score: 1.532327651977539).\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='101' max='101' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [101/101 00:07]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file https://huggingface.co/nlp4good/psych-search/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/daeea662c4b48e2b660049ca9c884af1818b56fa516e63fe8d4674fbd72c421c.38339d84e6e392addd730fd85fae32652c4cc7c5423633d6fa73e5f7937bbc38\n",
            "loading file https://huggingface.co/nlp4good/psych-search/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/nlp4good/psych-search/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/4a6fc3ad007c72a596ffe4cf1d5dfa0fa19dbb098481747e6757d602eedc30c3.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
            "loading file https://huggingface.co/nlp4good/psych-search/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/a861b08ab06b2a37194482cab468fe6bdfa40d1d760b4ae79744356068b102d7.e096ff0acc3183b627fd32953445a2a87dcb1eb6082c2897afd3dbb797efb7ba\n",
            "loading configuration file https://huggingface.co/nlp4good/psych-search/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/a42c5e0dd944d4c0f84302cc85db6e659bc597e8a136b4dfb3d89050b0f4d87b.f7ba9a920664090c977953cde41ea6bc638ce420772a754c2ed95eabb530437d\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"nlp4good/psych-search\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "loading configuration file https://huggingface.co/nlp4good/psych-search/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/a42c5e0dd944d4c0f84302cc85db6e659bc597e8a136b4dfb3d89050b0f4d87b.f7ba9a920664090c977953cde41ea6bc638ce420772a754c2ed95eabb530437d\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"allenai/scibert_scivocab_uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/nlp4good/psych-search/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/21798e87574f2b37c028397e50c0c48cfe13782c956dff552da851fc5529b72a.40462569c9b9f3a2812ab87853c873a9d14cdbb8d5170beb3a233440985753fa\n",
            "Some weights of the model checkpoint at nlp4good/psych-search were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at nlp4good/psych-search and are newly initialized: ['classifier.weight', 'classifier.bias', 'bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 801\n",
            "  Num Epochs = 30\n",
            "  Instantaneous batch size per device = 2\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 16\n",
            "  Total optimization steps = 750\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='725' max='750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [725/750 42:44 < 01:28, 0.28 it/s, Epoch 28/30]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.628971</td>\n",
              "      <td>0.641791</td>\n",
              "      <td>0.650000</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.265306</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.689730</td>\n",
              "      <td>0.557214</td>\n",
              "      <td>0.460432</td>\n",
              "      <td>0.820513</td>\n",
              "      <td>0.589862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.528945</td>\n",
              "      <td>0.746269</td>\n",
              "      <td>0.651685</td>\n",
              "      <td>0.743590</td>\n",
              "      <td>0.694611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.743189</td>\n",
              "      <td>0.741294</td>\n",
              "      <td>0.647727</td>\n",
              "      <td>0.730769</td>\n",
              "      <td>0.686747</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.853859</td>\n",
              "      <td>0.731343</td>\n",
              "      <td>0.611111</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>0.709677</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.264154</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.544715</td>\n",
              "      <td>0.858974</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>175</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.008084</td>\n",
              "      <td>0.751244</td>\n",
              "      <td>0.637255</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.722222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.283704</td>\n",
              "      <td>0.751244</td>\n",
              "      <td>0.634615</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>0.725275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>225</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.054519</td>\n",
              "      <td>0.756219</td>\n",
              "      <td>0.655914</td>\n",
              "      <td>0.782051</td>\n",
              "      <td>0.713450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.479467</td>\n",
              "      <td>0.696517</td>\n",
              "      <td>0.573913</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>0.683938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>275</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.265295</td>\n",
              "      <td>0.756219</td>\n",
              "      <td>0.646465</td>\n",
              "      <td>0.820513</td>\n",
              "      <td>0.723164</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.251841</td>\n",
              "      <td>0.741294</td>\n",
              "      <td>0.627451</td>\n",
              "      <td>0.820513</td>\n",
              "      <td>0.711111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>325</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.315131</td>\n",
              "      <td>0.761194</td>\n",
              "      <td>0.650000</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.730337</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.349581</td>\n",
              "      <td>0.741294</td>\n",
              "      <td>0.630000</td>\n",
              "      <td>0.807692</td>\n",
              "      <td>0.707865</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>375</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.351936</td>\n",
              "      <td>0.776119</td>\n",
              "      <td>0.689655</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.727273</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.471980</td>\n",
              "      <td>0.766169</td>\n",
              "      <td>0.718310</td>\n",
              "      <td>0.653846</td>\n",
              "      <td>0.684564</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>425</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.617712</td>\n",
              "      <td>0.741294</td>\n",
              "      <td>0.622642</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>0.717391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.806626</td>\n",
              "      <td>0.696517</td>\n",
              "      <td>0.572650</td>\n",
              "      <td>0.858974</td>\n",
              "      <td>0.687179</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>475</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.415528</td>\n",
              "      <td>0.786070</td>\n",
              "      <td>0.705882</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.736196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.135800</td>\n",
              "      <td>1.573338</td>\n",
              "      <td>0.741294</td>\n",
              "      <td>0.627451</td>\n",
              "      <td>0.820513</td>\n",
              "      <td>0.711111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>525</td>\n",
              "      <td>0.135800</td>\n",
              "      <td>1.536512</td>\n",
              "      <td>0.761194</td>\n",
              "      <td>0.659574</td>\n",
              "      <td>0.794872</td>\n",
              "      <td>0.720930</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.135800</td>\n",
              "      <td>1.671811</td>\n",
              "      <td>0.721393</td>\n",
              "      <td>0.603774</td>\n",
              "      <td>0.820513</td>\n",
              "      <td>0.695652</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>575</td>\n",
              "      <td>0.135800</td>\n",
              "      <td>1.904194</td>\n",
              "      <td>0.706468</td>\n",
              "      <td>0.585586</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.687831</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.135800</td>\n",
              "      <td>1.552672</td>\n",
              "      <td>0.761194</td>\n",
              "      <td>0.656250</td>\n",
              "      <td>0.807692</td>\n",
              "      <td>0.724138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>625</td>\n",
              "      <td>0.135800</td>\n",
              "      <td>1.682290</td>\n",
              "      <td>0.736318</td>\n",
              "      <td>0.621359</td>\n",
              "      <td>0.820513</td>\n",
              "      <td>0.707182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>0.135800</td>\n",
              "      <td>1.564639</td>\n",
              "      <td>0.771144</td>\n",
              "      <td>0.673913</td>\n",
              "      <td>0.794872</td>\n",
              "      <td>0.729412</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>675</td>\n",
              "      <td>0.135800</td>\n",
              "      <td>1.584509</td>\n",
              "      <td>0.751244</td>\n",
              "      <td>0.648936</td>\n",
              "      <td>0.782051</td>\n",
              "      <td>0.709302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.135800</td>\n",
              "      <td>1.589732</td>\n",
              "      <td>0.771144</td>\n",
              "      <td>0.677778</td>\n",
              "      <td>0.782051</td>\n",
              "      <td>0.726190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>725</td>\n",
              "      <td>0.135800</td>\n",
              "      <td>1.592989</td>\n",
              "      <td>0.776119</td>\n",
              "      <td>0.685393</td>\n",
              "      <td>0.782051</td>\n",
              "      <td>0.730539</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "Saving model checkpoint to output/checkpoint-500\n",
            "Configuration saved in output/checkpoint-500/config.json\n",
            "Model weights saved in output/checkpoint-500/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from output/checkpoint-500 (score: 1.5733375549316406).\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='101' max='101' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [101/101 00:07]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file https://huggingface.co/nlp4good/psych-search/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/daeea662c4b48e2b660049ca9c884af1818b56fa516e63fe8d4674fbd72c421c.38339d84e6e392addd730fd85fae32652c4cc7c5423633d6fa73e5f7937bbc38\n",
            "loading file https://huggingface.co/nlp4good/psych-search/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/nlp4good/psych-search/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/4a6fc3ad007c72a596ffe4cf1d5dfa0fa19dbb098481747e6757d602eedc30c3.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
            "loading file https://huggingface.co/nlp4good/psych-search/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/a861b08ab06b2a37194482cab468fe6bdfa40d1d760b4ae79744356068b102d7.e096ff0acc3183b627fd32953445a2a87dcb1eb6082c2897afd3dbb797efb7ba\n",
            "loading configuration file https://huggingface.co/nlp4good/psych-search/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/a42c5e0dd944d4c0f84302cc85db6e659bc597e8a136b4dfb3d89050b0f4d87b.f7ba9a920664090c977953cde41ea6bc638ce420772a754c2ed95eabb530437d\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"nlp4good/psych-search\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "loading configuration file https://huggingface.co/nlp4good/psych-search/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/a42c5e0dd944d4c0f84302cc85db6e659bc597e8a136b4dfb3d89050b0f4d87b.f7ba9a920664090c977953cde41ea6bc638ce420772a754c2ed95eabb530437d\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"allenai/scibert_scivocab_uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/nlp4good/psych-search/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/21798e87574f2b37c028397e50c0c48cfe13782c956dff552da851fc5529b72a.40462569c9b9f3a2812ab87853c873a9d14cdbb8d5170beb3a233440985753fa\n",
            "Some weights of the model checkpoint at nlp4good/psych-search were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at nlp4good/psych-search and are newly initialized: ['classifier.weight', 'classifier.bias', 'bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 801\n",
            "  Num Epochs = 33\n",
            "  Instantaneous batch size per device = 2\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 16\n",
            "  Total optimization steps = 825\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='650' max='825' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [650/825 38:18 < 10:20, 0.28 it/s, Epoch 25/33]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.635564</td>\n",
              "      <td>0.671642</td>\n",
              "      <td>0.772727</td>\n",
              "      <td>0.217949</td>\n",
              "      <td>0.340000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.583718</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.557895</td>\n",
              "      <td>0.679487</td>\n",
              "      <td>0.612717</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.607982</td>\n",
              "      <td>0.681592</td>\n",
              "      <td>0.557377</td>\n",
              "      <td>0.871795</td>\n",
              "      <td>0.680000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.995524</td>\n",
              "      <td>0.661692</td>\n",
              "      <td>0.535211</td>\n",
              "      <td>0.974359</td>\n",
              "      <td>0.690909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.896037</td>\n",
              "      <td>0.696517</td>\n",
              "      <td>0.564885</td>\n",
              "      <td>0.948718</td>\n",
              "      <td>0.708134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.511101</td>\n",
              "      <td>0.601990</td>\n",
              "      <td>0.493506</td>\n",
              "      <td>0.974359</td>\n",
              "      <td>0.655172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>175</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.840321</td>\n",
              "      <td>0.756219</td>\n",
              "      <td>0.640777</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>0.729282</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.972534</td>\n",
              "      <td>0.731343</td>\n",
              "      <td>0.607143</td>\n",
              "      <td>0.871795</td>\n",
              "      <td>0.715789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>225</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.010618</td>\n",
              "      <td>0.761194</td>\n",
              "      <td>0.659574</td>\n",
              "      <td>0.794872</td>\n",
              "      <td>0.720930</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.163429</td>\n",
              "      <td>0.751244</td>\n",
              "      <td>0.627273</td>\n",
              "      <td>0.884615</td>\n",
              "      <td>0.734043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>275</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.106145</td>\n",
              "      <td>0.741294</td>\n",
              "      <td>0.614035</td>\n",
              "      <td>0.897436</td>\n",
              "      <td>0.729167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.129130</td>\n",
              "      <td>0.746269</td>\n",
              "      <td>0.628571</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>0.721311</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>325</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.220271</td>\n",
              "      <td>0.766169</td>\n",
              "      <td>0.650485</td>\n",
              "      <td>0.858974</td>\n",
              "      <td>0.740331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.994278</td>\n",
              "      <td>0.761194</td>\n",
              "      <td>0.647059</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>0.733333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>375</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.189458</td>\n",
              "      <td>0.741294</td>\n",
              "      <td>0.614035</td>\n",
              "      <td>0.897436</td>\n",
              "      <td>0.729167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.069999</td>\n",
              "      <td>0.766169</td>\n",
              "      <td>0.678161</td>\n",
              "      <td>0.756410</td>\n",
              "      <td>0.715152</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>425</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.356536</td>\n",
              "      <td>0.781095</td>\n",
              "      <td>0.688889</td>\n",
              "      <td>0.794872</td>\n",
              "      <td>0.738095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.283315</td>\n",
              "      <td>0.746269</td>\n",
              "      <td>0.626168</td>\n",
              "      <td>0.858974</td>\n",
              "      <td>0.724324</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>475</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.742636</td>\n",
              "      <td>0.681592</td>\n",
              "      <td>0.551471</td>\n",
              "      <td>0.961538</td>\n",
              "      <td>0.700935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.170200</td>\n",
              "      <td>1.468855</td>\n",
              "      <td>0.761194</td>\n",
              "      <td>0.641509</td>\n",
              "      <td>0.871795</td>\n",
              "      <td>0.739130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>525</td>\n",
              "      <td>0.170200</td>\n",
              "      <td>1.301853</td>\n",
              "      <td>0.756219</td>\n",
              "      <td>0.643564</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.726257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.170200</td>\n",
              "      <td>1.982366</td>\n",
              "      <td>0.671642</td>\n",
              "      <td>0.544118</td>\n",
              "      <td>0.948718</td>\n",
              "      <td>0.691589</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>575</td>\n",
              "      <td>0.170200</td>\n",
              "      <td>1.361242</td>\n",
              "      <td>0.756219</td>\n",
              "      <td>0.652632</td>\n",
              "      <td>0.794872</td>\n",
              "      <td>0.716763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.170200</td>\n",
              "      <td>1.564434</td>\n",
              "      <td>0.716418</td>\n",
              "      <td>0.588235</td>\n",
              "      <td>0.897436</td>\n",
              "      <td>0.710660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>625</td>\n",
              "      <td>0.170200</td>\n",
              "      <td>1.496994</td>\n",
              "      <td>0.761194</td>\n",
              "      <td>0.650000</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.730337</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>0.170200</td>\n",
              "      <td>1.475355</td>\n",
              "      <td>0.756219</td>\n",
              "      <td>0.652632</td>\n",
              "      <td>0.794872</td>\n",
              "      <td>0.716763</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "Saving model checkpoint to output/checkpoint-500\n",
            "Configuration saved in output/checkpoint-500/config.json\n",
            "Model weights saved in output/checkpoint-500/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from output/checkpoint-500 (score: 1.4688547849655151).\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='101' max='101' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [101/101 00:07]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file https://huggingface.co/nlp4good/psych-search/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/daeea662c4b48e2b660049ca9c884af1818b56fa516e63fe8d4674fbd72c421c.38339d84e6e392addd730fd85fae32652c4cc7c5423633d6fa73e5f7937bbc38\n",
            "loading file https://huggingface.co/nlp4good/psych-search/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/nlp4good/psych-search/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/4a6fc3ad007c72a596ffe4cf1d5dfa0fa19dbb098481747e6757d602eedc30c3.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
            "loading file https://huggingface.co/nlp4good/psych-search/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/a861b08ab06b2a37194482cab468fe6bdfa40d1d760b4ae79744356068b102d7.e096ff0acc3183b627fd32953445a2a87dcb1eb6082c2897afd3dbb797efb7ba\n",
            "loading configuration file https://huggingface.co/nlp4good/psych-search/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/a42c5e0dd944d4c0f84302cc85db6e659bc597e8a136b4dfb3d89050b0f4d87b.f7ba9a920664090c977953cde41ea6bc638ce420772a754c2ed95eabb530437d\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"nlp4good/psych-search\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "loading configuration file https://huggingface.co/nlp4good/psych-search/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/a42c5e0dd944d4c0f84302cc85db6e659bc597e8a136b4dfb3d89050b0f4d87b.f7ba9a920664090c977953cde41ea6bc638ce420772a754c2ed95eabb530437d\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"allenai/scibert_scivocab_uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/nlp4good/psych-search/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/21798e87574f2b37c028397e50c0c48cfe13782c956dff552da851fc5529b72a.40462569c9b9f3a2812ab87853c873a9d14cdbb8d5170beb3a233440985753fa\n",
            "Some weights of the model checkpoint at nlp4good/psych-search were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at nlp4good/psych-search and are newly initialized: ['classifier.weight', 'classifier.bias', 'bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 801\n",
            "  Num Epochs = 36\n",
            "  Instantaneous batch size per device = 2\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 16\n",
            "  Total optimization steps = 900\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='575' max='900' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [575/900 33:53 < 19:13, 0.28 it/s, Epoch 22/36]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.595858</td>\n",
              "      <td>0.711443</td>\n",
              "      <td>0.661290</td>\n",
              "      <td>0.525641</td>\n",
              "      <td>0.585714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.549147</td>\n",
              "      <td>0.716418</td>\n",
              "      <td>0.623529</td>\n",
              "      <td>0.679487</td>\n",
              "      <td>0.650307</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.563924</td>\n",
              "      <td>0.731343</td>\n",
              "      <td>0.642857</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.830835</td>\n",
              "      <td>0.716418</td>\n",
              "      <td>0.606061</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.677966</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.894190</td>\n",
              "      <td>0.726368</td>\n",
              "      <td>0.613861</td>\n",
              "      <td>0.794872</td>\n",
              "      <td>0.692737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.941738</td>\n",
              "      <td>0.746269</td>\n",
              "      <td>0.658824</td>\n",
              "      <td>0.717949</td>\n",
              "      <td>0.687117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>175</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.256403</td>\n",
              "      <td>0.731343</td>\n",
              "      <td>0.615385</td>\n",
              "      <td>0.820513</td>\n",
              "      <td>0.703297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.178726</td>\n",
              "      <td>0.746269</td>\n",
              "      <td>0.639175</td>\n",
              "      <td>0.794872</td>\n",
              "      <td>0.708571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>225</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.235564</td>\n",
              "      <td>0.736318</td>\n",
              "      <td>0.623762</td>\n",
              "      <td>0.807692</td>\n",
              "      <td>0.703911</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.289490</td>\n",
              "      <td>0.741294</td>\n",
              "      <td>0.618182</td>\n",
              "      <td>0.871795</td>\n",
              "      <td>0.723404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>275</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.357250</td>\n",
              "      <td>0.736318</td>\n",
              "      <td>0.623762</td>\n",
              "      <td>0.807692</td>\n",
              "      <td>0.703911</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.364642</td>\n",
              "      <td>0.756219</td>\n",
              "      <td>0.655914</td>\n",
              "      <td>0.782051</td>\n",
              "      <td>0.713450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>325</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.297734</td>\n",
              "      <td>0.781095</td>\n",
              "      <td>0.680851</td>\n",
              "      <td>0.820513</td>\n",
              "      <td>0.744186</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.554619</td>\n",
              "      <td>0.716418</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.807692</td>\n",
              "      <td>0.688525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>375</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.637428</td>\n",
              "      <td>0.711443</td>\n",
              "      <td>0.590909</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.691489</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.369518</td>\n",
              "      <td>0.791045</td>\n",
              "      <td>0.719512</td>\n",
              "      <td>0.756410</td>\n",
              "      <td>0.737500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>425</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.604759</td>\n",
              "      <td>0.741294</td>\n",
              "      <td>0.627451</td>\n",
              "      <td>0.820513</td>\n",
              "      <td>0.711111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.647322</td>\n",
              "      <td>0.731343</td>\n",
              "      <td>0.613208</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.706522</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>475</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.690570</td>\n",
              "      <td>0.726368</td>\n",
              "      <td>0.609524</td>\n",
              "      <td>0.820513</td>\n",
              "      <td>0.699454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.122500</td>\n",
              "      <td>1.451014</td>\n",
              "      <td>0.776119</td>\n",
              "      <td>0.685393</td>\n",
              "      <td>0.782051</td>\n",
              "      <td>0.730539</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>525</td>\n",
              "      <td>0.122500</td>\n",
              "      <td>1.528008</td>\n",
              "      <td>0.761194</td>\n",
              "      <td>0.656250</td>\n",
              "      <td>0.807692</td>\n",
              "      <td>0.724138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.122500</td>\n",
              "      <td>1.558403</td>\n",
              "      <td>0.756219</td>\n",
              "      <td>0.646465</td>\n",
              "      <td>0.820513</td>\n",
              "      <td>0.723164</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>575</td>\n",
              "      <td>0.122500</td>\n",
              "      <td>1.588498</td>\n",
              "      <td>0.736318</td>\n",
              "      <td>0.619048</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.710383</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "Saving model checkpoint to output/checkpoint-500\n",
            "Configuration saved in output/checkpoint-500/config.json\n",
            "Model weights saved in output/checkpoint-500/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from output/checkpoint-500 (score: 1.4510139226913452).\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='101' max='101' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [101/101 00:07]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file https://huggingface.co/nlp4good/psych-search/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/daeea662c4b48e2b660049ca9c884af1818b56fa516e63fe8d4674fbd72c421c.38339d84e6e392addd730fd85fae32652c4cc7c5423633d6fa73e5f7937bbc38\n",
            "loading file https://huggingface.co/nlp4good/psych-search/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/nlp4good/psych-search/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/4a6fc3ad007c72a596ffe4cf1d5dfa0fa19dbb098481747e6757d602eedc30c3.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
            "loading file https://huggingface.co/nlp4good/psych-search/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/a861b08ab06b2a37194482cab468fe6bdfa40d1d760b4ae79744356068b102d7.e096ff0acc3183b627fd32953445a2a87dcb1eb6082c2897afd3dbb797efb7ba\n",
            "loading configuration file https://huggingface.co/nlp4good/psych-search/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/a42c5e0dd944d4c0f84302cc85db6e659bc597e8a136b4dfb3d89050b0f4d87b.f7ba9a920664090c977953cde41ea6bc638ce420772a754c2ed95eabb530437d\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"nlp4good/psych-search\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "loading configuration file https://huggingface.co/nlp4good/psych-search/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/a42c5e0dd944d4c0f84302cc85db6e659bc597e8a136b4dfb3d89050b0f4d87b.f7ba9a920664090c977953cde41ea6bc638ce420772a754c2ed95eabb530437d\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"allenai/scibert_scivocab_uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/nlp4good/psych-search/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/21798e87574f2b37c028397e50c0c48cfe13782c956dff552da851fc5529b72a.40462569c9b9f3a2812ab87853c873a9d14cdbb8d5170beb3a233440985753fa\n",
            "Some weights of the model checkpoint at nlp4good/psych-search were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at nlp4good/psych-search and are newly initialized: ['classifier.weight', 'classifier.bias', 'bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 801\n",
            "  Num Epochs = 39\n",
            "  Instantaneous batch size per device = 2\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 16\n",
            "  Total optimization steps = 975\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='575' max='975' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [575/975 33:52 < 23:38, 0.28 it/s, Epoch 22/39]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.630247</td>\n",
              "      <td>0.641791</td>\n",
              "      <td>0.537500</td>\n",
              "      <td>0.551282</td>\n",
              "      <td>0.544304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.583872</td>\n",
              "      <td>0.696517</td>\n",
              "      <td>0.589474</td>\n",
              "      <td>0.717949</td>\n",
              "      <td>0.647399</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.542331</td>\n",
              "      <td>0.746269</td>\n",
              "      <td>0.675325</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.670968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.772924</td>\n",
              "      <td>0.731343</td>\n",
              "      <td>0.627660</td>\n",
              "      <td>0.756410</td>\n",
              "      <td>0.686047</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.895234</td>\n",
              "      <td>0.721393</td>\n",
              "      <td>0.601852</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.698925</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.136330</td>\n",
              "      <td>0.691542</td>\n",
              "      <td>0.568966</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>0.680412</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>175</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.066114</td>\n",
              "      <td>0.741294</td>\n",
              "      <td>0.635417</td>\n",
              "      <td>0.782051</td>\n",
              "      <td>0.701149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.084227</td>\n",
              "      <td>0.771144</td>\n",
              "      <td>0.705128</td>\n",
              "      <td>0.705128</td>\n",
              "      <td>0.705128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>225</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.118921</td>\n",
              "      <td>0.771144</td>\n",
              "      <td>0.663265</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.738636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.306214</td>\n",
              "      <td>0.706468</td>\n",
              "      <td>0.590476</td>\n",
              "      <td>0.794872</td>\n",
              "      <td>0.677596</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>275</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.283806</td>\n",
              "      <td>0.746269</td>\n",
              "      <td>0.655172</td>\n",
              "      <td>0.730769</td>\n",
              "      <td>0.690909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.242616</td>\n",
              "      <td>0.731343</td>\n",
              "      <td>0.627660</td>\n",
              "      <td>0.756410</td>\n",
              "      <td>0.686047</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>325</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.329563</td>\n",
              "      <td>0.756219</td>\n",
              "      <td>0.683544</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.687898</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.486500</td>\n",
              "      <td>0.746269</td>\n",
              "      <td>0.645161</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.701754</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>375</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.379683</td>\n",
              "      <td>0.771144</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.717949</td>\n",
              "      <td>0.708861</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.419595</td>\n",
              "      <td>0.766169</td>\n",
              "      <td>0.686747</td>\n",
              "      <td>0.730769</td>\n",
              "      <td>0.708075</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>425</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.482651</td>\n",
              "      <td>0.766169</td>\n",
              "      <td>0.682353</td>\n",
              "      <td>0.743590</td>\n",
              "      <td>0.711656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.633445</td>\n",
              "      <td>0.726368</td>\n",
              "      <td>0.605505</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>0.705882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>475</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.518101</td>\n",
              "      <td>0.746269</td>\n",
              "      <td>0.636364</td>\n",
              "      <td>0.807692</td>\n",
              "      <td>0.711864</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.130500</td>\n",
              "      <td>1.447289</td>\n",
              "      <td>0.771144</td>\n",
              "      <td>0.690476</td>\n",
              "      <td>0.743590</td>\n",
              "      <td>0.716049</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>525</td>\n",
              "      <td>0.130500</td>\n",
              "      <td>1.562418</td>\n",
              "      <td>0.761194</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.714286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.130500</td>\n",
              "      <td>1.593702</td>\n",
              "      <td>0.761194</td>\n",
              "      <td>0.663043</td>\n",
              "      <td>0.782051</td>\n",
              "      <td>0.717647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>575</td>\n",
              "      <td>0.130500</td>\n",
              "      <td>1.593101</td>\n",
              "      <td>0.751244</td>\n",
              "      <td>0.642857</td>\n",
              "      <td>0.807692</td>\n",
              "      <td>0.715909</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "Saving model checkpoint to output/checkpoint-500\n",
            "Configuration saved in output/checkpoint-500/config.json\n",
            "Model weights saved in output/checkpoint-500/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from output/checkpoint-500 (score: 1.447288990020752).\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='101' max='101' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [101/101 00:07]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file https://huggingface.co/nlp4good/psych-search/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/daeea662c4b48e2b660049ca9c884af1818b56fa516e63fe8d4674fbd72c421c.38339d84e6e392addd730fd85fae32652c4cc7c5423633d6fa73e5f7937bbc38\n",
            "loading file https://huggingface.co/nlp4good/psych-search/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/nlp4good/psych-search/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/4a6fc3ad007c72a596ffe4cf1d5dfa0fa19dbb098481747e6757d602eedc30c3.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
            "loading file https://huggingface.co/nlp4good/psych-search/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/a861b08ab06b2a37194482cab468fe6bdfa40d1d760b4ae79744356068b102d7.e096ff0acc3183b627fd32953445a2a87dcb1eb6082c2897afd3dbb797efb7ba\n",
            "loading configuration file https://huggingface.co/nlp4good/psych-search/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/a42c5e0dd944d4c0f84302cc85db6e659bc597e8a136b4dfb3d89050b0f4d87b.f7ba9a920664090c977953cde41ea6bc638ce420772a754c2ed95eabb530437d\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"nlp4good/psych-search\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "loading configuration file https://huggingface.co/nlp4good/psych-search/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/a42c5e0dd944d4c0f84302cc85db6e659bc597e8a136b4dfb3d89050b0f4d87b.f7ba9a920664090c977953cde41ea6bc638ce420772a754c2ed95eabb530437d\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"allenai/scibert_scivocab_uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/nlp4good/psych-search/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/21798e87574f2b37c028397e50c0c48cfe13782c956dff552da851fc5529b72a.40462569c9b9f3a2812ab87853c873a9d14cdbb8d5170beb3a233440985753fa\n",
            "Some weights of the model checkpoint at nlp4good/psych-search were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at nlp4good/psych-search and are newly initialized: ['classifier.weight', 'classifier.bias', 'bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 801\n",
            "  Num Epochs = 42\n",
            "  Instantaneous batch size per device = 2\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 16\n",
            "  Total optimization steps = 1050\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='660' max='1050' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 660/1050 38:37 < 22:53, 0.28 it/s, Epoch 26.36/42]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.630840</td>\n",
              "      <td>0.636816</td>\n",
              "      <td>0.530864</td>\n",
              "      <td>0.551282</td>\n",
              "      <td>0.540881</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.568611</td>\n",
              "      <td>0.686567</td>\n",
              "      <td>0.586207</td>\n",
              "      <td>0.653846</td>\n",
              "      <td>0.618182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.531124</td>\n",
              "      <td>0.736318</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.641026</td>\n",
              "      <td>0.653595</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.809213</td>\n",
              "      <td>0.731343</td>\n",
              "      <td>0.627660</td>\n",
              "      <td>0.756410</td>\n",
              "      <td>0.686047</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.923999</td>\n",
              "      <td>0.731343</td>\n",
              "      <td>0.617647</td>\n",
              "      <td>0.807692</td>\n",
              "      <td>0.700000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.361375</td>\n",
              "      <td>0.646766</td>\n",
              "      <td>0.527559</td>\n",
              "      <td>0.858974</td>\n",
              "      <td>0.653659</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>175</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.165870</td>\n",
              "      <td>0.761194</td>\n",
              "      <td>0.687500</td>\n",
              "      <td>0.705128</td>\n",
              "      <td>0.696203</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.133297</td>\n",
              "      <td>0.751244</td>\n",
              "      <td>0.675000</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.683544</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>225</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.103261</td>\n",
              "      <td>0.726368</td>\n",
              "      <td>0.626374</td>\n",
              "      <td>0.730769</td>\n",
              "      <td>0.674556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.358454</td>\n",
              "      <td>0.751244</td>\n",
              "      <td>0.648936</td>\n",
              "      <td>0.782051</td>\n",
              "      <td>0.709302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>275</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.406191</td>\n",
              "      <td>0.726368</td>\n",
              "      <td>0.632184</td>\n",
              "      <td>0.705128</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.221286</td>\n",
              "      <td>0.761194</td>\n",
              "      <td>0.702703</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.684211</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>325</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.535769</td>\n",
              "      <td>0.721393</td>\n",
              "      <td>0.641026</td>\n",
              "      <td>0.641026</td>\n",
              "      <td>0.641026</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.576302</td>\n",
              "      <td>0.761194</td>\n",
              "      <td>0.644231</td>\n",
              "      <td>0.858974</td>\n",
              "      <td>0.736264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>375</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.373623</td>\n",
              "      <td>0.761194</td>\n",
              "      <td>0.663043</td>\n",
              "      <td>0.782051</td>\n",
              "      <td>0.717647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.504848</td>\n",
              "      <td>0.766169</td>\n",
              "      <td>0.724638</td>\n",
              "      <td>0.641026</td>\n",
              "      <td>0.680272</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>425</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.569316</td>\n",
              "      <td>0.771144</td>\n",
              "      <td>0.695122</td>\n",
              "      <td>0.730769</td>\n",
              "      <td>0.712500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.615117</td>\n",
              "      <td>0.756219</td>\n",
              "      <td>0.640777</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>0.729282</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>475</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.660719</td>\n",
              "      <td>0.726368</td>\n",
              "      <td>0.603604</td>\n",
              "      <td>0.858974</td>\n",
              "      <td>0.708995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.135400</td>\n",
              "      <td>1.659510</td>\n",
              "      <td>0.751244</td>\n",
              "      <td>0.679487</td>\n",
              "      <td>0.679487</td>\n",
              "      <td>0.679487</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>525</td>\n",
              "      <td>0.135400</td>\n",
              "      <td>1.639832</td>\n",
              "      <td>0.721393</td>\n",
              "      <td>0.612245</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.681818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.135400</td>\n",
              "      <td>1.635321</td>\n",
              "      <td>0.726368</td>\n",
              "      <td>0.621053</td>\n",
              "      <td>0.756410</td>\n",
              "      <td>0.682081</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>575</td>\n",
              "      <td>0.135400</td>\n",
              "      <td>1.592095</td>\n",
              "      <td>0.736318</td>\n",
              "      <td>0.619048</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.710383</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.135400</td>\n",
              "      <td>1.635808</td>\n",
              "      <td>0.741294</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.714286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>625</td>\n",
              "      <td>0.135400</td>\n",
              "      <td>1.694525</td>\n",
              "      <td>0.731343</td>\n",
              "      <td>0.620000</td>\n",
              "      <td>0.794872</td>\n",
              "      <td>0.696629</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>0.135400</td>\n",
              "      <td>1.682618</td>\n",
              "      <td>0.736318</td>\n",
              "      <td>0.631579</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.693642</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "Saving model checkpoint to output/checkpoint-500\n",
            "Configuration saved in output/checkpoint-500/config.json\n",
            "Model weights saved in output/checkpoint-500/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-9d9f70e6404e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m   ) \n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m   \u001b[0mtrainer_psy_tmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m   \u001b[0mtmp_eval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer_psy_tmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0mrecall_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_eval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eval_recall'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1398\u001b[0m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1399\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1400\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1402\u001b[0m                 if (\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2000\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepspeed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2001\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2002\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2004\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(range(3,42,3),recall_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "r4vMpnt8Gg8h",
        "outputId": "57a68dee-4417-4001-9024-c90b8a196acd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fd548e657d0>]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(max(recall_list))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOvlPKyjj6BI",
        "outputId": "c64c208f-74ed-4fb8-ad23-7bd334b1ee66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8717948717948718\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sci_epoch_range = range(3,31,3)\n",
        "sci_recall_list = []\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for i in sci_epoch_range:\n",
        "\n",
        "  tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "  model = BertForSequenceClassification.from_pretrained(model_name,num_labels =2 )\n",
        "\n",
        "\n",
        "  \n",
        "  args = TrainingArguments(\n",
        "      output_dir=\"output\",\n",
        "      evaluation_strategy=\"steps\",\n",
        "      eval_steps=25,\n",
        "      per_device_train_batch_size=2,\n",
        "      per_device_eval_batch_size=2,\n",
        "      num_train_epochs=i,\n",
        "      seed=0,\n",
        "      load_best_model_at_end=True,\n",
        "      overwrite_output_dir=True,\n",
        "      learning_rate=3e-5,\n",
        "      gradient_accumulation_steps=16\n",
        "  )\n",
        "\n",
        "  trainer_sci_tmp = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
        "  ) \n",
        "\n",
        "  trainer_sci_tmp.train()\n",
        "  tmp_eval = trainer_sci_tmp.evaluate()\n",
        "  sci_recall_list.append(tmp_eval['eval_recall'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "08kq--sHkV3V",
        "outputId": "3472a51d-14bb-4bc1-f4d5-7d567b18720b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 801\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 2\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 16\n",
            "  Total optimization steps = 75\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='75' max='75' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [75/75 02:41, Epoch 2/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.616511</td>\n",
              "      <td>0.636816</td>\n",
              "      <td>0.580645</td>\n",
              "      <td>0.433735</td>\n",
              "      <td>0.496552</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.594900</td>\n",
              "      <td>0.671642</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.819277</td>\n",
              "      <td>0.673267</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.550046</td>\n",
              "      <td>0.711443</td>\n",
              "      <td>0.654321</td>\n",
              "      <td>0.638554</td>\n",
              "      <td>0.646341</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='101' max='101' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [101/101 00:04]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/33593020f507d72099bd84ea6cd2296feb424fecd62d4a8edcc2a02899af6e29.38339d84e6e392addd730fd85fae32652c4cc7c5423633d6fa73e5f7937bbc38\n",
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/tokenizer_config.json from cache at None\n",
            "loading configuration file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/858852fd2471ce39075378592ddc87f5a6551e64c6825d1b92c8dab9318e0fc3.03ff9e9f998b9a9d40647a2148a202e3fb3d568dc0f170dda9dda194bab4d5dd\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"allenai/scibert_scivocab_uncased\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "loading configuration file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/858852fd2471ce39075378592ddc87f5a6551e64c6825d1b92c8dab9318e0fc3.03ff9e9f998b9a9d40647a2148a202e3fb3d568dc0f170dda9dda194bab4d5dd\n",
            "Model config BertConfig {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/de14937a851e8180a2bc5660c0041d385f8a0c62b1b2ccafa46df31043a2390c.74830bb01a0ffcdeaed8be9916312726d0c4cd364ac6fc15b375f789eaff4cbb\n",
            "Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 801\n",
            "  Num Epochs = 6\n",
            "  Instantaneous batch size per device = 2\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 16\n",
            "  Total optimization steps = 150\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='150' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [150/150 05:24, Epoch 5/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.645609</td>\n",
              "      <td>0.592040</td>\n",
              "      <td>0.523810</td>\n",
              "      <td>0.132530</td>\n",
              "      <td>0.211538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.637897</td>\n",
              "      <td>0.621891</td>\n",
              "      <td>0.527132</td>\n",
              "      <td>0.819277</td>\n",
              "      <td>0.641509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.574719</td>\n",
              "      <td>0.681592</td>\n",
              "      <td>0.743590</td>\n",
              "      <td>0.349398</td>\n",
              "      <td>0.475410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.552826</td>\n",
              "      <td>0.741294</td>\n",
              "      <td>0.644860</td>\n",
              "      <td>0.831325</td>\n",
              "      <td>0.726316</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.626575</td>\n",
              "      <td>0.741294</td>\n",
              "      <td>0.642202</td>\n",
              "      <td>0.843373</td>\n",
              "      <td>0.729167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.620787</td>\n",
              "      <td>0.736318</td>\n",
              "      <td>0.647059</td>\n",
              "      <td>0.795181</td>\n",
              "      <td>0.713514</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='101' max='101' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [101/101 00:04]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/33593020f507d72099bd84ea6cd2296feb424fecd62d4a8edcc2a02899af6e29.38339d84e6e392addd730fd85fae32652c4cc7c5423633d6fa73e5f7937bbc38\n",
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/tokenizer_config.json from cache at None\n",
            "loading configuration file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/858852fd2471ce39075378592ddc87f5a6551e64c6825d1b92c8dab9318e0fc3.03ff9e9f998b9a9d40647a2148a202e3fb3d568dc0f170dda9dda194bab4d5dd\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"allenai/scibert_scivocab_uncased\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "loading configuration file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/858852fd2471ce39075378592ddc87f5a6551e64c6825d1b92c8dab9318e0fc3.03ff9e9f998b9a9d40647a2148a202e3fb3d568dc0f170dda9dda194bab4d5dd\n",
            "Model config BertConfig {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/de14937a851e8180a2bc5660c0041d385f8a0c62b1b2ccafa46df31043a2390c.74830bb01a0ffcdeaed8be9916312726d0c4cd364ac6fc15b375f789eaff4cbb\n",
            "Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 801\n",
            "  Num Epochs = 9\n",
            "  Instantaneous batch size per device = 2\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 16\n",
            "  Total optimization steps = 225\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='225' max='225' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [225/225 08:07, Epoch 8/9]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.631577</td>\n",
              "      <td>0.611940</td>\n",
              "      <td>0.522523</td>\n",
              "      <td>0.698795</td>\n",
              "      <td>0.597938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.608117</td>\n",
              "      <td>0.646766</td>\n",
              "      <td>0.546875</td>\n",
              "      <td>0.843373</td>\n",
              "      <td>0.663507</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.579865</td>\n",
              "      <td>0.701493</td>\n",
              "      <td>0.621053</td>\n",
              "      <td>0.710843</td>\n",
              "      <td>0.662921</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.657839</td>\n",
              "      <td>0.671642</td>\n",
              "      <td>0.573913</td>\n",
              "      <td>0.795181</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.722918</td>\n",
              "      <td>0.706468</td>\n",
              "      <td>0.607143</td>\n",
              "      <td>0.819277</td>\n",
              "      <td>0.697436</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.759083</td>\n",
              "      <td>0.731343</td>\n",
              "      <td>0.643564</td>\n",
              "      <td>0.783133</td>\n",
              "      <td>0.706522</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>175</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.875152</td>\n",
              "      <td>0.716418</td>\n",
              "      <td>0.620370</td>\n",
              "      <td>0.807229</td>\n",
              "      <td>0.701571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.861620</td>\n",
              "      <td>0.726368</td>\n",
              "      <td>0.632075</td>\n",
              "      <td>0.807229</td>\n",
              "      <td>0.708995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>225</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.975915</td>\n",
              "      <td>0.701493</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.831325</td>\n",
              "      <td>0.696970</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='101' max='101' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [101/101 00:04]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/33593020f507d72099bd84ea6cd2296feb424fecd62d4a8edcc2a02899af6e29.38339d84e6e392addd730fd85fae32652c4cc7c5423633d6fa73e5f7937bbc38\n",
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/tokenizer_config.json from cache at None\n",
            "loading configuration file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/858852fd2471ce39075378592ddc87f5a6551e64c6825d1b92c8dab9318e0fc3.03ff9e9f998b9a9d40647a2148a202e3fb3d568dc0f170dda9dda194bab4d5dd\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"allenai/scibert_scivocab_uncased\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "loading configuration file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/858852fd2471ce39075378592ddc87f5a6551e64c6825d1b92c8dab9318e0fc3.03ff9e9f998b9a9d40647a2148a202e3fb3d568dc0f170dda9dda194bab4d5dd\n",
            "Model config BertConfig {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/de14937a851e8180a2bc5660c0041d385f8a0c62b1b2ccafa46df31043a2390c.74830bb01a0ffcdeaed8be9916312726d0c4cd364ac6fc15b375f789eaff4cbb\n",
            "Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 801\n",
            "  Num Epochs = 12\n",
            "  Instantaneous batch size per device = 2\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 16\n",
            "  Total optimization steps = 300\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 10:50, Epoch 11/12]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.608811</td>\n",
              "      <td>0.656716</td>\n",
              "      <td>0.568627</td>\n",
              "      <td>0.698795</td>\n",
              "      <td>0.627027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.531065</td>\n",
              "      <td>0.751244</td>\n",
              "      <td>0.698795</td>\n",
              "      <td>0.698795</td>\n",
              "      <td>0.698795</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.550929</td>\n",
              "      <td>0.696517</td>\n",
              "      <td>0.617021</td>\n",
              "      <td>0.698795</td>\n",
              "      <td>0.655367</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.600568</td>\n",
              "      <td>0.746269</td>\n",
              "      <td>0.656863</td>\n",
              "      <td>0.807229</td>\n",
              "      <td>0.724324</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.747919</td>\n",
              "      <td>0.721393</td>\n",
              "      <td>0.617391</td>\n",
              "      <td>0.855422</td>\n",
              "      <td>0.717172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.915270</td>\n",
              "      <td>0.736318</td>\n",
              "      <td>0.633929</td>\n",
              "      <td>0.855422</td>\n",
              "      <td>0.728205</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>175</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.954884</td>\n",
              "      <td>0.736318</td>\n",
              "      <td>0.638889</td>\n",
              "      <td>0.831325</td>\n",
              "      <td>0.722513</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.869182</td>\n",
              "      <td>0.781095</td>\n",
              "      <td>0.767123</td>\n",
              "      <td>0.674699</td>\n",
              "      <td>0.717949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>225</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.037396</td>\n",
              "      <td>0.736318</td>\n",
              "      <td>0.638889</td>\n",
              "      <td>0.831325</td>\n",
              "      <td>0.722513</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.989170</td>\n",
              "      <td>0.736318</td>\n",
              "      <td>0.650000</td>\n",
              "      <td>0.783133</td>\n",
              "      <td>0.710383</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>275</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.142176</td>\n",
              "      <td>0.726368</td>\n",
              "      <td>0.629630</td>\n",
              "      <td>0.819277</td>\n",
              "      <td>0.712042</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.130878</td>\n",
              "      <td>0.731343</td>\n",
              "      <td>0.638095</td>\n",
              "      <td>0.807229</td>\n",
              "      <td>0.712766</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='101' max='101' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [101/101 00:04]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/33593020f507d72099bd84ea6cd2296feb424fecd62d4a8edcc2a02899af6e29.38339d84e6e392addd730fd85fae32652c4cc7c5423633d6fa73e5f7937bbc38\n",
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/tokenizer_config.json from cache at None\n",
            "loading configuration file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/858852fd2471ce39075378592ddc87f5a6551e64c6825d1b92c8dab9318e0fc3.03ff9e9f998b9a9d40647a2148a202e3fb3d568dc0f170dda9dda194bab4d5dd\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"allenai/scibert_scivocab_uncased\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "loading configuration file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/858852fd2471ce39075378592ddc87f5a6551e64c6825d1b92c8dab9318e0fc3.03ff9e9f998b9a9d40647a2148a202e3fb3d568dc0f170dda9dda194bab4d5dd\n",
            "Model config BertConfig {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/de14937a851e8180a2bc5660c0041d385f8a0c62b1b2ccafa46df31043a2390c.74830bb01a0ffcdeaed8be9916312726d0c4cd364ac6fc15b375f789eaff4cbb\n",
            "Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 801\n",
            "  Num Epochs = 15\n",
            "  Instantaneous batch size per device = 2\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 16\n",
            "  Total optimization steps = 375\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='375' max='375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [375/375 13:32, Epoch 14/15]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.623453</td>\n",
              "      <td>0.631841</td>\n",
              "      <td>0.539130</td>\n",
              "      <td>0.746988</td>\n",
              "      <td>0.626263</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.563788</td>\n",
              "      <td>0.706468</td>\n",
              "      <td>0.657895</td>\n",
              "      <td>0.602410</td>\n",
              "      <td>0.628931</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.630781</td>\n",
              "      <td>0.671642</td>\n",
              "      <td>0.579439</td>\n",
              "      <td>0.746988</td>\n",
              "      <td>0.652632</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.560007</td>\n",
              "      <td>0.786070</td>\n",
              "      <td>0.738095</td>\n",
              "      <td>0.746988</td>\n",
              "      <td>0.742515</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.859764</td>\n",
              "      <td>0.706468</td>\n",
              "      <td>0.607143</td>\n",
              "      <td>0.819277</td>\n",
              "      <td>0.697436</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.649138</td>\n",
              "      <td>0.800995</td>\n",
              "      <td>0.794521</td>\n",
              "      <td>0.698795</td>\n",
              "      <td>0.743590</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>175</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.771219</td>\n",
              "      <td>0.776119</td>\n",
              "      <td>0.702128</td>\n",
              "      <td>0.795181</td>\n",
              "      <td>0.745763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.734753</td>\n",
              "      <td>0.805970</td>\n",
              "      <td>0.775000</td>\n",
              "      <td>0.746988</td>\n",
              "      <td>0.760736</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>225</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.009595</td>\n",
              "      <td>0.761194</td>\n",
              "      <td>0.657658</td>\n",
              "      <td>0.879518</td>\n",
              "      <td>0.752577</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.050173</td>\n",
              "      <td>0.731343</td>\n",
              "      <td>0.630631</td>\n",
              "      <td>0.843373</td>\n",
              "      <td>0.721649</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>275</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.403892</td>\n",
              "      <td>0.671642</td>\n",
              "      <td>0.562963</td>\n",
              "      <td>0.915663</td>\n",
              "      <td>0.697248</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.103354</td>\n",
              "      <td>0.751244</td>\n",
              "      <td>0.657143</td>\n",
              "      <td>0.831325</td>\n",
              "      <td>0.734043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>325</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.237804</td>\n",
              "      <td>0.726368</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.843373</td>\n",
              "      <td>0.717949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.165796</td>\n",
              "      <td>0.756219</td>\n",
              "      <td>0.663462</td>\n",
              "      <td>0.831325</td>\n",
              "      <td>0.737968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>375</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.176018</td>\n",
              "      <td>0.751244</td>\n",
              "      <td>0.657143</td>\n",
              "      <td>0.831325</td>\n",
              "      <td>0.734043</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='101' max='101' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [101/101 00:04]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/33593020f507d72099bd84ea6cd2296feb424fecd62d4a8edcc2a02899af6e29.38339d84e6e392addd730fd85fae32652c4cc7c5423633d6fa73e5f7937bbc38\n",
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/tokenizer_config.json from cache at None\n",
            "loading configuration file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/858852fd2471ce39075378592ddc87f5a6551e64c6825d1b92c8dab9318e0fc3.03ff9e9f998b9a9d40647a2148a202e3fb3d568dc0f170dda9dda194bab4d5dd\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"allenai/scibert_scivocab_uncased\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "loading configuration file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/858852fd2471ce39075378592ddc87f5a6551e64c6825d1b92c8dab9318e0fc3.03ff9e9f998b9a9d40647a2148a202e3fb3d568dc0f170dda9dda194bab4d5dd\n",
            "Model config BertConfig {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/de14937a851e8180a2bc5660c0041d385f8a0c62b1b2ccafa46df31043a2390c.74830bb01a0ffcdeaed8be9916312726d0c4cd364ac6fc15b375f789eaff4cbb\n",
            "Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 801\n",
            "  Num Epochs = 18\n",
            "  Instantaneous batch size per device = 2\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 16\n",
            "  Total optimization steps = 450\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='450' max='450' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [450/450 16:14, Epoch 17/18]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.621023</td>\n",
              "      <td>0.656716</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.674699</td>\n",
              "      <td>0.618785</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.579836</td>\n",
              "      <td>0.706468</td>\n",
              "      <td>0.615385</td>\n",
              "      <td>0.771084</td>\n",
              "      <td>0.684492</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.527762</td>\n",
              "      <td>0.781095</td>\n",
              "      <td>0.819672</td>\n",
              "      <td>0.602410</td>\n",
              "      <td>0.694444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.711985</td>\n",
              "      <td>0.716418</td>\n",
              "      <td>0.618182</td>\n",
              "      <td>0.819277</td>\n",
              "      <td>0.704663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.662450</td>\n",
              "      <td>0.746269</td>\n",
              "      <td>0.660000</td>\n",
              "      <td>0.795181</td>\n",
              "      <td>0.721311</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.853177</td>\n",
              "      <td>0.761194</td>\n",
              "      <td>0.710843</td>\n",
              "      <td>0.710843</td>\n",
              "      <td>0.710843</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>175</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.005821</td>\n",
              "      <td>0.741294</td>\n",
              "      <td>0.650485</td>\n",
              "      <td>0.807229</td>\n",
              "      <td>0.720430</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.907926</td>\n",
              "      <td>0.786070</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.722892</td>\n",
              "      <td>0.736196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>225</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.254929</td>\n",
              "      <td>0.711443</td>\n",
              "      <td>0.605042</td>\n",
              "      <td>0.867470</td>\n",
              "      <td>0.712871</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.243197</td>\n",
              "      <td>0.706468</td>\n",
              "      <td>0.601695</td>\n",
              "      <td>0.855422</td>\n",
              "      <td>0.706468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>275</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.716248</td>\n",
              "      <td>0.651741</td>\n",
              "      <td>0.548148</td>\n",
              "      <td>0.891566</td>\n",
              "      <td>0.678899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.453576</td>\n",
              "      <td>0.711443</td>\n",
              "      <td>0.605042</td>\n",
              "      <td>0.867470</td>\n",
              "      <td>0.712871</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>325</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.156547</td>\n",
              "      <td>0.761194</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>0.662651</td>\n",
              "      <td>0.696203</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.251203</td>\n",
              "      <td>0.761194</td>\n",
              "      <td>0.673267</td>\n",
              "      <td>0.819277</td>\n",
              "      <td>0.739130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>375</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.162907</td>\n",
              "      <td>0.746269</td>\n",
              "      <td>0.673913</td>\n",
              "      <td>0.746988</td>\n",
              "      <td>0.708571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.233412</td>\n",
              "      <td>0.756219</td>\n",
              "      <td>0.660377</td>\n",
              "      <td>0.843373</td>\n",
              "      <td>0.740741</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>425</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.177622</td>\n",
              "      <td>0.756219</td>\n",
              "      <td>0.673469</td>\n",
              "      <td>0.795181</td>\n",
              "      <td>0.729282</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.218046</td>\n",
              "      <td>0.751244</td>\n",
              "      <td>0.660194</td>\n",
              "      <td>0.819277</td>\n",
              "      <td>0.731183</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='101' max='101' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [101/101 00:04]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/33593020f507d72099bd84ea6cd2296feb424fecd62d4a8edcc2a02899af6e29.38339d84e6e392addd730fd85fae32652c4cc7c5423633d6fa73e5f7937bbc38\n",
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/tokenizer_config.json from cache at None\n",
            "loading configuration file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/858852fd2471ce39075378592ddc87f5a6551e64c6825d1b92c8dab9318e0fc3.03ff9e9f998b9a9d40647a2148a202e3fb3d568dc0f170dda9dda194bab4d5dd\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"allenai/scibert_scivocab_uncased\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "loading configuration file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/858852fd2471ce39075378592ddc87f5a6551e64c6825d1b92c8dab9318e0fc3.03ff9e9f998b9a9d40647a2148a202e3fb3d568dc0f170dda9dda194bab4d5dd\n",
            "Model config BertConfig {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/de14937a851e8180a2bc5660c0041d385f8a0c62b1b2ccafa46df31043a2390c.74830bb01a0ffcdeaed8be9916312726d0c4cd364ac6fc15b375f789eaff4cbb\n",
            "Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 801\n",
            "  Num Epochs = 21\n",
            "  Instantaneous batch size per device = 2\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 16\n",
            "  Total optimization steps = 525\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [525/525 19:03, Epoch 20/21]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.640644</td>\n",
              "      <td>0.592040</td>\n",
              "      <td>0.513514</td>\n",
              "      <td>0.228916</td>\n",
              "      <td>0.316667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.588663</td>\n",
              "      <td>0.676617</td>\n",
              "      <td>0.591837</td>\n",
              "      <td>0.698795</td>\n",
              "      <td>0.640884</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.536195</td>\n",
              "      <td>0.741294</td>\n",
              "      <td>0.829787</td>\n",
              "      <td>0.469880</td>\n",
              "      <td>0.600000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.622451</td>\n",
              "      <td>0.746269</td>\n",
              "      <td>0.660000</td>\n",
              "      <td>0.795181</td>\n",
              "      <td>0.721311</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.779103</td>\n",
              "      <td>0.761194</td>\n",
              "      <td>0.657658</td>\n",
              "      <td>0.879518</td>\n",
              "      <td>0.752577</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.850402</td>\n",
              "      <td>0.731343</td>\n",
              "      <td>0.638095</td>\n",
              "      <td>0.807229</td>\n",
              "      <td>0.712766</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>175</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.869809</td>\n",
              "      <td>0.781095</td>\n",
              "      <td>0.701031</td>\n",
              "      <td>0.819277</td>\n",
              "      <td>0.755556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.967494</td>\n",
              "      <td>0.756219</td>\n",
              "      <td>0.774194</td>\n",
              "      <td>0.578313</td>\n",
              "      <td>0.662069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>225</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.576949</td>\n",
              "      <td>0.641791</td>\n",
              "      <td>0.538462</td>\n",
              "      <td>0.927711</td>\n",
              "      <td>0.681416</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.983241</td>\n",
              "      <td>0.766169</td>\n",
              "      <td>0.687500</td>\n",
              "      <td>0.795181</td>\n",
              "      <td>0.737430</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>275</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.221730</td>\n",
              "      <td>0.716418</td>\n",
              "      <td>0.608333</td>\n",
              "      <td>0.879518</td>\n",
              "      <td>0.719212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.206536</td>\n",
              "      <td>0.746269</td>\n",
              "      <td>0.640351</td>\n",
              "      <td>0.879518</td>\n",
              "      <td>0.741117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>325</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.126508</td>\n",
              "      <td>0.766169</td>\n",
              "      <td>0.683673</td>\n",
              "      <td>0.807229</td>\n",
              "      <td>0.740331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.192295</td>\n",
              "      <td>0.786070</td>\n",
              "      <td>0.722222</td>\n",
              "      <td>0.783133</td>\n",
              "      <td>0.751445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>375</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.299806</td>\n",
              "      <td>0.741294</td>\n",
              "      <td>0.639640</td>\n",
              "      <td>0.855422</td>\n",
              "      <td>0.731959</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.144311</td>\n",
              "      <td>0.796020</td>\n",
              "      <td>0.723404</td>\n",
              "      <td>0.819277</td>\n",
              "      <td>0.768362</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>425</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.229508</td>\n",
              "      <td>0.786070</td>\n",
              "      <td>0.708333</td>\n",
              "      <td>0.819277</td>\n",
              "      <td>0.759777</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.395584</td>\n",
              "      <td>0.746269</td>\n",
              "      <td>0.640351</td>\n",
              "      <td>0.879518</td>\n",
              "      <td>0.741117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>475</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.404395</td>\n",
              "      <td>0.761194</td>\n",
              "      <td>0.657658</td>\n",
              "      <td>0.879518</td>\n",
              "      <td>0.752577</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.166400</td>\n",
              "      <td>1.327419</td>\n",
              "      <td>0.771144</td>\n",
              "      <td>0.679612</td>\n",
              "      <td>0.843373</td>\n",
              "      <td>0.752688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>525</td>\n",
              "      <td>0.166400</td>\n",
              "      <td>1.354203</td>\n",
              "      <td>0.771144</td>\n",
              "      <td>0.669725</td>\n",
              "      <td>0.879518</td>\n",
              "      <td>0.760417</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "Saving model checkpoint to output/checkpoint-500\n",
            "Configuration saved in output/checkpoint-500/config.json\n",
            "Model weights saved in output/checkpoint-500/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from output/checkpoint-500 (score: 1.327418565750122).\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='101' max='101' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [101/101 00:04]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/33593020f507d72099bd84ea6cd2296feb424fecd62d4a8edcc2a02899af6e29.38339d84e6e392addd730fd85fae32652c4cc7c5423633d6fa73e5f7937bbc38\n",
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/tokenizer_config.json from cache at None\n",
            "loading configuration file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/858852fd2471ce39075378592ddc87f5a6551e64c6825d1b92c8dab9318e0fc3.03ff9e9f998b9a9d40647a2148a202e3fb3d568dc0f170dda9dda194bab4d5dd\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"allenai/scibert_scivocab_uncased\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "loading configuration file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/858852fd2471ce39075378592ddc87f5a6551e64c6825d1b92c8dab9318e0fc3.03ff9e9f998b9a9d40647a2148a202e3fb3d568dc0f170dda9dda194bab4d5dd\n",
            "Model config BertConfig {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/de14937a851e8180a2bc5660c0041d385f8a0c62b1b2ccafa46df31043a2390c.74830bb01a0ffcdeaed8be9916312726d0c4cd364ac6fc15b375f789eaff4cbb\n",
            "Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 801\n",
            "  Num Epochs = 24\n",
            "  Instantaneous batch size per device = 2\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 16\n",
            "  Total optimization steps = 600\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='575' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [575/600 20:56 < 00:54, 0.46 it/s, Epoch 22/24]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.631795</td>\n",
              "      <td>0.616915</td>\n",
              "      <td>0.536585</td>\n",
              "      <td>0.530120</td>\n",
              "      <td>0.533333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.570805</td>\n",
              "      <td>0.696517</td>\n",
              "      <td>0.619565</td>\n",
              "      <td>0.686747</td>\n",
              "      <td>0.651429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.521665</td>\n",
              "      <td>0.741294</td>\n",
              "      <td>0.731343</td>\n",
              "      <td>0.590361</td>\n",
              "      <td>0.653333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.560959</td>\n",
              "      <td>0.751244</td>\n",
              "      <td>0.689655</td>\n",
              "      <td>0.722892</td>\n",
              "      <td>0.705882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.821374</td>\n",
              "      <td>0.711443</td>\n",
              "      <td>0.619048</td>\n",
              "      <td>0.783133</td>\n",
              "      <td>0.691489</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.944500</td>\n",
              "      <td>0.721393</td>\n",
              "      <td>0.633663</td>\n",
              "      <td>0.771084</td>\n",
              "      <td>0.695652</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>175</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.169887</td>\n",
              "      <td>0.721393</td>\n",
              "      <td>0.645161</td>\n",
              "      <td>0.722892</td>\n",
              "      <td>0.681818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.082768</td>\n",
              "      <td>0.781095</td>\n",
              "      <td>0.774648</td>\n",
              "      <td>0.662651</td>\n",
              "      <td>0.714286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>225</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.455410</td>\n",
              "      <td>0.691542</td>\n",
              "      <td>0.586777</td>\n",
              "      <td>0.855422</td>\n",
              "      <td>0.696078</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.210984</td>\n",
              "      <td>0.721393</td>\n",
              "      <td>0.633663</td>\n",
              "      <td>0.771084</td>\n",
              "      <td>0.695652</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>275</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.234695</td>\n",
              "      <td>0.686567</td>\n",
              "      <td>0.589286</td>\n",
              "      <td>0.795181</td>\n",
              "      <td>0.676923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.169923</td>\n",
              "      <td>0.761194</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.759036</td>\n",
              "      <td>0.724138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>325</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.098496</td>\n",
              "      <td>0.761194</td>\n",
              "      <td>0.688172</td>\n",
              "      <td>0.771084</td>\n",
              "      <td>0.727273</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.187578</td>\n",
              "      <td>0.761194</td>\n",
              "      <td>0.710843</td>\n",
              "      <td>0.710843</td>\n",
              "      <td>0.710843</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>375</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.272746</td>\n",
              "      <td>0.741294</td>\n",
              "      <td>0.659794</td>\n",
              "      <td>0.771084</td>\n",
              "      <td>0.711111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.243462</td>\n",
              "      <td>0.761194</td>\n",
              "      <td>0.716049</td>\n",
              "      <td>0.698795</td>\n",
              "      <td>0.707317</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>425</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.611887</td>\n",
              "      <td>0.701493</td>\n",
              "      <td>0.596639</td>\n",
              "      <td>0.855422</td>\n",
              "      <td>0.702970</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.392344</td>\n",
              "      <td>0.746269</td>\n",
              "      <td>0.677778</td>\n",
              "      <td>0.734940</td>\n",
              "      <td>0.705202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>475</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.541852</td>\n",
              "      <td>0.726368</td>\n",
              "      <td>0.629630</td>\n",
              "      <td>0.819277</td>\n",
              "      <td>0.712042</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.160500</td>\n",
              "      <td>1.551101</td>\n",
              "      <td>0.726368</td>\n",
              "      <td>0.629630</td>\n",
              "      <td>0.819277</td>\n",
              "      <td>0.712042</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>525</td>\n",
              "      <td>0.160500</td>\n",
              "      <td>1.757098</td>\n",
              "      <td>0.691542</td>\n",
              "      <td>0.589744</td>\n",
              "      <td>0.831325</td>\n",
              "      <td>0.690000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.160500</td>\n",
              "      <td>1.652719</td>\n",
              "      <td>0.736318</td>\n",
              "      <td>0.638889</td>\n",
              "      <td>0.831325</td>\n",
              "      <td>0.722513</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>575</td>\n",
              "      <td>0.160500</td>\n",
              "      <td>1.576031</td>\n",
              "      <td>0.741294</td>\n",
              "      <td>0.647619</td>\n",
              "      <td>0.819277</td>\n",
              "      <td>0.723404</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "Saving model checkpoint to output/checkpoint-500\n",
            "Configuration saved in output/checkpoint-500/config.json\n",
            "Model weights saved in output/checkpoint-500/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from output/checkpoint-500 (score: 1.5511008501052856).\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='101' max='101' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [101/101 00:04]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/33593020f507d72099bd84ea6cd2296feb424fecd62d4a8edcc2a02899af6e29.38339d84e6e392addd730fd85fae32652c4cc7c5423633d6fa73e5f7937bbc38\n",
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/tokenizer_config.json from cache at None\n",
            "loading configuration file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/858852fd2471ce39075378592ddc87f5a6551e64c6825d1b92c8dab9318e0fc3.03ff9e9f998b9a9d40647a2148a202e3fb3d568dc0f170dda9dda194bab4d5dd\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"allenai/scibert_scivocab_uncased\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "loading configuration file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/858852fd2471ce39075378592ddc87f5a6551e64c6825d1b92c8dab9318e0fc3.03ff9e9f998b9a9d40647a2148a202e3fb3d568dc0f170dda9dda194bab4d5dd\n",
            "Model config BertConfig {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/de14937a851e8180a2bc5660c0041d385f8a0c62b1b2ccafa46df31043a2390c.74830bb01a0ffcdeaed8be9916312726d0c4cd364ac6fc15b375f789eaff4cbb\n",
            "Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 801\n",
            "  Num Epochs = 27\n",
            "  Instantaneous batch size per device = 2\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 16\n",
            "  Total optimization steps = 675\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='675' max='675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [675/675 24:37, Epoch 26/27]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.626353</td>\n",
              "      <td>0.646766</td>\n",
              "      <td>0.585714</td>\n",
              "      <td>0.493976</td>\n",
              "      <td>0.535948</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.587604</td>\n",
              "      <td>0.706468</td>\n",
              "      <td>0.642857</td>\n",
              "      <td>0.650602</td>\n",
              "      <td>0.646707</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.580239</td>\n",
              "      <td>0.716418</td>\n",
              "      <td>0.608333</td>\n",
              "      <td>0.879518</td>\n",
              "      <td>0.719212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.652937</td>\n",
              "      <td>0.736318</td>\n",
              "      <td>0.641509</td>\n",
              "      <td>0.819277</td>\n",
              "      <td>0.719577</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.049434</td>\n",
              "      <td>0.671642</td>\n",
              "      <td>0.561151</td>\n",
              "      <td>0.939759</td>\n",
              "      <td>0.702703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.183051</td>\n",
              "      <td>0.686567</td>\n",
              "      <td>0.581967</td>\n",
              "      <td>0.855422</td>\n",
              "      <td>0.692683</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>175</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.101745</td>\n",
              "      <td>0.716418</td>\n",
              "      <td>0.618182</td>\n",
              "      <td>0.819277</td>\n",
              "      <td>0.704663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.104203</td>\n",
              "      <td>0.726368</td>\n",
              "      <td>0.659091</td>\n",
              "      <td>0.698795</td>\n",
              "      <td>0.678363</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>225</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.540152</td>\n",
              "      <td>0.661692</td>\n",
              "      <td>0.556391</td>\n",
              "      <td>0.891566</td>\n",
              "      <td>0.685185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.941384</td>\n",
              "      <td>0.791045</td>\n",
              "      <td>0.788732</td>\n",
              "      <td>0.674699</td>\n",
              "      <td>0.727273</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>275</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.396302</td>\n",
              "      <td>0.696517</td>\n",
              "      <td>0.591667</td>\n",
              "      <td>0.855422</td>\n",
              "      <td>0.699507</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.242063</td>\n",
              "      <td>0.726368</td>\n",
              "      <td>0.629630</td>\n",
              "      <td>0.819277</td>\n",
              "      <td>0.712042</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>325</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.306828</td>\n",
              "      <td>0.746269</td>\n",
              "      <td>0.656863</td>\n",
              "      <td>0.807229</td>\n",
              "      <td>0.724324</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.219117</td>\n",
              "      <td>0.731343</td>\n",
              "      <td>0.649485</td>\n",
              "      <td>0.759036</td>\n",
              "      <td>0.700000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>375</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.123051</td>\n",
              "      <td>0.741294</td>\n",
              "      <td>0.686747</td>\n",
              "      <td>0.686747</td>\n",
              "      <td>0.686747</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.126075</td>\n",
              "      <td>0.756219</td>\n",
              "      <td>0.707317</td>\n",
              "      <td>0.698795</td>\n",
              "      <td>0.703030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>425</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.623008</td>\n",
              "      <td>0.691542</td>\n",
              "      <td>0.585366</td>\n",
              "      <td>0.867470</td>\n",
              "      <td>0.699029</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.436351</td>\n",
              "      <td>0.726368</td>\n",
              "      <td>0.632075</td>\n",
              "      <td>0.807229</td>\n",
              "      <td>0.708995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>475</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.490153</td>\n",
              "      <td>0.726368</td>\n",
              "      <td>0.629630</td>\n",
              "      <td>0.819277</td>\n",
              "      <td>0.712042</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.162400</td>\n",
              "      <td>1.620451</td>\n",
              "      <td>0.716418</td>\n",
              "      <td>0.614035</td>\n",
              "      <td>0.843373</td>\n",
              "      <td>0.710660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>525</td>\n",
              "      <td>0.162400</td>\n",
              "      <td>1.520101</td>\n",
              "      <td>0.711443</td>\n",
              "      <td>0.612613</td>\n",
              "      <td>0.819277</td>\n",
              "      <td>0.701031</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.162400</td>\n",
              "      <td>1.518707</td>\n",
              "      <td>0.711443</td>\n",
              "      <td>0.614679</td>\n",
              "      <td>0.807229</td>\n",
              "      <td>0.697917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>575</td>\n",
              "      <td>0.162400</td>\n",
              "      <td>1.460318</td>\n",
              "      <td>0.761194</td>\n",
              "      <td>0.676768</td>\n",
              "      <td>0.807229</td>\n",
              "      <td>0.736264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.162400</td>\n",
              "      <td>1.515634</td>\n",
              "      <td>0.731343</td>\n",
              "      <td>0.638095</td>\n",
              "      <td>0.807229</td>\n",
              "      <td>0.712766</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>625</td>\n",
              "      <td>0.162400</td>\n",
              "      <td>1.533800</td>\n",
              "      <td>0.731343</td>\n",
              "      <td>0.638095</td>\n",
              "      <td>0.807229</td>\n",
              "      <td>0.712766</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>0.162400</td>\n",
              "      <td>1.495636</td>\n",
              "      <td>0.751244</td>\n",
              "      <td>0.663366</td>\n",
              "      <td>0.807229</td>\n",
              "      <td>0.728261</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>675</td>\n",
              "      <td>0.162400</td>\n",
              "      <td>1.483648</td>\n",
              "      <td>0.761194</td>\n",
              "      <td>0.676768</td>\n",
              "      <td>0.807229</td>\n",
              "      <td>0.736264</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "Saving model checkpoint to output/checkpoint-500\n",
            "Configuration saved in output/checkpoint-500/config.json\n",
            "Model weights saved in output/checkpoint-500/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from output/checkpoint-500 (score: 1.6204508543014526).\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='101' max='101' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [101/101 00:04]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/33593020f507d72099bd84ea6cd2296feb424fecd62d4a8edcc2a02899af6e29.38339d84e6e392addd730fd85fae32652c4cc7c5423633d6fa73e5f7937bbc38\n",
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/tokenizer_config.json from cache at None\n",
            "loading configuration file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/858852fd2471ce39075378592ddc87f5a6551e64c6825d1b92c8dab9318e0fc3.03ff9e9f998b9a9d40647a2148a202e3fb3d568dc0f170dda9dda194bab4d5dd\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"allenai/scibert_scivocab_uncased\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "loading configuration file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/858852fd2471ce39075378592ddc87f5a6551e64c6825d1b92c8dab9318e0fc3.03ff9e9f998b9a9d40647a2148a202e3fb3d568dc0f170dda9dda194bab4d5dd\n",
            "Model config BertConfig {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/de14937a851e8180a2bc5660c0041d385f8a0c62b1b2ccafa46df31043a2390c.74830bb01a0ffcdeaed8be9916312726d0c4cd364ac6fc15b375f789eaff4cbb\n",
            "Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 801\n",
            "  Num Epochs = 30\n",
            "  Instantaneous batch size per device = 2\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 16\n",
            "  Total optimization steps = 750\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='750' max='750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [750/750 27:19, Epoch 29/30]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.621259</td>\n",
              "      <td>0.681592</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.686747</td>\n",
              "      <td>0.640449</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.550076</td>\n",
              "      <td>0.716418</td>\n",
              "      <td>0.732143</td>\n",
              "      <td>0.493976</td>\n",
              "      <td>0.589928</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.570356</td>\n",
              "      <td>0.726368</td>\n",
              "      <td>0.634615</td>\n",
              "      <td>0.795181</td>\n",
              "      <td>0.705882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.597047</td>\n",
              "      <td>0.751244</td>\n",
              "      <td>0.660194</td>\n",
              "      <td>0.819277</td>\n",
              "      <td>0.731183</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.056519</td>\n",
              "      <td>0.691542</td>\n",
              "      <td>0.582677</td>\n",
              "      <td>0.891566</td>\n",
              "      <td>0.704762</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.859084</td>\n",
              "      <td>0.741294</td>\n",
              "      <td>0.686747</td>\n",
              "      <td>0.686747</td>\n",
              "      <td>0.686747</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>175</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.162889</td>\n",
              "      <td>0.726368</td>\n",
              "      <td>0.634615</td>\n",
              "      <td>0.795181</td>\n",
              "      <td>0.705882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.163048</td>\n",
              "      <td>0.761194</td>\n",
              "      <td>0.830189</td>\n",
              "      <td>0.530120</td>\n",
              "      <td>0.647059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>225</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.348636</td>\n",
              "      <td>0.676617</td>\n",
              "      <td>0.568182</td>\n",
              "      <td>0.903614</td>\n",
              "      <td>0.697674</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.934565</td>\n",
              "      <td>0.756219</td>\n",
              "      <td>0.693182</td>\n",
              "      <td>0.734940</td>\n",
              "      <td>0.713450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>275</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.362080</td>\n",
              "      <td>0.671642</td>\n",
              "      <td>0.563910</td>\n",
              "      <td>0.903614</td>\n",
              "      <td>0.694444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.201386</td>\n",
              "      <td>0.736318</td>\n",
              "      <td>0.636364</td>\n",
              "      <td>0.843373</td>\n",
              "      <td>0.725389</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>325</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.023451</td>\n",
              "      <td>0.746269</td>\n",
              "      <td>0.681818</td>\n",
              "      <td>0.722892</td>\n",
              "      <td>0.701754</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.215624</td>\n",
              "      <td>0.751244</td>\n",
              "      <td>0.698795</td>\n",
              "      <td>0.698795</td>\n",
              "      <td>0.698795</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>375</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.126197</td>\n",
              "      <td>0.726368</td>\n",
              "      <td>0.662791</td>\n",
              "      <td>0.686747</td>\n",
              "      <td>0.674556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.273645</td>\n",
              "      <td>0.726368</td>\n",
              "      <td>0.648936</td>\n",
              "      <td>0.734940</td>\n",
              "      <td>0.689266</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>425</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.529418</td>\n",
              "      <td>0.711443</td>\n",
              "      <td>0.605042</td>\n",
              "      <td>0.867470</td>\n",
              "      <td>0.712871</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.447588</td>\n",
              "      <td>0.726368</td>\n",
              "      <td>0.632075</td>\n",
              "      <td>0.807229</td>\n",
              "      <td>0.708995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>475</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.397952</td>\n",
              "      <td>0.736318</td>\n",
              "      <td>0.647059</td>\n",
              "      <td>0.795181</td>\n",
              "      <td>0.713514</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.154600</td>\n",
              "      <td>1.769865</td>\n",
              "      <td>0.711443</td>\n",
              "      <td>0.601626</td>\n",
              "      <td>0.891566</td>\n",
              "      <td>0.718447</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>525</td>\n",
              "      <td>0.154600</td>\n",
              "      <td>1.745394</td>\n",
              "      <td>0.716418</td>\n",
              "      <td>0.608333</td>\n",
              "      <td>0.879518</td>\n",
              "      <td>0.719212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.154600</td>\n",
              "      <td>1.501822</td>\n",
              "      <td>0.741294</td>\n",
              "      <td>0.650485</td>\n",
              "      <td>0.807229</td>\n",
              "      <td>0.720430</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>575</td>\n",
              "      <td>0.154600</td>\n",
              "      <td>1.528398</td>\n",
              "      <td>0.731343</td>\n",
              "      <td>0.635514</td>\n",
              "      <td>0.819277</td>\n",
              "      <td>0.715789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.154600</td>\n",
              "      <td>1.589226</td>\n",
              "      <td>0.706468</td>\n",
              "      <td>0.607143</td>\n",
              "      <td>0.819277</td>\n",
              "      <td>0.697436</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>625</td>\n",
              "      <td>0.154600</td>\n",
              "      <td>1.631486</td>\n",
              "      <td>0.711443</td>\n",
              "      <td>0.610619</td>\n",
              "      <td>0.831325</td>\n",
              "      <td>0.704082</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>0.154600</td>\n",
              "      <td>1.592883</td>\n",
              "      <td>0.721393</td>\n",
              "      <td>0.623853</td>\n",
              "      <td>0.819277</td>\n",
              "      <td>0.708333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>675</td>\n",
              "      <td>0.154600</td>\n",
              "      <td>1.587564</td>\n",
              "      <td>0.736318</td>\n",
              "      <td>0.641509</td>\n",
              "      <td>0.819277</td>\n",
              "      <td>0.719577</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.154600</td>\n",
              "      <td>1.615494</td>\n",
              "      <td>0.721393</td>\n",
              "      <td>0.623853</td>\n",
              "      <td>0.819277</td>\n",
              "      <td>0.708333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>725</td>\n",
              "      <td>0.154600</td>\n",
              "      <td>1.601258</td>\n",
              "      <td>0.731343</td>\n",
              "      <td>0.635514</td>\n",
              "      <td>0.819277</td>\n",
              "      <td>0.715789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>0.154600</td>\n",
              "      <td>1.624325</td>\n",
              "      <td>0.721393</td>\n",
              "      <td>0.623853</td>\n",
              "      <td>0.819277</td>\n",
              "      <td>0.708333</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "Saving model checkpoint to output/checkpoint-500\n",
            "Configuration saved in output/checkpoint-500/config.json\n",
            "Model weights saved in output/checkpoint-500/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from output/checkpoint-500 (score: 1.7698652744293213).\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='101' max='101' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [101/101 00:04]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(range(3,42,3),sci_recall_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "QO4El1MPkXId",
        "outputId": "c3354de2-44b1-4466-de0c-4a4889554f61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fc1a13e9810>]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(range(3,31,3),sci_recall_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "0jIrsbEnUf8c",
        "outputId": "5e5e272e-f3a0-41af-dd9a-afe56c3a5e8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fd2fc0a7e90>]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}