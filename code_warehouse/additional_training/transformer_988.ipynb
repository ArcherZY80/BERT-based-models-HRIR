{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "transformer_988.ipynb（副本）",
      "provenance": [],
      "collapsed_sections": [
        "gW34gr1AC24p",
        "4EFStMG-C_VK",
        "o3WR8yFJDR6k",
        "luepqYESn1vw",
        "Recnekj8kdxj",
        "RaznU02IDUOE",
        "-51pSseQn5l-",
        "KxLVP1zHOm9a",
        "XmDiN-MXSc3i",
        "H9OWeTn4DWOs",
        "V9ic376EoM_x",
        "W33ko4DhNyNi",
        "GeQ6oDq2kl_U",
        "YyPc4gyzoPA1",
        "s7hDQtn3O1GF",
        "iygJs_6cSnCR"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "075acf12a0fa4aa581686f7592f0a71f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_506e66e022f04111a6196b6469797b01",
              "IPY_MODEL_c1473c71ba8f4076a1623414aaee3adb",
              "IPY_MODEL_4aa6b01d34b049c9a0324e012fe22cc8"
            ],
            "layout": "IPY_MODEL_cf75e595fd484800b6b43aa650feac53"
          }
        },
        "506e66e022f04111a6196b6469797b01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f95647bc0c574983b3318a0191c139de",
            "placeholder": "​",
            "style": "IPY_MODEL_54c962fecfde4262858244b5108153d1",
            "value": "Downloading: 100%"
          }
        },
        "c1473c71ba8f4076a1623414aaee3adb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e28ad265352b4a37a603b7c9520a3e76",
            "max": 227845,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f07539909a6941998263322ed1ea1953",
            "value": 227845
          }
        },
        "4aa6b01d34b049c9a0324e012fe22cc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df555d18b01e4762b17204834b0b1f24",
            "placeholder": "​",
            "style": "IPY_MODEL_72d5c1747be24836b8e178442d642074",
            "value": " 223k/223k [00:00&lt;00:00, 823kB/s]"
          }
        },
        "cf75e595fd484800b6b43aa650feac53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f95647bc0c574983b3318a0191c139de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54c962fecfde4262858244b5108153d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e28ad265352b4a37a603b7c9520a3e76": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f07539909a6941998263322ed1ea1953": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "df555d18b01e4762b17204834b0b1f24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72d5c1747be24836b8e178442d642074": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c46304ead6eb49c3ae99489b86733710": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b6179279416d43e890c481bfd73a3d6d",
              "IPY_MODEL_ecaf63142d8c4f2c8855cedd96ec434e",
              "IPY_MODEL_b31c15f145274f4197ad4efb158a59cf"
            ],
            "layout": "IPY_MODEL_4f242a4abae345fb83d087a793c3cb3b"
          }
        },
        "b6179279416d43e890c481bfd73a3d6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d7946035f9d4694a3e98f7f1d736cf2",
            "placeholder": "​",
            "style": "IPY_MODEL_988e1fd8ef144fe58ba666ddbf596c92",
            "value": "Downloading: 100%"
          }
        },
        "ecaf63142d8c4f2c8855cedd96ec434e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cfb32c26143e48b0881bf11d58968b85",
            "max": 385,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_11316dd3a8644733b2e6114407a36daa",
            "value": 385
          }
        },
        "b31c15f145274f4197ad4efb158a59cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29e300dbdb7840de93c12a8118945256",
            "placeholder": "​",
            "style": "IPY_MODEL_455ef103cfd84fcbb5981cc743d4ae58",
            "value": " 385/385 [00:00&lt;00:00, 12.6kB/s]"
          }
        },
        "4f242a4abae345fb83d087a793c3cb3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d7946035f9d4694a3e98f7f1d736cf2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "988e1fd8ef144fe58ba666ddbf596c92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cfb32c26143e48b0881bf11d58968b85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11316dd3a8644733b2e6114407a36daa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "29e300dbdb7840de93c12a8118945256": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "455ef103cfd84fcbb5981cc743d4ae58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d8adbd8474a34f35a1fde7ddd483ef57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e5dadd18025a469b90338361ed665c50",
              "IPY_MODEL_fc92374b48bf48aa957291edaa645daf",
              "IPY_MODEL_3b539550a7384f0b882873d87a245865"
            ],
            "layout": "IPY_MODEL_ef53c4d9c4d24cd280057159a9c2b987"
          }
        },
        "e5dadd18025a469b90338361ed665c50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13ccd64cf41741548a5cee0b28c4f060",
            "placeholder": "​",
            "style": "IPY_MODEL_fc958b4bd8374914a504de6fccfde01c",
            "value": "Downloading: 100%"
          }
        },
        "fc92374b48bf48aa957291edaa645daf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46443a03baf74d539f853c45a183c67a",
            "max": 442221694,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1ba26684ee514393a72a3d7aa941e598",
            "value": 442221694
          }
        },
        "3b539550a7384f0b882873d87a245865": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51c19f3ed28e4c17ace4e879515928e7",
            "placeholder": "​",
            "style": "IPY_MODEL_dc07df0814e44c059cf8cf788a561558",
            "value": " 422M/422M [00:09&lt;00:00, 62.3MB/s]"
          }
        },
        "ef53c4d9c4d24cd280057159a9c2b987": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13ccd64cf41741548a5cee0b28c4f060": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc958b4bd8374914a504de6fccfde01c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "46443a03baf74d539f853c45a183c67a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ba26684ee514393a72a3d7aa941e598": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "51c19f3ed28e4c17ace4e879515928e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc07df0814e44c059cf8cf788a561558": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Import"
      ],
      "metadata": {
        "id": "gW34gr1AC24p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eN0PVKZDLSuy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03e9f7b0-40cf-411e-f8ee-cb11ce85b079"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.17.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 8.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.2)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 80.1 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 60.6 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,>=0.11.1\n",
            "  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.5 MB 57.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 6.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.49 tokenizers-0.11.6 transformers-4.17.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import logging\n",
        "\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "transformers_logger = logging.getLogger(\"transformers\")\n",
        "transformers_logger.setLevel(logging.WARNING)"
      ],
      "metadata": {
        "id": "cdaE_5fyC6Lj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!/opt/bin/nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpBIvX3fC8Ou",
        "outputId": "953d25ad-a097-406c-90e3-fd91c3f63f64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Mar 16 20:24:48 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "import torch\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from transformers import EarlyStoppingCallback"
      ],
      "metadata": {
        "id": "Jhk5tAz2DO7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#read dataset"
      ],
      "metadata": {
        "id": "4EFStMG-C_VK"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "8efa9f89-8c73-4ef6-f053-a67010e04b50",
        "id": "oKZTJuEnqphe"
      },
      "source": [
        "\n",
        "train_df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/project/4192/Data/DirectCompare/train_df.csv\")\n",
        "\n",
        "train_df = train_df[['selftext','Expert-label']]\n",
        "train_df[['Expert-label']] = train_df[['Expert-label']].astype(int)\n",
        "train_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               selftext  Expert-label\n",
              "0     I posted this on Piazza but thought I might as...             1\n",
              "1     Hi i’ve applied for arts from Vancouver,BC as ...             0\n",
              "2     i'm an international student and i've been tak...             1\n",
              "3     i'm an international student and the midterm w...             1\n",
              "4     they think i wouldnt be able to handle the str...             0\n",
              "...                                                 ...           ...\n",
              "997   My boyfriend is Canadian and I’m American. Obv...             0\n",
              "998   Do you need to be vaccinated to travel domesti...             0\n",
              "999   Hello, are there any International students he...             1\n",
              "1000  Will you guys take a leave of absence? Or are ...             0\n",
              "1001  I posted this on Piazza but thought I might as...             1\n",
              "\n",
              "[1002 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-db6b31e0-0638-43d4-9619-cd894fb034e2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>selftext</th>\n",
              "      <th>Expert-label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I posted this on Piazza but thought I might as...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hi i’ve applied for arts from Vancouver,BC as ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i'm an international student and i've been tak...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i'm an international student and the midterm w...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>they think i wouldnt be able to handle the str...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>My boyfriend is Canadian and I’m American. Obv...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>Do you need to be vaccinated to travel domesti...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>Hello, are there any International students he...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1000</th>\n",
              "      <td>Will you guys take a leave of absence? Or are ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1001</th>\n",
              "      <td>I posted this on Piazza but thought I might as...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1002 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-db6b31e0-0638-43d4-9619-cd894fb034e2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-db6b31e0-0638-43d4-9619-cd894fb034e2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-db6b31e0-0638-43d4-9619-cd894fb034e2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/project/4192/Data/Validation988/988validation.csv\")\n",
        "\n",
        "test_df = test_df[['selftext']]\n",
        "test_df.insert(test_df.shape[1], 'label', 1)\n",
        "test_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "ETqRVarMJC5D",
        "outputId": "b109aceb-1338-482b-c9ab-f90c888c9ae5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              selftext  label\n",
              "0    Well... I think I need some help... about depr...      1\n",
              "1    I am an international student and i started en...      1\n",
              "2    i'm an international student and the midterm w...      1\n",
              "3    Honestly just want to end it all , it’s so har...      1\n",
              "4    Hi all, \\n\\nI'm really upset to know the Winte...      1\n",
              "..                                                 ...    ...\n",
              "983  WE NEED A SCIENCE AND DATA BASED APPROACH TO C...      1\n",
              "984  Hi everyone! Hope that all who are applying ar...      1\n",
              "985  Hello everyone !\\n\\nI request some advice from...      1\n",
              "986  Hi, I was wondering what my chances were at th...      1\n",
              "987  \\nPlease help me [support this petition ](http...      1\n",
              "\n",
              "[988 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cee4382c-5c94-49ef-ad50-f60dbd3d3309\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>selftext</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Well... I think I need some help... about depr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I am an international student and i started en...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i'm an international student and the midterm w...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Honestly just want to end it all , it’s so har...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Hi all, \\n\\nI'm really upset to know the Winte...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>983</th>\n",
              "      <td>WE NEED A SCIENCE AND DATA BASED APPROACH TO C...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>984</th>\n",
              "      <td>Hi everyone! Hope that all who are applying ar...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>985</th>\n",
              "      <td>Hello everyone !\\n\\nI request some advice from...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>986</th>\n",
              "      <td>Hi, I was wondering what my chances were at th...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>987</th>\n",
              "      <td>\\nPlease help me [support this petition ](http...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>988 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cee4382c-5c94-49ef-ad50-f60dbd3d3309')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cee4382c-5c94-49ef-ad50-f60dbd3d3309 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cee4382c-5c94-49ef-ad50-f60dbd3d3309');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##data prepration"
      ],
      "metadata": {
        "id": "TWg5DSUmEmVh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train_df[\"selftext\"].values.tolist()\n",
        "y_train = train_df[\"Expert-label\"].values.tolist()\n",
        "X_val = test_df[\"selftext\"].values.tolist()\n",
        "y_val = test_df[\"label\"].values.tolist()\n",
        "\n"
      ],
      "metadata": {
        "id": "H9brgjQ3DgRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##torch dataset"
      ],
      "metadata": {
        "id": "WzMZb4CvEkO3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels=None):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        if self.labels:\n",
        "            item[\"labels\"] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings[\"input_ids\"])\n",
        "\n"
      ],
      "metadata": {
        "id": "zB7XnQRPDrUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Metrics"
      ],
      "metadata": {
        "id": "gQfBpCsPDvkt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(p):\n",
        "    pred, labels = p\n",
        "    pred = np.argmax(pred, axis=1)\n",
        "\n",
        "    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n",
        "    recall = recall_score(y_true=labels, y_pred=pred)\n",
        "    precision = precision_score(y_true=labels, y_pred=pred)\n",
        "    f1 = f1_score(y_true=labels, y_pred=pred)\n",
        "\n",
        "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}"
      ],
      "metadata": {
        "id": "0ptdaWxZDxy7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Models"
      ],
      "metadata": {
        "id": "TkoA5HxpDFE5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##SciBERT"
      ],
      "metadata": {
        "id": "o3WR8yFJDR6k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"allenai/scibert_scivocab_uncased\"\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "model = BertForSequenceClassification.from_pretrained(model_name,num_labels =2 )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "075acf12a0fa4aa581686f7592f0a71f",
            "506e66e022f04111a6196b6469797b01",
            "c1473c71ba8f4076a1623414aaee3adb",
            "4aa6b01d34b049c9a0324e012fe22cc8",
            "cf75e595fd484800b6b43aa650feac53",
            "f95647bc0c574983b3318a0191c139de",
            "54c962fecfde4262858244b5108153d1",
            "e28ad265352b4a37a603b7c9520a3e76",
            "f07539909a6941998263322ed1ea1953",
            "df555d18b01e4762b17204834b0b1f24",
            "72d5c1747be24836b8e178442d642074",
            "c46304ead6eb49c3ae99489b86733710",
            "b6179279416d43e890c481bfd73a3d6d",
            "ecaf63142d8c4f2c8855cedd96ec434e",
            "b31c15f145274f4197ad4efb158a59cf",
            "4f242a4abae345fb83d087a793c3cb3b",
            "7d7946035f9d4694a3e98f7f1d736cf2",
            "988e1fd8ef144fe58ba666ddbf596c92",
            "cfb32c26143e48b0881bf11d58968b85",
            "11316dd3a8644733b2e6114407a36daa",
            "29e300dbdb7840de93c12a8118945256",
            "455ef103cfd84fcbb5981cc743d4ae58",
            "d8adbd8474a34f35a1fde7ddd483ef57",
            "e5dadd18025a469b90338361ed665c50",
            "fc92374b48bf48aa957291edaa645daf",
            "3b539550a7384f0b882873d87a245865",
            "ef53c4d9c4d24cd280057159a9c2b987",
            "13ccd64cf41741548a5cee0b28c4f060",
            "fc958b4bd8374914a504de6fccfde01c",
            "46443a03baf74d539f853c45a183c67a",
            "1ba26684ee514393a72a3d7aa941e598",
            "51c19f3ed28e4c17ace4e879515928e7",
            "dc07df0814e44c059cf8cf788a561558"
          ]
        },
        "id": "Pq1SwqHyDGo9",
        "outputId": "9c3dfdf1-f087-4fa3-d605-b5385bdeb78e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/223k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "075acf12a0fa4aa581686f7592f0a71f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/385 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c46304ead6eb49c3ae99489b86733710"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/422M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d8adbd8474a34f35a1fde7ddd483ef57"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tokenized = tokenizer(X_train, padding=True, truncation=True, max_length=512)\n",
        "X_val_tokenized = tokenizer(X_val, padding=True, truncation=True, max_length=512)"
      ],
      "metadata": {
        "id": "m8kZyGElEeT8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = Dataset(X_train_tokenized, y_train)\n",
        "val_dataset = Dataset(X_val_tokenized, y_val)"
      ],
      "metadata": {
        "id": "SC5Lbit-EiNA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###epoch=3"
      ],
      "metadata": {
        "id": "luepqYESn1vw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "args = TrainingArguments(\n",
        "    output_dir=\"output\",\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=25,\n",
        "    per_device_train_batch_size=2,\n",
        "    per_device_eval_batch_size=2,\n",
        "    num_train_epochs=3,\n",
        "    seed=0,\n",
        "    load_best_model_at_end=True,\n",
        "    overwrite_output_dir=True,\n",
        "    learning_rate=3e-5,\n",
        "    gradient_accumulation_steps=16\n",
        ")"
      ],
      "metadata": {
        "id": "diReFCzPD2V_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_sci = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
        ")"
      ],
      "metadata": {
        "id": "Rirdn7NED3pM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_sci.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570
        },
        "id": "vBUe1O6sD47-",
        "outputId": "0185e06a-7be3-4044-b68c-71e4e60a74bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 1002\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 2\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 16\n",
            "  Total optimization steps = 93\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='93' max='93' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [93/93 04:04, Epoch 2/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.042321</td>\n",
              "      <td>0.330972</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.330972</td>\n",
              "      <td>0.497338</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.553313</td>\n",
              "      <td>0.045547</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.045547</td>\n",
              "      <td>0.087125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.510696</td>\n",
              "      <td>0.169028</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.169028</td>\n",
              "      <td>0.289177</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=93, training_loss=0.6075086696173555, metrics={'train_runtime': 246.6366, 'train_samples_per_second': 12.188, 'train_steps_per_second': 0.377, 'total_flos': 788280721858560.0, 'train_loss': 0.6075086696173555, 'epoch': 2.99})"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###epoch=6"
      ],
      "metadata": {
        "id": "3_4-GQLyNlKF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "args = TrainingArguments(\n",
        "    output_dir=\"output\",\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=25,\n",
        "    per_device_train_batch_size=2,\n",
        "    per_device_eval_batch_size=2,\n",
        "    num_train_epochs=6,\n",
        "    seed=0,\n",
        "    load_best_model_at_end=True,\n",
        "    overwrite_output_dir=True,\n",
        "    learning_rate=3e-5,\n",
        "    gradient_accumulation_steps=16\n",
        ")"
      ],
      "metadata": {
        "id": "HT6GLeg0Nlea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_sci_6 = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
        ")"
      ],
      "metadata": {
        "id": "Kd6_9hYlNpJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_sci_6.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 881
        },
        "id": "GHWxM8OYNrxY",
        "outputId": "119d98a3-852d-4fea-f07d-ac03d57aae2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 1002\n",
            "  Num Epochs = 6\n",
            "  Instantaneous batch size per device = 2\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 16\n",
            "  Total optimization steps = 186\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='186' max='186' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [186/186 08:42, Epoch 5/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.099229</td>\n",
              "      <td>0.239879</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.239879</td>\n",
              "      <td>0.386939</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.570231</td>\n",
              "      <td>0.114372</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.114372</td>\n",
              "      <td>0.205268</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.769751</td>\n",
              "      <td>0.172065</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.172065</td>\n",
              "      <td>0.293610</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.819309</td>\n",
              "      <td>0.252024</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.252024</td>\n",
              "      <td>0.402587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.401219</td>\n",
              "      <td>0.161943</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.161943</td>\n",
              "      <td>0.278746</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.190536</td>\n",
              "      <td>0.224696</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.224696</td>\n",
              "      <td>0.366942</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>175</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.533719</td>\n",
              "      <td>0.180162</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.180162</td>\n",
              "      <td>0.305317</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=186, training_loss=0.4460338059292045, metrics={'train_runtime': 524.4684, 'train_samples_per_second': 11.463, 'train_steps_per_second': 0.355, 'total_flos': 1579192554270720.0, 'train_loss': 0.4460338059292045, 'epoch': 5.99})"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###epoch=9"
      ],
      "metadata": {
        "id": "Recnekj8kdxj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "args = TrainingArguments(\n",
        "    output_dir=\"output\",\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=25,\n",
        "    per_device_train_batch_size=2,\n",
        "    per_device_eval_batch_size=2,\n",
        "    num_train_epochs=9,\n",
        "    seed=0,\n",
        "    load_best_model_at_end=True,\n",
        "    overwrite_output_dir=True,\n",
        "    learning_rate=3e-5,\n",
        "    gradient_accumulation_steps=16\n",
        ")"
      ],
      "metadata": {
        "id": "qqxMWliFkfqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_sci_9 = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
        ")"
      ],
      "metadata": {
        "id": "4h1OAYB0kgIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_sci_9.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BcaTQInVkiKs",
        "outputId": "75c144f1-90df-40e6-fe6c-7dabde11fbc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 1002\n",
            "  Num Epochs = 9\n",
            "  Instantaneous batch size per device = 2\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 16\n",
            "  Total optimization steps = 279\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='279' max='279' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [279/279 13:10, Epoch 8/9]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.042184</td>\n",
              "      <td>0.156883</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.156883</td>\n",
              "      <td>0.271216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.288229</td>\n",
              "      <td>0.134615</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.134615</td>\n",
              "      <td>0.237288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.579396</td>\n",
              "      <td>0.193320</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.193320</td>\n",
              "      <td>0.324003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.054889</td>\n",
              "      <td>0.189271</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.189271</td>\n",
              "      <td>0.318298</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.249748</td>\n",
              "      <td>0.153846</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.153846</td>\n",
              "      <td>0.266667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.531972</td>\n",
              "      <td>0.187247</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.187247</td>\n",
              "      <td>0.315431</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>175</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.001111</td>\n",
              "      <td>0.164980</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.164980</td>\n",
              "      <td>0.283232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.676663</td>\n",
              "      <td>0.256073</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.256073</td>\n",
              "      <td>0.407736</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>225</td>\n",
              "      <td>No log</td>\n",
              "      <td>4.048328</td>\n",
              "      <td>0.116397</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.116397</td>\n",
              "      <td>0.208522</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.700036</td>\n",
              "      <td>0.178138</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.178138</td>\n",
              "      <td>0.302405</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>275</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.684569</td>\n",
              "      <td>0.194332</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.194332</td>\n",
              "      <td>0.325424</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=279, training_loss=0.27450225173786125, metrics={'train_runtime': 792.4637, 'train_samples_per_second': 11.38, 'train_steps_per_second': 0.352, 'total_flos': 2370104386682880.0, 'train_loss': 0.27450225173786125, 'epoch': 8.99})"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##PSY"
      ],
      "metadata": {
        "id": "RaznU02IDUOE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"nlp4good/psych-search\"\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "model = BertForSequenceClassification.from_pretrained(model_name,num_labels =2 )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7AfI2q-UDVWR",
        "outputId": "9f81d90c-331c-4df0-b12e-31d1d6c66cb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at nlp4good/psych-search were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at nlp4good/psych-search and are newly initialized: ['bert.pooler.dense.weight', 'classifier.weight', 'classifier.bias', 'bert.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tokenized = tokenizer(X_train, padding=True, truncation=True, max_length=512)\n",
        "X_val_tokenized = tokenizer(X_val, padding=True, truncation=True, max_length=512)"
      ],
      "metadata": {
        "id": "ZVk46haNFvc1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = Dataset(X_train_tokenized, y_train)\n",
        "val_dataset = Dataset(X_val_tokenized, y_val)"
      ],
      "metadata": {
        "id": "CPYDA-zvFvxv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###epoch=3"
      ],
      "metadata": {
        "id": "-51pSseQn5l-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "args = TrainingArguments(\n",
        "    output_dir=\"output\",\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=25,\n",
        "    per_device_train_batch_size=2,\n",
        "    per_device_eval_batch_size=2,\n",
        "    num_train_epochs=3,\n",
        "    seed=0,\n",
        "    load_best_model_at_end=True,\n",
        "    overwrite_output_dir=True,\n",
        "    learning_rate=3e-5,\n",
        "    gradient_accumulation_steps=16\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8PQWi8XFv-b",
        "outputId": "89417f49-0255-4be4-9387-c43e2419317f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_psy = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
        ")"
      ],
      "metadata": {
        "id": "O1ynfE5HF0YC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_psy.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570
        },
        "id": "_QAYTIy4F4C2",
        "outputId": "a8841fac-0c1d-4a6a-af3b-d4001da7ce53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 1002\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 2\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 16\n",
            "  Total optimization steps = 93\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='93' max='93' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [93/93 04:04, Epoch 2/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.249074</td>\n",
              "      <td>0.042510</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.042510</td>\n",
              "      <td>0.081553</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.728763</td>\n",
              "      <td>0.121457</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.121457</td>\n",
              "      <td>0.216606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.897291</td>\n",
              "      <td>0.157895</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.157895</td>\n",
              "      <td>0.272727</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=93, training_loss=0.56231689453125, metrics={'train_runtime': 246.524, 'train_samples_per_second': 12.194, 'train_steps_per_second': 0.377, 'total_flos': 788280721858560.0, 'train_loss': 0.56231689453125, 'epoch': 2.99})"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###epoch=6"
      ],
      "metadata": {
        "id": "KxLVP1zHOm9a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "args = TrainingArguments(\n",
        "    output_dir=\"output\",\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=25,\n",
        "    per_device_train_batch_size=2,\n",
        "    per_device_eval_batch_size=2,\n",
        "    num_train_epochs=6,\n",
        "    seed=0,\n",
        "    load_best_model_at_end=True,\n",
        "    overwrite_output_dir=True,\n",
        "    learning_rate=3e-5,\n",
        "    gradient_accumulation_steps=16\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmquoIrMOoWI",
        "outputId": "0d89323d-98bc-4fca-9e8c-a1fe565329bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_psy_6 = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
        ")"
      ],
      "metadata": {
        "id": "WOCjHeY7Ot43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_psy_6.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 881
        },
        "id": "e0Ys6ApbOucB",
        "outputId": "d16d7af1-a082-43f7-a7ca-63b0e2afb6d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 1002\n",
            "  Num Epochs = 6\n",
            "  Instantaneous batch size per device = 2\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 16\n",
            "  Total optimization steps = 186\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='186' max='186' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [186/186 08:40, Epoch 5/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>No log</td>\n",
              "      <td>6.266512</td>\n",
              "      <td>0.205466</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.205466</td>\n",
              "      <td>0.340890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>No log</td>\n",
              "      <td>7.144855</td>\n",
              "      <td>0.170040</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.170040</td>\n",
              "      <td>0.290657</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>No log</td>\n",
              "      <td>7.206092</td>\n",
              "      <td>0.151822</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.151822</td>\n",
              "      <td>0.263620</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>No log</td>\n",
              "      <td>5.402030</td>\n",
              "      <td>0.150810</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.150810</td>\n",
              "      <td>0.262093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>No log</td>\n",
              "      <td>5.408955</td>\n",
              "      <td>0.185223</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.185223</td>\n",
              "      <td>0.312553</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>No log</td>\n",
              "      <td>6.578726</td>\n",
              "      <td>0.133603</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.133603</td>\n",
              "      <td>0.235714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>175</td>\n",
              "      <td>No log</td>\n",
              "      <td>6.356332</td>\n",
              "      <td>0.153846</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.153846</td>\n",
              "      <td>0.266667</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=186, training_loss=0.04805446952901861, metrics={'train_runtime': 522.7205, 'train_samples_per_second': 11.501, 'train_steps_per_second': 0.356, 'total_flos': 1579192554270720.0, 'train_loss': 0.04805446952901861, 'epoch': 5.99})"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###epoch=9"
      ],
      "metadata": {
        "id": "XmDiN-MXSc3i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "args = TrainingArguments(\n",
        "    output_dir=\"output\",\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=25,\n",
        "    per_device_train_batch_size=2,\n",
        "    per_device_eval_batch_size=2,\n",
        "    num_train_epochs=9,\n",
        "    seed=0,\n",
        "    load_best_model_at_end=True,\n",
        "    overwrite_output_dir=True,\n",
        "    learning_rate=3e-5,\n",
        "    gradient_accumulation_steps=16\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUUR-hKjSeQY",
        "outputId": "c222b7d3-60e3-435b-c3d7-9603c589aea4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_psy_9 = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
        ")"
      ],
      "metadata": {
        "id": "2F7Osa9oSesY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_psy_9.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_feiRRpqSe6B",
        "outputId": "de41d393-add7-4def-98ef-05c9ba634a11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 1002\n",
            "  Num Epochs = 9\n",
            "  Instantaneous batch size per device = 2\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 16\n",
            "  Total optimization steps = 279\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='279' max='279' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [279/279 13:11, Epoch 8/9]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>No log</td>\n",
              "      <td>8.373548</td>\n",
              "      <td>0.165992</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.165992</td>\n",
              "      <td>0.284722</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>No log</td>\n",
              "      <td>6.484338</td>\n",
              "      <td>0.212551</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.212551</td>\n",
              "      <td>0.350584</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>No log</td>\n",
              "      <td>8.190551</td>\n",
              "      <td>0.146761</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.146761</td>\n",
              "      <td>0.255958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>No log</td>\n",
              "      <td>8.226768</td>\n",
              "      <td>0.141700</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.141700</td>\n",
              "      <td>0.248227</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>No log</td>\n",
              "      <td>7.063513</td>\n",
              "      <td>0.191296</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.191296</td>\n",
              "      <td>0.321155</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>No log</td>\n",
              "      <td>9.005898</td>\n",
              "      <td>0.093117</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.093117</td>\n",
              "      <td>0.170370</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>175</td>\n",
              "      <td>No log</td>\n",
              "      <td>7.540215</td>\n",
              "      <td>0.197368</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.197368</td>\n",
              "      <td>0.329670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>No log</td>\n",
              "      <td>8.464607</td>\n",
              "      <td>0.130567</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.130567</td>\n",
              "      <td>0.230976</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>225</td>\n",
              "      <td>No log</td>\n",
              "      <td>8.451786</td>\n",
              "      <td>0.141700</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.141700</td>\n",
              "      <td>0.248227</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>No log</td>\n",
              "      <td>8.410789</td>\n",
              "      <td>0.139676</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.139676</td>\n",
              "      <td>0.245115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>275</td>\n",
              "      <td>No log</td>\n",
              "      <td>8.524260</td>\n",
              "      <td>0.128543</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.128543</td>\n",
              "      <td>0.227803</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=279, training_loss=0.02872309804389981, metrics={'train_runtime': 793.878, 'train_samples_per_second': 11.359, 'train_steps_per_second': 0.351, 'total_flos': 2370104386682880.0, 'train_loss': 0.02872309804389981, 'epoch': 8.99})"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Outputs"
      ],
      "metadata": {
        "id": "LFdPun0rDLgm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##SciBERT"
      ],
      "metadata": {
        "id": "H9OWeTn4DWOs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###epoch=3"
      ],
      "metadata": {
        "id": "V9ic376EoM_x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_sci.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "id": "L5aMNte6DX3o",
        "outputId": "8e1144f5-48ff-465f-bed2-978279b75d53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='494' max='494' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [494/494 00:20]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epoch': 2.99,\n",
              " 'eval_accuracy': 0.14979757085020243,\n",
              " 'eval_f1': 0.2605633802816901,\n",
              " 'eval_loss': 1.6332290172576904,\n",
              " 'eval_precision': 1.0,\n",
              " 'eval_recall': 0.14979757085020243,\n",
              " 'eval_runtime': 21.0314,\n",
              " 'eval_samples_per_second': 46.977,\n",
              " 'eval_steps_per_second': 23.489}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###epoch=6"
      ],
      "metadata": {
        "id": "W33ko4DhNyNi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_sci_6.evaluate()"
      ],
      "metadata": {
        "id": "YJYaEi8XN0Su",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "outputId": "89af5b1a-49b0-4f10-85c1-63c98248d9f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='494' max='494' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [494/494 00:21]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epoch': 5.99,\n",
              " 'eval_accuracy': 0.1700404858299595,\n",
              " 'eval_f1': 0.29065743944636674,\n",
              " 'eval_loss': 2.6157729625701904,\n",
              " 'eval_precision': 1.0,\n",
              " 'eval_recall': 0.1700404858299595,\n",
              " 'eval_runtime': 21.5487,\n",
              " 'eval_samples_per_second': 45.85,\n",
              " 'eval_steps_per_second': 22.925}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###epoch=9"
      ],
      "metadata": {
        "id": "GeQ6oDq2kl_U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_sci_9.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "id": "yHFMFc_gknSF",
        "outputId": "e8c4159e-2214-47a1-cc5a-8c7e297370b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='494' max='494' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [494/494 00:21]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epoch': 8.99,\n",
              " 'eval_accuracy': 0.19635627530364372,\n",
              " 'eval_f1': 0.32825719120135366,\n",
              " 'eval_loss': 3.6765050888061523,\n",
              " 'eval_precision': 1.0,\n",
              " 'eval_recall': 0.19635627530364372,\n",
              " 'eval_runtime': 21.4206,\n",
              " 'eval_samples_per_second': 46.124,\n",
              " 'eval_steps_per_second': 23.062}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##PSY"
      ],
      "metadata": {
        "id": "4gje3ApODYFg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###epoch=3"
      ],
      "metadata": {
        "id": "YyPc4gyzoPA1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_psy.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "id": "Z3csZDM0DZj_",
        "outputId": "3cabaa52-1054-412c-f291-8d1a8d99fdf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='494' max='494' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [494/494 00:20]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epoch': 2.99,\n",
              " 'eval_accuracy': 0.19230769230769232,\n",
              " 'eval_f1': 0.32258064516129037,\n",
              " 'eval_loss': 1.8422211408615112,\n",
              " 'eval_precision': 1.0,\n",
              " 'eval_recall': 0.19230769230769232,\n",
              " 'eval_runtime': 21.0253,\n",
              " 'eval_samples_per_second': 46.991,\n",
              " 'eval_steps_per_second': 23.496}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###epoch=6"
      ],
      "metadata": {
        "id": "s7hDQtn3O1GF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_psy_6.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "id": "RHcxOcPrO2js",
        "outputId": "b29ba93f-4f34-4917-c55c-5b8c51a16fa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='494' max='494' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [494/494 00:21]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epoch': 5.99,\n",
              " 'eval_accuracy': 0.13663967611336034,\n",
              " 'eval_f1': 0.24042742653606414,\n",
              " 'eval_loss': 6.61625337600708,\n",
              " 'eval_precision': 1.0,\n",
              " 'eval_recall': 0.13663967611336034,\n",
              " 'eval_runtime': 21.4276,\n",
              " 'eval_samples_per_second': 46.109,\n",
              " 'eval_steps_per_second': 23.054}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###epoch=9"
      ],
      "metadata": {
        "id": "iygJs_6cSnCR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_psy_9.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "id": "aICGaGg5Sohy",
        "outputId": "3dfce34d-9c9f-440d-e976-05f6d6cd11c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='494' max='494' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [494/494 00:21]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epoch': 8.99,\n",
              " 'eval_accuracy': 0.12854251012145748,\n",
              " 'eval_f1': 0.22780269058295963,\n",
              " 'eval_loss': 8.521716117858887,\n",
              " 'eval_precision': 1.0,\n",
              " 'eval_recall': 0.12854251012145748,\n",
              " 'eval_runtime': 21.361,\n",
              " 'eval_samples_per_second': 46.252,\n",
              " 'eval_steps_per_second': 23.126}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#epoch test"
      ],
      "metadata": {
        "id": "sY_fpvs3AriO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sci_epoch_range = range(3,31,3)\n",
        "sci_recall_list = []\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for i in sci_epoch_range:\n",
        "\n",
        "  tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "  model = BertForSequenceClassification.from_pretrained(model_name,num_labels =2 )\n",
        "\n",
        "\n",
        "  \n",
        "  args = TrainingArguments(\n",
        "      output_dir=\"output\",\n",
        "      evaluation_strategy=\"steps\",\n",
        "      eval_steps=25,\n",
        "      per_device_train_batch_size=2,\n",
        "      per_device_eval_batch_size=2,\n",
        "      num_train_epochs=i,\n",
        "      seed=0,\n",
        "      load_best_model_at_end=True,\n",
        "      overwrite_output_dir=True,\n",
        "      learning_rate=3e-5,\n",
        "      gradient_accumulation_steps=16\n",
        "  )\n",
        "\n",
        "  trainer_sci_tmp = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
        "  ) \n",
        "\n",
        "  trainer_sci_tmp.train()\n",
        "  tmp_eval = trainer_sci_tmp.evaluate()\n",
        "  sci_recall_list.append(tmp_eval['eval_recall'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SWSyCOfYAucg",
        "outputId": "2d22e108-f9ec-451a-8894-181662fcc485"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/33593020f507d72099bd84ea6cd2296feb424fecd62d4a8edcc2a02899af6e29.38339d84e6e392addd730fd85fae32652c4cc7c5423633d6fa73e5f7937bbc38\n",
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/tokenizer_config.json from cache at None\n",
            "loading configuration file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/858852fd2471ce39075378592ddc87f5a6551e64c6825d1b92c8dab9318e0fc3.03ff9e9f998b9a9d40647a2148a202e3fb3d568dc0f170dda9dda194bab4d5dd\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"allenai/scibert_scivocab_uncased\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "loading configuration file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/858852fd2471ce39075378592ddc87f5a6551e64c6825d1b92c8dab9318e0fc3.03ff9e9f998b9a9d40647a2148a202e3fb3d568dc0f170dda9dda194bab4d5dd\n",
            "Model config BertConfig {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/de14937a851e8180a2bc5660c0041d385f8a0c62b1b2ccafa46df31043a2390c.74830bb01a0ffcdeaed8be9916312726d0c4cd364ac6fc15b375f789eaff4cbb\n",
            "Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 1002\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 2\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 16\n",
            "  Total optimization steps = 93\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='93' max='93' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [93/93 04:04, Epoch 2/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.315965</td>\n",
              "      <td>0.029352</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.029352</td>\n",
              "      <td>0.057030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.562269</td>\n",
              "      <td>0.064777</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.064777</td>\n",
              "      <td>0.121673</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.662449</td>\n",
              "      <td>0.110324</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.110324</td>\n",
              "      <td>0.198724</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='494' max='494' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [494/494 00:20]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/33593020f507d72099bd84ea6cd2296feb424fecd62d4a8edcc2a02899af6e29.38339d84e6e392addd730fd85fae32652c4cc7c5423633d6fa73e5f7937bbc38\n",
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/tokenizer_config.json from cache at None\n",
            "loading configuration file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/858852fd2471ce39075378592ddc87f5a6551e64c6825d1b92c8dab9318e0fc3.03ff9e9f998b9a9d40647a2148a202e3fb3d568dc0f170dda9dda194bab4d5dd\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"allenai/scibert_scivocab_uncased\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "loading configuration file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/858852fd2471ce39075378592ddc87f5a6551e64c6825d1b92c8dab9318e0fc3.03ff9e9f998b9a9d40647a2148a202e3fb3d568dc0f170dda9dda194bab4d5dd\n",
            "Model config BertConfig {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/de14937a851e8180a2bc5660c0041d385f8a0c62b1b2ccafa46df31043a2390c.74830bb01a0ffcdeaed8be9916312726d0c4cd364ac6fc15b375f789eaff4cbb\n",
            "Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 1002\n",
            "  Num Epochs = 6\n",
            "  Instantaneous batch size per device = 2\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 16\n",
            "  Total optimization steps = 186\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='186' max='186' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [186/186 08:31, Epoch 5/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.846267</td>\n",
              "      <td>0.367409</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.367409</td>\n",
              "      <td>0.537380</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.219027</td>\n",
              "      <td>0.216599</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.216599</td>\n",
              "      <td>0.356073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.569018</td>\n",
              "      <td>0.195344</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.195344</td>\n",
              "      <td>0.326842</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.745092</td>\n",
              "      <td>0.239879</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.239879</td>\n",
              "      <td>0.386939</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.644949</td>\n",
              "      <td>0.071862</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.071862</td>\n",
              "      <td>0.134089</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.524228</td>\n",
              "      <td>0.119433</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.119433</td>\n",
              "      <td>0.213382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>175</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.751083</td>\n",
              "      <td>0.103239</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.103239</td>\n",
              "      <td>0.187156</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='494' max='494' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [494/494 00:20]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/33593020f507d72099bd84ea6cd2296feb424fecd62d4a8edcc2a02899af6e29.38339d84e6e392addd730fd85fae32652c4cc7c5423633d6fa73e5f7937bbc38\n",
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/tokenizer_config.json from cache at None\n",
            "loading configuration file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/858852fd2471ce39075378592ddc87f5a6551e64c6825d1b92c8dab9318e0fc3.03ff9e9f998b9a9d40647a2148a202e3fb3d568dc0f170dda9dda194bab4d5dd\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"allenai/scibert_scivocab_uncased\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "loading configuration file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/858852fd2471ce39075378592ddc87f5a6551e64c6825d1b92c8dab9318e0fc3.03ff9e9f998b9a9d40647a2148a202e3fb3d568dc0f170dda9dda194bab4d5dd\n",
            "Model config BertConfig {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/de14937a851e8180a2bc5660c0041d385f8a0c62b1b2ccafa46df31043a2390c.74830bb01a0ffcdeaed8be9916312726d0c4cd364ac6fc15b375f789eaff4cbb\n",
            "Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 1002\n",
            "  Num Epochs = 9\n",
            "  Instantaneous batch size per device = 2\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 16\n",
            "  Total optimization steps = 279\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='279' max='279' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [279/279 12:59, Epoch 8/9]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.139641</td>\n",
              "      <td>0.168016</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.168016</td>\n",
              "      <td>0.287695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.340565</td>\n",
              "      <td>0.162955</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.162955</td>\n",
              "      <td>0.280244</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.870145</td>\n",
              "      <td>0.216599</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.216599</td>\n",
              "      <td>0.356073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.309189</td>\n",
              "      <td>0.194332</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.194332</td>\n",
              "      <td>0.325424</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.542300</td>\n",
              "      <td>0.093117</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.093117</td>\n",
              "      <td>0.170370</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.604902</td>\n",
              "      <td>0.162955</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.162955</td>\n",
              "      <td>0.280244</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>175</td>\n",
              "      <td>No log</td>\n",
              "      <td>4.483225</td>\n",
              "      <td>0.092105</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.092105</td>\n",
              "      <td>0.168675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.255684</td>\n",
              "      <td>0.258097</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.258097</td>\n",
              "      <td>0.410298</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>225</td>\n",
              "      <td>No log</td>\n",
              "      <td>4.656199</td>\n",
              "      <td>0.133603</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.133603</td>\n",
              "      <td>0.235714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>No log</td>\n",
              "      <td>4.582757</td>\n",
              "      <td>0.154858</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.154858</td>\n",
              "      <td>0.268186</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>275</td>\n",
              "      <td>No log</td>\n",
              "      <td>4.328596</td>\n",
              "      <td>0.173077</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.173077</td>\n",
              "      <td>0.295082</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='494' max='494' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [494/494 00:20]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/33593020f507d72099bd84ea6cd2296feb424fecd62d4a8edcc2a02899af6e29.38339d84e6e392addd730fd85fae32652c4cc7c5423633d6fa73e5f7937bbc38\n",
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/tokenizer_config.json from cache at None\n",
            "loading configuration file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/858852fd2471ce39075378592ddc87f5a6551e64c6825d1b92c8dab9318e0fc3.03ff9e9f998b9a9d40647a2148a202e3fb3d568dc0f170dda9dda194bab4d5dd\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"allenai/scibert_scivocab_uncased\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "loading configuration file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/858852fd2471ce39075378592ddc87f5a6551e64c6825d1b92c8dab9318e0fc3.03ff9e9f998b9a9d40647a2148a202e3fb3d568dc0f170dda9dda194bab4d5dd\n",
            "Model config BertConfig {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/de14937a851e8180a2bc5660c0041d385f8a0c62b1b2ccafa46df31043a2390c.74830bb01a0ffcdeaed8be9916312726d0c4cd364ac6fc15b375f789eaff4cbb\n",
            "Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 1002\n",
            "  Num Epochs = 12\n",
            "  Instantaneous batch size per device = 2\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 16\n",
            "  Total optimization steps = 372\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='372' max='372' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [372/372 17:05, Epoch 11/12]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.143986</td>\n",
              "      <td>0.160931</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.160931</td>\n",
              "      <td>0.277245</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.560146</td>\n",
              "      <td>0.028340</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.028340</td>\n",
              "      <td>0.055118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.261744</td>\n",
              "      <td>0.307692</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.307692</td>\n",
              "      <td>0.470588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.280637</td>\n",
              "      <td>0.041498</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.041498</td>\n",
              "      <td>0.079689</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.912281</td>\n",
              "      <td>0.057692</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.057692</td>\n",
              "      <td>0.109091</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.455578</td>\n",
              "      <td>0.211538</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.211538</td>\n",
              "      <td>0.349206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>175</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.954658</td>\n",
              "      <td>0.226721</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.226721</td>\n",
              "      <td>0.369637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.886551</td>\n",
              "      <td>0.282389</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.282389</td>\n",
              "      <td>0.440410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>225</td>\n",
              "      <td>No log</td>\n",
              "      <td>4.146486</td>\n",
              "      <td>0.112348</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.112348</td>\n",
              "      <td>0.202002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.281456</td>\n",
              "      <td>0.253036</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.253036</td>\n",
              "      <td>0.403877</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>275</td>\n",
              "      <td>No log</td>\n",
              "      <td>4.139461</td>\n",
              "      <td>0.164980</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.164980</td>\n",
              "      <td>0.283232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>No log</td>\n",
              "      <td>4.478663</td>\n",
              "      <td>0.151822</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.151822</td>\n",
              "      <td>0.263620</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>325</td>\n",
              "      <td>No log</td>\n",
              "      <td>4.125014</td>\n",
              "      <td>0.194332</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.194332</td>\n",
              "      <td>0.325424</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>No log</td>\n",
              "      <td>4.040919</td>\n",
              "      <td>0.225709</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.225709</td>\n",
              "      <td>0.368291</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='494' max='494' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [494/494 00:20]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/33593020f507d72099bd84ea6cd2296feb424fecd62d4a8edcc2a02899af6e29.38339d84e6e392addd730fd85fae32652c4cc7c5423633d6fa73e5f7937bbc38\n",
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/tokenizer_config.json from cache at None\n",
            "loading configuration file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/858852fd2471ce39075378592ddc87f5a6551e64c6825d1b92c8dab9318e0fc3.03ff9e9f998b9a9d40647a2148a202e3fb3d568dc0f170dda9dda194bab4d5dd\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"allenai/scibert_scivocab_uncased\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "loading configuration file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/858852fd2471ce39075378592ddc87f5a6551e64c6825d1b92c8dab9318e0fc3.03ff9e9f998b9a9d40647a2148a202e3fb3d568dc0f170dda9dda194bab4d5dd\n",
            "Model config BertConfig {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/de14937a851e8180a2bc5660c0041d385f8a0c62b1b2ccafa46df31043a2390c.74830bb01a0ffcdeaed8be9916312726d0c4cd364ac6fc15b375f789eaff4cbb\n",
            "Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 1002\n",
            "  Num Epochs = 15\n",
            "  Instantaneous batch size per device = 2\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 16\n",
            "  Total optimization steps = 465\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='465' max='465' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [465/465 21:32, Epoch 14/15]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.113923</td>\n",
              "      <td>0.009109</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.009109</td>\n",
              "      <td>0.018054</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.564524</td>\n",
              "      <td>0.138664</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.138664</td>\n",
              "      <td>0.243556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.348560</td>\n",
              "      <td>0.126518</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.126518</td>\n",
              "      <td>0.224618</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.399947</td>\n",
              "      <td>0.147773</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.147773</td>\n",
              "      <td>0.257496</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.624411</td>\n",
              "      <td>0.091093</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.091093</td>\n",
              "      <td>0.166976</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.404746</td>\n",
              "      <td>0.135628</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.135628</td>\n",
              "      <td>0.238859</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>175</td>\n",
              "      <td>No log</td>\n",
              "      <td>4.288368</td>\n",
              "      <td>0.111336</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.111336</td>\n",
              "      <td>0.200364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.396213</td>\n",
              "      <td>0.261134</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.261134</td>\n",
              "      <td>0.414125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>225</td>\n",
              "      <td>No log</td>\n",
              "      <td>4.270241</td>\n",
              "      <td>0.198381</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.198381</td>\n",
              "      <td>0.331081</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>No log</td>\n",
              "      <td>4.302343</td>\n",
              "      <td>0.212551</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.212551</td>\n",
              "      <td>0.350584</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>275</td>\n",
              "      <td>No log</td>\n",
              "      <td>4.965252</td>\n",
              "      <td>0.165992</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.165992</td>\n",
              "      <td>0.284722</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>No log</td>\n",
              "      <td>4.768248</td>\n",
              "      <td>0.186235</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.186235</td>\n",
              "      <td>0.313993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>325</td>\n",
              "      <td>No log</td>\n",
              "      <td>4.852660</td>\n",
              "      <td>0.183198</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.183198</td>\n",
              "      <td>0.309666</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>No log</td>\n",
              "      <td>5.437387</td>\n",
              "      <td>0.141700</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.141700</td>\n",
              "      <td>0.248227</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>375</td>\n",
              "      <td>No log</td>\n",
              "      <td>5.549217</td>\n",
              "      <td>0.134615</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.134615</td>\n",
              "      <td>0.237288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>No log</td>\n",
              "      <td>5.652233</td>\n",
              "      <td>0.136640</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.136640</td>\n",
              "      <td>0.240427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>425</td>\n",
              "      <td>No log</td>\n",
              "      <td>5.494398</td>\n",
              "      <td>0.161943</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.161943</td>\n",
              "      <td>0.278746</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>No log</td>\n",
              "      <td>5.832854</td>\n",
              "      <td>0.133603</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.133603</td>\n",
              "      <td>0.235714</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='494' max='494' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [494/494 00:20]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/33593020f507d72099bd84ea6cd2296feb424fecd62d4a8edcc2a02899af6e29.38339d84e6e392addd730fd85fae32652c4cc7c5423633d6fa73e5f7937bbc38\n",
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/tokenizer_config.json from cache at None\n",
            "loading configuration file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/858852fd2471ce39075378592ddc87f5a6551e64c6825d1b92c8dab9318e0fc3.03ff9e9f998b9a9d40647a2148a202e3fb3d568dc0f170dda9dda194bab4d5dd\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"allenai/scibert_scivocab_uncased\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "loading configuration file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/858852fd2471ce39075378592ddc87f5a6551e64c6825d1b92c8dab9318e0fc3.03ff9e9f998b9a9d40647a2148a202e3fb3d568dc0f170dda9dda194bab4d5dd\n",
            "Model config BertConfig {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/de14937a851e8180a2bc5660c0041d385f8a0c62b1b2ccafa46df31043a2390c.74830bb01a0ffcdeaed8be9916312726d0c4cd364ac6fc15b375f789eaff4cbb\n",
            "Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 1002\n",
            "  Num Epochs = 18\n",
            "  Instantaneous batch size per device = 2\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 16\n",
            "  Total optimization steps = 558\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='558' max='558' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [558/558 26:03, Epoch 17/18]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.070922</td>\n",
              "      <td>0.257085</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.257085</td>\n",
              "      <td>0.409018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.469890</td>\n",
              "      <td>0.184211</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.184211</td>\n",
              "      <td>0.311111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.678418</td>\n",
              "      <td>0.188259</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.188259</td>\n",
              "      <td>0.316865</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.416969</td>\n",
              "      <td>0.105263</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.105263</td>\n",
              "      <td>0.190476</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.325831</td>\n",
              "      <td>0.051619</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.051619</td>\n",
              "      <td>0.098171</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.844161</td>\n",
              "      <td>0.125506</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.125506</td>\n",
              "      <td>0.223022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>175</td>\n",
              "      <td>No log</td>\n",
              "      <td>4.065267</td>\n",
              "      <td>0.102227</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.102227</td>\n",
              "      <td>0.185491</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.865581</td>\n",
              "      <td>0.151822</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.151822</td>\n",
              "      <td>0.263620</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>225</td>\n",
              "      <td>No log</td>\n",
              "      <td>5.083966</td>\n",
              "      <td>0.099190</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.099190</td>\n",
              "      <td>0.180479</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>No log</td>\n",
              "      <td>5.346222</td>\n",
              "      <td>0.092105</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.092105</td>\n",
              "      <td>0.168675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>275</td>\n",
              "      <td>No log</td>\n",
              "      <td>4.996476</td>\n",
              "      <td>0.125506</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.125506</td>\n",
              "      <td>0.223022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>No log</td>\n",
              "      <td>5.680014</td>\n",
              "      <td>0.095142</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.095142</td>\n",
              "      <td>0.173752</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>325</td>\n",
              "      <td>No log</td>\n",
              "      <td>5.578566</td>\n",
              "      <td>0.101215</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.101215</td>\n",
              "      <td>0.183824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>No log</td>\n",
              "      <td>5.342540</td>\n",
              "      <td>0.116397</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.116397</td>\n",
              "      <td>0.208522</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>375</td>\n",
              "      <td>No log</td>\n",
              "      <td>5.646584</td>\n",
              "      <td>0.115385</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.115385</td>\n",
              "      <td>0.206897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>No log</td>\n",
              "      <td>5.216470</td>\n",
              "      <td>0.153846</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.153846</td>\n",
              "      <td>0.266667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>425</td>\n",
              "      <td>No log</td>\n",
              "      <td>6.108074</td>\n",
              "      <td>0.112348</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.112348</td>\n",
              "      <td>0.202002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>No log</td>\n",
              "      <td>6.718763</td>\n",
              "      <td>0.086032</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.086032</td>\n",
              "      <td>0.158434</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>475</td>\n",
              "      <td>No log</td>\n",
              "      <td>5.324045</td>\n",
              "      <td>0.171053</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.171053</td>\n",
              "      <td>0.292135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.186600</td>\n",
              "      <td>6.007891</td>\n",
              "      <td>0.122470</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.122470</td>\n",
              "      <td>0.218215</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>525</td>\n",
              "      <td>0.186600</td>\n",
              "      <td>5.997335</td>\n",
              "      <td>0.120445</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.120445</td>\n",
              "      <td>0.214995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.186600</td>\n",
              "      <td>6.109631</td>\n",
              "      <td>0.113360</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.113360</td>\n",
              "      <td>0.203636</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "Saving model checkpoint to output/checkpoint-500\n",
            "Configuration saved in output/checkpoint-500/config.json\n",
            "Model weights saved in output/checkpoint-500/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from output/checkpoint-500 (score: 6.007890701293945).\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='494' max='494' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [494/494 00:20]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/33593020f507d72099bd84ea6cd2296feb424fecd62d4a8edcc2a02899af6e29.38339d84e6e392addd730fd85fae32652c4cc7c5423633d6fa73e5f7937bbc38\n",
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/tokenizer_config.json from cache at None\n",
            "loading configuration file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/858852fd2471ce39075378592ddc87f5a6551e64c6825d1b92c8dab9318e0fc3.03ff9e9f998b9a9d40647a2148a202e3fb3d568dc0f170dda9dda194bab4d5dd\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"allenai/scibert_scivocab_uncased\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "loading configuration file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/858852fd2471ce39075378592ddc87f5a6551e64c6825d1b92c8dab9318e0fc3.03ff9e9f998b9a9d40647a2148a202e3fb3d568dc0f170dda9dda194bab4d5dd\n",
            "Model config BertConfig {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/de14937a851e8180a2bc5660c0041d385f8a0c62b1b2ccafa46df31043a2390c.74830bb01a0ffcdeaed8be9916312726d0c4cd364ac6fc15b375f789eaff4cbb\n",
            "Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 1002\n",
            "  Num Epochs = 21\n",
            "  Instantaneous batch size per device = 2\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 16\n",
            "  Total optimization steps = 651\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='575' max='651' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [575/651 26:58 < 03:34, 0.35 it/s, Epoch 18/21]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.173175</td>\n",
              "      <td>0.009109</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.009109</td>\n",
              "      <td>0.018054</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.496552</td>\n",
              "      <td>0.172065</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.172065</td>\n",
              "      <td>0.293610</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.885052</td>\n",
              "      <td>0.208502</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.208502</td>\n",
              "      <td>0.345059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.128182</td>\n",
              "      <td>0.236842</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.236842</td>\n",
              "      <td>0.382979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.749450</td>\n",
              "      <td>0.089069</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.089069</td>\n",
              "      <td>0.163569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>No log</td>\n",
              "      <td>4.313660</td>\n",
              "      <td>0.097166</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.097166</td>\n",
              "      <td>0.177122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>175</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.807053</td>\n",
              "      <td>0.214575</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.214575</td>\n",
              "      <td>0.353333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.502484</td>\n",
              "      <td>0.314777</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.314777</td>\n",
              "      <td>0.478830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>225</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.924337</td>\n",
              "      <td>0.228745</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.228745</td>\n",
              "      <td>0.372323</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.927816</td>\n",
              "      <td>0.224696</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.224696</td>\n",
              "      <td>0.366942</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>275</td>\n",
              "      <td>No log</td>\n",
              "      <td>5.061865</td>\n",
              "      <td>0.186235</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.186235</td>\n",
              "      <td>0.313993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>No log</td>\n",
              "      <td>4.343934</td>\n",
              "      <td>0.251012</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.251012</td>\n",
              "      <td>0.401294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>325</td>\n",
              "      <td>No log</td>\n",
              "      <td>5.140680</td>\n",
              "      <td>0.197368</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.197368</td>\n",
              "      <td>0.329670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>No log</td>\n",
              "      <td>5.541580</td>\n",
              "      <td>0.171053</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.171053</td>\n",
              "      <td>0.292135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>375</td>\n",
              "      <td>No log</td>\n",
              "      <td>6.168878</td>\n",
              "      <td>0.151822</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.151822</td>\n",
              "      <td>0.263620</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>No log</td>\n",
              "      <td>5.898698</td>\n",
              "      <td>0.179150</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.179150</td>\n",
              "      <td>0.303863</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>425</td>\n",
              "      <td>No log</td>\n",
              "      <td>5.789906</td>\n",
              "      <td>0.196356</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.196356</td>\n",
              "      <td>0.328257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>No log</td>\n",
              "      <td>6.428097</td>\n",
              "      <td>0.149798</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.149798</td>\n",
              "      <td>0.260563</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>475</td>\n",
              "      <td>No log</td>\n",
              "      <td>5.765782</td>\n",
              "      <td>0.212551</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.212551</td>\n",
              "      <td>0.350584</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.185100</td>\n",
              "      <td>6.112411</td>\n",
              "      <td>0.184211</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.184211</td>\n",
              "      <td>0.311111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>525</td>\n",
              "      <td>0.185100</td>\n",
              "      <td>6.220412</td>\n",
              "      <td>0.187247</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.187247</td>\n",
              "      <td>0.315431</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.185100</td>\n",
              "      <td>6.377495</td>\n",
              "      <td>0.175101</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.175101</td>\n",
              "      <td>0.298019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>575</td>\n",
              "      <td>0.185100</td>\n",
              "      <td>6.332476</td>\n",
              "      <td>0.179150</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.179150</td>\n",
              "      <td>0.303863</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "Saving model checkpoint to output/checkpoint-500\n",
            "Configuration saved in output/checkpoint-500/config.json\n",
            "Model weights saved in output/checkpoint-500/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from output/checkpoint-500 (score: 6.1124114990234375).\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='494' max='494' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [494/494 00:20]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/33593020f507d72099bd84ea6cd2296feb424fecd62d4a8edcc2a02899af6e29.38339d84e6e392addd730fd85fae32652c4cc7c5423633d6fa73e5f7937bbc38\n",
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/tokenizer_config.json from cache at None\n",
            "loading configuration file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/858852fd2471ce39075378592ddc87f5a6551e64c6825d1b92c8dab9318e0fc3.03ff9e9f998b9a9d40647a2148a202e3fb3d568dc0f170dda9dda194bab4d5dd\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"allenai/scibert_scivocab_uncased\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "loading configuration file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/858852fd2471ce39075378592ddc87f5a6551e64c6825d1b92c8dab9318e0fc3.03ff9e9f998b9a9d40647a2148a202e3fb3d568dc0f170dda9dda194bab4d5dd\n",
            "Model config BertConfig {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/de14937a851e8180a2bc5660c0041d385f8a0c62b1b2ccafa46df31043a2390c.74830bb01a0ffcdeaed8be9916312726d0c4cd364ac6fc15b375f789eaff4cbb\n",
            "Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 1002\n",
            "  Num Epochs = 24\n",
            "  Instantaneous batch size per device = 2\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 16\n",
            "  Total optimization steps = 744\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='575' max='744' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [575/744 26:58 < 07:57, 0.35 it/s, Epoch 18/24]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.281368</td>\n",
              "      <td>0.129555</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.129555</td>\n",
              "      <td>0.229391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.421737</td>\n",
              "      <td>0.190283</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.190283</td>\n",
              "      <td>0.319728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.579962</td>\n",
              "      <td>0.231781</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.231781</td>\n",
              "      <td>0.376335</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.935137</td>\n",
              "      <td>0.219636</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.219636</td>\n",
              "      <td>0.360166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.233432</td>\n",
              "      <td>0.097166</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.097166</td>\n",
              "      <td>0.177122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.978019</td>\n",
              "      <td>0.082996</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.082996</td>\n",
              "      <td>0.153271</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>175</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.787308</td>\n",
              "      <td>0.145749</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.145749</td>\n",
              "      <td>0.254417</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.469918</td>\n",
              "      <td>0.225709</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.225709</td>\n",
              "      <td>0.368291</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>225</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.671619</td>\n",
              "      <td>0.264170</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.264170</td>\n",
              "      <td>0.417934</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>No log</td>\n",
              "      <td>4.723198</td>\n",
              "      <td>0.143725</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.143725</td>\n",
              "      <td>0.251327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>275</td>\n",
              "      <td>No log</td>\n",
              "      <td>5.164569</td>\n",
              "      <td>0.149798</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.149798</td>\n",
              "      <td>0.260563</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>No log</td>\n",
              "      <td>4.525155</td>\n",
              "      <td>0.180162</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.180162</td>\n",
              "      <td>0.305317</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>325</td>\n",
              "      <td>No log</td>\n",
              "      <td>5.281843</td>\n",
              "      <td>0.146761</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.146761</td>\n",
              "      <td>0.255958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>No log</td>\n",
              "      <td>4.211777</td>\n",
              "      <td>0.237854</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.237854</td>\n",
              "      <td>0.384301</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>375</td>\n",
              "      <td>No log</td>\n",
              "      <td>5.101571</td>\n",
              "      <td>0.170040</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.170040</td>\n",
              "      <td>0.290657</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>No log</td>\n",
              "      <td>4.978660</td>\n",
              "      <td>0.162955</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.162955</td>\n",
              "      <td>0.280244</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>425</td>\n",
              "      <td>No log</td>\n",
              "      <td>5.044451</td>\n",
              "      <td>0.192308</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.192308</td>\n",
              "      <td>0.322581</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>No log</td>\n",
              "      <td>6.124807</td>\n",
              "      <td>0.113360</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.113360</td>\n",
              "      <td>0.203636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>475</td>\n",
              "      <td>No log</td>\n",
              "      <td>6.256343</td>\n",
              "      <td>0.126518</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.126518</td>\n",
              "      <td>0.224618</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.189800</td>\n",
              "      <td>4.999150</td>\n",
              "      <td>0.226721</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.226721</td>\n",
              "      <td>0.369637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>525</td>\n",
              "      <td>0.189800</td>\n",
              "      <td>5.998599</td>\n",
              "      <td>0.146761</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.146761</td>\n",
              "      <td>0.255958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.189800</td>\n",
              "      <td>6.362573</td>\n",
              "      <td>0.133603</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.133603</td>\n",
              "      <td>0.235714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>575</td>\n",
              "      <td>0.189800</td>\n",
              "      <td>5.515996</td>\n",
              "      <td>0.209514</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.209514</td>\n",
              "      <td>0.346444</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "Saving model checkpoint to output/checkpoint-500\n",
            "Configuration saved in output/checkpoint-500/config.json\n",
            "Model weights saved in output/checkpoint-500/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from output/checkpoint-500 (score: 4.999149799346924).\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='494' max='494' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [494/494 00:20]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/33593020f507d72099bd84ea6cd2296feb424fecd62d4a8edcc2a02899af6e29.38339d84e6e392addd730fd85fae32652c4cc7c5423633d6fa73e5f7937bbc38\n",
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/tokenizer_config.json from cache at None\n",
            "loading configuration file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/858852fd2471ce39075378592ddc87f5a6551e64c6825d1b92c8dab9318e0fc3.03ff9e9f998b9a9d40647a2148a202e3fb3d568dc0f170dda9dda194bab4d5dd\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"allenai/scibert_scivocab_uncased\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "loading configuration file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/858852fd2471ce39075378592ddc87f5a6551e64c6825d1b92c8dab9318e0fc3.03ff9e9f998b9a9d40647a2148a202e3fb3d568dc0f170dda9dda194bab4d5dd\n",
            "Model config BertConfig {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/de14937a851e8180a2bc5660c0041d385f8a0c62b1b2ccafa46df31043a2390c.74830bb01a0ffcdeaed8be9916312726d0c4cd364ac6fc15b375f789eaff4cbb\n",
            "Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 1002\n",
            "  Num Epochs = 27\n",
            "  Instantaneous batch size per device = 2\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 16\n",
            "  Total optimization steps = 837\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='575' max='837' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [575/837 26:58 < 12:19, 0.35 it/s, Epoch 18/27]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.271142</td>\n",
              "      <td>0.136640</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.136640</td>\n",
              "      <td>0.240427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.429243</td>\n",
              "      <td>0.154858</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.154858</td>\n",
              "      <td>0.268186</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.788036</td>\n",
              "      <td>0.169028</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.169028</td>\n",
              "      <td>0.289177</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.203613</td>\n",
              "      <td>0.126518</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.126518</td>\n",
              "      <td>0.224618</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.353783</td>\n",
              "      <td>0.094130</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.094130</td>\n",
              "      <td>0.172063</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.187804</td>\n",
              "      <td>0.127530</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.127530</td>\n",
              "      <td>0.226212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>175</td>\n",
              "      <td>No log</td>\n",
              "      <td>4.117231</td>\n",
              "      <td>0.117409</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.117409</td>\n",
              "      <td>0.210145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>No log</td>\n",
              "      <td>4.036572</td>\n",
              "      <td>0.164980</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.164980</td>\n",
              "      <td>0.283232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>225</td>\n",
              "      <td>No log</td>\n",
              "      <td>4.621170</td>\n",
              "      <td>0.133603</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.133603</td>\n",
              "      <td>0.235714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>No log</td>\n",
              "      <td>4.325041</td>\n",
              "      <td>0.155870</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.155870</td>\n",
              "      <td>0.269702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>275</td>\n",
              "      <td>No log</td>\n",
              "      <td>4.611021</td>\n",
              "      <td>0.129555</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.129555</td>\n",
              "      <td>0.229391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>No log</td>\n",
              "      <td>4.846405</td>\n",
              "      <td>0.160931</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.160931</td>\n",
              "      <td>0.277245</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>325</td>\n",
              "      <td>No log</td>\n",
              "      <td>5.286816</td>\n",
              "      <td>0.140688</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.140688</td>\n",
              "      <td>0.246673</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>No log</td>\n",
              "      <td>4.313406</td>\n",
              "      <td>0.226721</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.226721</td>\n",
              "      <td>0.369637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>375</td>\n",
              "      <td>No log</td>\n",
              "      <td>4.850642</td>\n",
              "      <td>0.178138</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.178138</td>\n",
              "      <td>0.302405</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>No log</td>\n",
              "      <td>5.997764</td>\n",
              "      <td>0.127530</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.127530</td>\n",
              "      <td>0.226212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>425</td>\n",
              "      <td>No log</td>\n",
              "      <td>5.435998</td>\n",
              "      <td>0.170040</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.170040</td>\n",
              "      <td>0.290657</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>No log</td>\n",
              "      <td>6.485664</td>\n",
              "      <td>0.124494</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.124494</td>\n",
              "      <td>0.221422</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>475</td>\n",
              "      <td>No log</td>\n",
              "      <td>6.017516</td>\n",
              "      <td>0.162955</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.162955</td>\n",
              "      <td>0.280244</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.189100</td>\n",
              "      <td>5.463313</td>\n",
              "      <td>0.209514</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.209514</td>\n",
              "      <td>0.346444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>525</td>\n",
              "      <td>0.189100</td>\n",
              "      <td>6.521316</td>\n",
              "      <td>0.133603</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.133603</td>\n",
              "      <td>0.235714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.189100</td>\n",
              "      <td>6.258458</td>\n",
              "      <td>0.156883</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.156883</td>\n",
              "      <td>0.271216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>575</td>\n",
              "      <td>0.189100</td>\n",
              "      <td>5.924686</td>\n",
              "      <td>0.182186</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.182186</td>\n",
              "      <td>0.308219</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "Saving model checkpoint to output/checkpoint-500\n",
            "Configuration saved in output/checkpoint-500/config.json\n",
            "Model weights saved in output/checkpoint-500/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from output/checkpoint-500 (score: 5.46331262588501).\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='494' max='494' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [494/494 00:20]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/33593020f507d72099bd84ea6cd2296feb424fecd62d4a8edcc2a02899af6e29.38339d84e6e392addd730fd85fae32652c4cc7c5423633d6fa73e5f7937bbc38\n",
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/tokenizer_config.json from cache at None\n",
            "loading configuration file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/858852fd2471ce39075378592ddc87f5a6551e64c6825d1b92c8dab9318e0fc3.03ff9e9f998b9a9d40647a2148a202e3fb3d568dc0f170dda9dda194bab4d5dd\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"allenai/scibert_scivocab_uncased\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "loading configuration file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/858852fd2471ce39075378592ddc87f5a6551e64c6825d1b92c8dab9318e0fc3.03ff9e9f998b9a9d40647a2148a202e3fb3d568dc0f170dda9dda194bab4d5dd\n",
            "Model config BertConfig {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/de14937a851e8180a2bc5660c0041d385f8a0c62b1b2ccafa46df31043a2390c.74830bb01a0ffcdeaed8be9916312726d0c4cd364ac6fc15b375f789eaff4cbb\n",
            "Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 1002\n",
            "  Num Epochs = 30\n",
            "  Instantaneous batch size per device = 2\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 16\n",
            "  Total optimization steps = 930\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='575' max='930' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [575/930 26:57 < 16:42, 0.35 it/s, Epoch 18/30]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.280156</td>\n",
              "      <td>0.117409</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.117409</td>\n",
              "      <td>0.210145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.641697</td>\n",
              "      <td>0.087045</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.087045</td>\n",
              "      <td>0.160149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.841269</td>\n",
              "      <td>0.178138</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.178138</td>\n",
              "      <td>0.302405</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.027132</td>\n",
              "      <td>0.200405</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.200405</td>\n",
              "      <td>0.333895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.828673</td>\n",
              "      <td>0.040486</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.040486</td>\n",
              "      <td>0.077821</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.551726</td>\n",
              "      <td>0.209514</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.209514</td>\n",
              "      <td>0.346444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>175</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.545934</td>\n",
              "      <td>0.182186</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.182186</td>\n",
              "      <td>0.308219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.933459</td>\n",
              "      <td>0.303644</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.303644</td>\n",
              "      <td>0.465839</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>225</td>\n",
              "      <td>No log</td>\n",
              "      <td>4.000411</td>\n",
              "      <td>0.195344</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.195344</td>\n",
              "      <td>0.326842</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>No log</td>\n",
              "      <td>4.191019</td>\n",
              "      <td>0.185223</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.185223</td>\n",
              "      <td>0.312553</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>275</td>\n",
              "      <td>No log</td>\n",
              "      <td>5.548480</td>\n",
              "      <td>0.132591</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.132591</td>\n",
              "      <td>0.234138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>No log</td>\n",
              "      <td>4.782294</td>\n",
              "      <td>0.207490</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.207490</td>\n",
              "      <td>0.343671</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>325</td>\n",
              "      <td>No log</td>\n",
              "      <td>5.876927</td>\n",
              "      <td>0.161943</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.161943</td>\n",
              "      <td>0.278746</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>No log</td>\n",
              "      <td>5.316200</td>\n",
              "      <td>0.197368</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.197368</td>\n",
              "      <td>0.329670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>375</td>\n",
              "      <td>No log</td>\n",
              "      <td>5.656489</td>\n",
              "      <td>0.191296</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.191296</td>\n",
              "      <td>0.321155</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>No log</td>\n",
              "      <td>6.774297</td>\n",
              "      <td>0.116397</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.116397</td>\n",
              "      <td>0.208522</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>425</td>\n",
              "      <td>No log</td>\n",
              "      <td>6.416091</td>\n",
              "      <td>0.148785</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.148785</td>\n",
              "      <td>0.259031</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>No log</td>\n",
              "      <td>6.328687</td>\n",
              "      <td>0.134615</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.134615</td>\n",
              "      <td>0.237288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>475</td>\n",
              "      <td>No log</td>\n",
              "      <td>5.955273</td>\n",
              "      <td>0.186235</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.186235</td>\n",
              "      <td>0.313993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.191500</td>\n",
              "      <td>5.696459</td>\n",
              "      <td>0.206478</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.206478</td>\n",
              "      <td>0.342282</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>525</td>\n",
              "      <td>0.191500</td>\n",
              "      <td>6.879270</td>\n",
              "      <td>0.121457</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.121457</td>\n",
              "      <td>0.216606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.191500</td>\n",
              "      <td>6.023487</td>\n",
              "      <td>0.193320</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.193320</td>\n",
              "      <td>0.324003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>575</td>\n",
              "      <td>0.191500</td>\n",
              "      <td>6.475826</td>\n",
              "      <td>0.156883</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.156883</td>\n",
              "      <td>0.271216</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "Saving model checkpoint to output/checkpoint-500\n",
            "Configuration saved in output/checkpoint-500/config.json\n",
            "Model weights saved in output/checkpoint-500/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from output/checkpoint-500 (score: 5.6964592933654785).\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='494' max='494' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [494/494 00:20]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt"
      ],
      "metadata": {
        "id": "JQ8GvWcANjJE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(range(3,31,3),sci_recall_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "s1juIVSyA22J",
        "outputId": "1f121018-81ab-4772-c9ca-01531170fb63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fc2f189eb10>]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(range(3,31,3),sci_recall_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "d8Cyuym2OaFL",
        "outputId": "8d9a39b5-6680-46c3-96b9-d84d8381bea3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fc2f085a810>]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}