{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "scibert（副本）",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "72a424f19f344ac387cd0f131a74f7f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_41dbf93bc41240fc82c72eb9d3226945",
              "IPY_MODEL_70d851bb347a4f398b5d3d0aff80c0e1",
              "IPY_MODEL_fa90e562054b46029c9145a0873d1044"
            ],
            "layout": "IPY_MODEL_3201f95041ab4fca98e58a59523363ce"
          }
        },
        "41dbf93bc41240fc82c72eb9d3226945": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5adc3f3c1cbe482082f0c4fb68ff0573",
            "placeholder": "​",
            "style": "IPY_MODEL_bd1b46128fc04a82b8fa6de5cce01cae",
            "value": "Downloading: 100%"
          }
        },
        "70d851bb347a4f398b5d3d0aff80c0e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f8f6d1e31c446acb7366cfb15214fb4",
            "max": 227845,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c773f55197444e4a841b375471800538",
            "value": 227845
          }
        },
        "fa90e562054b46029c9145a0873d1044": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3df4d77ca046409f871db6fef723b605",
            "placeholder": "​",
            "style": "IPY_MODEL_80da9225a4e74599b46283c1608a068a",
            "value": " 223k/223k [00:00&lt;00:00, 639kB/s]"
          }
        },
        "3201f95041ab4fca98e58a59523363ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5adc3f3c1cbe482082f0c4fb68ff0573": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd1b46128fc04a82b8fa6de5cce01cae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6f8f6d1e31c446acb7366cfb15214fb4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c773f55197444e4a841b375471800538": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3df4d77ca046409f871db6fef723b605": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80da9225a4e74599b46283c1608a068a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6eb6769b37a24f16bd31bc2d6fb95aaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4a765184d512433b97c9b1b8f7ecd500",
              "IPY_MODEL_55f499e696f543e1a955a83e7b4f5548",
              "IPY_MODEL_454ac0d3075641d5a68ce1703fdafe26"
            ],
            "layout": "IPY_MODEL_821238f121e24715b0cd531fc00d609d"
          }
        },
        "4a765184d512433b97c9b1b8f7ecd500": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe964b16ce704a84a844709862293b94",
            "placeholder": "​",
            "style": "IPY_MODEL_76d9510cec234c578bc13de8b1a79e2a",
            "value": "Downloading: 100%"
          }
        },
        "55f499e696f543e1a955a83e7b4f5548": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_258e3736096c48bf99e5194dc6b0fe12",
            "max": 385,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1fdd53df6eed4cd9bac44968ec43ff1c",
            "value": 385
          }
        },
        "454ac0d3075641d5a68ce1703fdafe26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5298b410e37d44a4859e150c5a9df420",
            "placeholder": "​",
            "style": "IPY_MODEL_8c4e4bf572724c40a7124b949424f41c",
            "value": " 385/385 [00:00&lt;00:00, 9.52kB/s]"
          }
        },
        "821238f121e24715b0cd531fc00d609d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe964b16ce704a84a844709862293b94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76d9510cec234c578bc13de8b1a79e2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "258e3736096c48bf99e5194dc6b0fe12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fdd53df6eed4cd9bac44968ec43ff1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5298b410e37d44a4859e150c5a9df420": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c4e4bf572724c40a7124b949424f41c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b41175a729946c99ef5b7f4756b37c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8f1fd21fbb974456a2661aa956d35e25",
              "IPY_MODEL_e42e5b3b3ec649da9eb6bcd4ba201416",
              "IPY_MODEL_f0e1d67acb9d4463a24d41922aea5179"
            ],
            "layout": "IPY_MODEL_751393aad27248b39dc01c19b0b979bd"
          }
        },
        "8f1fd21fbb974456a2661aa956d35e25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32be2537c3c34c0ebea6a2abf53b78ce",
            "placeholder": "​",
            "style": "IPY_MODEL_296fcec3a6e74755b39a250eadc61fdf",
            "value": "Downloading: 100%"
          }
        },
        "e42e5b3b3ec649da9eb6bcd4ba201416": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d92d526d0140441ab7f3c3f837dc299a",
            "max": 442221694,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f130c10de737429998e6cb5326f89068",
            "value": 442221694
          }
        },
        "f0e1d67acb9d4463a24d41922aea5179": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d118a4ae383641c3930484e8a2b9a864",
            "placeholder": "​",
            "style": "IPY_MODEL_38c50512d6f04c9696dacf9f9d303da4",
            "value": " 422M/422M [00:10&lt;00:00, 60.0MB/s]"
          }
        },
        "751393aad27248b39dc01c19b0b979bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32be2537c3c34c0ebea6a2abf53b78ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "296fcec3a6e74755b39a250eadc61fdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d92d526d0140441ab7f3c3f837dc299a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f130c10de737429998e6cb5326f89068": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d118a4ae383641c3930484e8a2b9a864": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38c50512d6f04c9696dacf9f9d303da4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Import"
      ],
      "metadata": {
        "id": "gW34gr1AC24p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eN0PVKZDLSuy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edf29694-7d6d-4df4-c4c4-4f074f73e03f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.17.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 13.7 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 50.3 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 6.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Collecting tokenizers!=0.11.3,>=0.11.1\n",
            "  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.5 MB 48.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 64.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.49 tokenizers-0.11.6 transformers-4.17.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import logging\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "transformers_logger = logging.getLogger(\"transformers\")\n",
        "transformers_logger.setLevel(logging.WARNING)"
      ],
      "metadata": {
        "id": "cdaE_5fyC6Lj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!/opt/bin/nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpBIvX3fC8Ou",
        "outputId": "ebd56952-a6d6-4b5f-cc43-fc9b4dd085bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Mar 21 07:10:38 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   47C    P8    13W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "import torch\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from transformers import EarlyStoppingCallback"
      ],
      "metadata": {
        "id": "Jhk5tAz2DO7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#read dataset"
      ],
      "metadata": {
        "id": "4EFStMG-C_VK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##988"
      ],
      "metadata": {
        "id": "Q4Y2hLB-ZKJm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4819910-6eb8-4d1b-dd68-ed5fee6e0f4d",
        "id": "wCyfEeS5Tm9J"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               selftext  Expert-label\n",
              "0     I posted this on Piazza but thought I might as...             1\n",
              "1     Hi i’ve applied for arts from Vancouver,BC as ...             0\n",
              "2     i'm an international student and i've been tak...             1\n",
              "3     i'm an international student and the midterm w...             1\n",
              "4     they think i wouldnt be able to handle the str...             0\n",
              "...                                                 ...           ...\n",
              "997   My boyfriend is Canadian and I’m American. Obv...             0\n",
              "998   Do you need to be vaccinated to travel domesti...             0\n",
              "999   Hello, are there any International students he...             1\n",
              "1000  Will you guys take a leave of absence? Or are ...             0\n",
              "1001  I posted this on Piazza but thought I might as...             1\n",
              "\n",
              "[1002 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c4be25e7-0f02-4b42-b842-c8a862d406f2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>selftext</th>\n",
              "      <th>Expert-label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I posted this on Piazza but thought I might as...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hi i’ve applied for arts from Vancouver,BC as ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i'm an international student and i've been tak...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i'm an international student and the midterm w...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>they think i wouldnt be able to handle the str...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>My boyfriend is Canadian and I’m American. Obv...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>Do you need to be vaccinated to travel domesti...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>Hello, are there any International students he...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1000</th>\n",
              "      <td>Will you guys take a leave of absence? Or are ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1001</th>\n",
              "      <td>I posted this on Piazza but thought I might as...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1002 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c4be25e7-0f02-4b42-b842-c8a862d406f2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c4be25e7-0f02-4b42-b842-c8a862d406f2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c4be25e7-0f02-4b42-b842-c8a862d406f2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "\n",
        "\n",
        "train_df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/project/4192/Data/DirectCompare/train_df.csv\")\n",
        "\n",
        "train_df = train_df[['selftext','Expert-label']]\n",
        "train_df[['Expert-label']] = train_df[['Expert-label']].astype(int)\n",
        "train_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a24286f-d3dd-4718-dbc7-c13a71baf8a8",
        "id": "hb31QcnjTm9J"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              selftext  label\n",
              "0    Well... I think I need some help... about depr...      1\n",
              "1    I am an international student and i started en...      1\n",
              "2    i'm an international student and the midterm w...      1\n",
              "3    Honestly just want to end it all , it’s so har...      1\n",
              "4    Hi all, \\n\\nI'm really upset to know the Winte...      1\n",
              "..                                                 ...    ...\n",
              "983  WE NEED A SCIENCE AND DATA BASED APPROACH TO C...      1\n",
              "984  Hi everyone! Hope that all who are applying ar...      1\n",
              "985  Hello everyone !\\n\\nI request some advice from...      1\n",
              "986  Hi, I was wondering what my chances were at th...      1\n",
              "987  \\nPlease help me [support this petition ](http...      1\n",
              "\n",
              "[988 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ecfe7ac3-7eb1-4139-9558-88287fb72bd7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>selftext</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Well... I think I need some help... about depr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I am an international student and i started en...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i'm an international student and the midterm w...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Honestly just want to end it all , it’s so har...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Hi all, \\n\\nI'm really upset to know the Winte...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>983</th>\n",
              "      <td>WE NEED A SCIENCE AND DATA BASED APPROACH TO C...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>984</th>\n",
              "      <td>Hi everyone! Hope that all who are applying ar...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>985</th>\n",
              "      <td>Hello everyone !\\n\\nI request some advice from...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>986</th>\n",
              "      <td>Hi, I was wondering what my chances were at th...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>987</th>\n",
              "      <td>\\nPlease help me [support this petition ](http...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>988 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ecfe7ac3-7eb1-4139-9558-88287fb72bd7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ecfe7ac3-7eb1-4139-9558-88287fb72bd7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ecfe7ac3-7eb1-4139-9558-88287fb72bd7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "test_df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/project/4192/Data/Validation988/988validation.csv\")\n",
        "\n",
        "test_df = test_df[['selftext']]\n",
        "test_df.insert(test_df.shape[1], 'label', 1)\n",
        "test_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kTGVITRkTm9K"
      },
      "outputs": [],
      "source": [
        "test_data = test_df['selftext'].values.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_list=[]\n",
        "train_20 = train_df.iloc[:200]\n",
        "train_40 = train_df.iloc[:400]\n",
        "train_60 = train_df.iloc[:600]\n",
        "train_80 = train_df.iloc[:800]\n",
        "\n",
        "\n",
        "train_list.append(train_20)\n",
        "train_list.append(train_40)\n",
        "train_list.append(train_60)\n",
        "train_list.append(train_80)\n",
        "train_list.append(train_df)"
      ],
      "metadata": {
        "id": "hsjVO6BPXT5J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##tss"
      ],
      "metadata": {
        "id": "4KEJ74cNZIaj"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkEzM6iEZHkj"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_df_tss = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/project/4192/Data/DirectCompare/train_df.csv\")\n",
        "\n",
        "train_df_tss = train_df_tss[['selftext','Expert-label']]\n",
        "train_df_tss[['Expert-label']] = train_df_tss[['Expert-label']].astype(int)\n",
        "\n",
        "X = train_df_tss[\"selftext\"].values.tolist()\n",
        "y = train_df_tss[\"Expert-label\"].values.tolist()\n",
        "\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2,random_state=0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_list_tss=[]\n",
        "\n",
        "train_20_tss = X_train[:200]\n",
        "train_40_tss = X_train[:400]\n",
        "train_60_tss = X_train[:600]\n",
        "\n",
        "\n",
        "train_list_tss.append(train_20_tss)\n",
        "train_list_tss.append(train_40_tss)\n",
        "train_list_tss.append(train_60_tss)\n",
        "train_list_tss.append(X_train)\n",
        "\n",
        "train_label_tss=[]\n",
        "\n",
        "label_20_tss = y_train[:200]\n",
        "label_40_tss = y_train[:400]\n",
        "label_60_tss = y_train[:600]\n",
        "\n",
        "\n",
        "train_label_tss.append(label_20_tss)\n",
        "train_label_tss.append(label_40_tss)\n",
        "train_label_tss.append(label_60_tss)\n",
        "train_label_tss.append(y_train)"
      ],
      "metadata": {
        "id": "y04TaVJrajxU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##torch dataset"
      ],
      "metadata": {
        "id": "WzMZb4CvEkO3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels=None):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        if self.labels:\n",
        "            item[\"labels\"] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings[\"input_ids\"])\n",
        "\n"
      ],
      "metadata": {
        "id": "zB7XnQRPDrUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Metrics"
      ],
      "metadata": {
        "id": "gQfBpCsPDvkt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(p):\n",
        "    pred, labels = p\n",
        "    pred = np.argmax(pred, axis=1)\n",
        "\n",
        "    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n",
        "    recall = recall_score(y_true=labels, y_pred=pred)\n",
        "    precision = precision_score(y_true=labels, y_pred=pred)\n",
        "    f1 = f1_score(y_true=labels, y_pred=pred)\n",
        "\n",
        "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}"
      ],
      "metadata": {
        "id": "0ptdaWxZDxy7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#SciBERT"
      ],
      "metadata": {
        "id": "o3WR8yFJDR6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##988"
      ],
      "metadata": {
        "id": "luepqYESn1vw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"allenai/scibert_scivocab_uncased\"\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "model = BertForSequenceClassification.from_pretrained(model_name,num_labels =2 )\n",
        "\n",
        "recall_list=[]\n",
        "\n",
        "X_val = test_df[\"selftext\"].values.tolist()\n",
        "y_val = test_df[\"label\"].values.tolist()\n",
        "X_val_tokenized = tokenizer(X_val, padding=True, truncation=True, max_length=512)\n",
        "val_dataset = Dataset(X_val_tokenized, y_val)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ni8ClhImvaOH",
        "outputId": "bc5541d1-be76-404e-bdc9-c472d11e743f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/33593020f507d72099bd84ea6cd2296feb424fecd62d4a8edcc2a02899af6e29.38339d84e6e392addd730fd85fae32652c4cc7c5423633d6fa73e5f7937bbc38\n",
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/tokenizer_config.json from cache at None\n",
            "loading configuration file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/858852fd2471ce39075378592ddc87f5a6551e64c6825d1b92c8dab9318e0fc3.03ff9e9f998b9a9d40647a2148a202e3fb3d568dc0f170dda9dda194bab4d5dd\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"allenai/scibert_scivocab_uncased\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "loading configuration file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/858852fd2471ce39075378592ddc87f5a6551e64c6825d1b92c8dab9318e0fc3.03ff9e9f998b9a9d40647a2148a202e3fb3d568dc0f170dda9dda194bab4d5dd\n",
            "Model config BertConfig {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/de14937a851e8180a2bc5660c0041d385f8a0c62b1b2ccafa46df31043a2390c.74830bb01a0ffcdeaed8be9916312726d0c4cd364ac6fc15b375f789eaff4cbb\n",
            "Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in train_list:\n",
        "\n",
        "  tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "  model = BertForSequenceClassification.from_pretrained(model_name,num_labels =2 )\n",
        "\n",
        "\n",
        "  X_train = i[\"selftext\"].values.tolist()\n",
        "  y_train = i[\"Expert-label\"].values.tolist()\n",
        "  X_train_tokenized = tokenizer(X_train, padding=True, truncation=True, max_length=512)\n",
        "  train_dataset = Dataset(X_train_tokenized, y_train)\n",
        "\n",
        "  args = TrainingArguments(\n",
        "    output_dir=\"output\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    per_device_train_batch_size=2,\n",
        "    per_device_eval_batch_size=2,\n",
        "    num_train_epochs=3,\n",
        "    seed=0,\n",
        "    overwrite_output_dir=True,\n",
        "    learning_rate=3e-5,\n",
        "    gradient_accumulation_steps=16\n",
        "\n",
        "    \n",
        "  )\n",
        "\n",
        "  trainer_sci = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "  \n",
        "  \n",
        "  )\n",
        "\n",
        "  trainer_sci.train()\n",
        "  res = trainer_sci.evaluate()\n",
        "  recall_list.append(res['eval_recall'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FOA-2z99vF4q",
        "outputId": "a5608fd5-2c34-4660-8be1-d1955546e890"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/33593020f507d72099bd84ea6cd2296feb424fecd62d4a8edcc2a02899af6e29.38339d84e6e392addd730fd85fae32652c4cc7c5423633d6fa73e5f7937bbc38\n",
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/tokenizer_config.json from cache at None\n",
            "loading configuration file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/858852fd2471ce39075378592ddc87f5a6551e64c6825d1b92c8dab9318e0fc3.03ff9e9f998b9a9d40647a2148a202e3fb3d568dc0f170dda9dda194bab4d5dd\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"allenai/scibert_scivocab_uncased\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "loading configuration file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/858852fd2471ce39075378592ddc87f5a6551e64c6825d1b92c8dab9318e0fc3.03ff9e9f998b9a9d40647a2148a202e3fb3d568dc0f170dda9dda194bab4d5dd\n",
            "Model config BertConfig {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/de14937a851e8180a2bc5660c0041d385f8a0c62b1b2ccafa46df31043a2390c.74830bb01a0ffcdeaed8be9916312726d0c4cd364ac6fc15b375f789eaff4cbb\n",
            "Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 200\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 2\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 16\n",
            "  Total optimization steps = 18\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [18/18 01:38, Epoch 2/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.777393</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.843297</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.845726</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='494' max='494' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [494/494 00:21]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/33593020f507d72099bd84ea6cd2296feb424fecd62d4a8edcc2a02899af6e29.38339d84e6e392addd730fd85fae32652c4cc7c5423633d6fa73e5f7937bbc38\n",
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/tokenizer_config.json from cache at None\n",
            "loading configuration file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/858852fd2471ce39075378592ddc87f5a6551e64c6825d1b92c8dab9318e0fc3.03ff9e9f998b9a9d40647a2148a202e3fb3d568dc0f170dda9dda194bab4d5dd\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"allenai/scibert_scivocab_uncased\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "loading configuration file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/858852fd2471ce39075378592ddc87f5a6551e64c6825d1b92c8dab9318e0fc3.03ff9e9f998b9a9d40647a2148a202e3fb3d568dc0f170dda9dda194bab4d5dd\n",
            "Model config BertConfig {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/de14937a851e8180a2bc5660c0041d385f8a0c62b1b2ccafa46df31043a2390c.74830bb01a0ffcdeaed8be9916312726d0c4cd364ac6fc15b375f789eaff4cbb\n",
            "Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 400\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 2\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 16\n",
            "  Total optimization steps = 36\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [36/36 02:15, Epoch 2/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.380034</td>\n",
              "      <td>0.096154</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.096154</td>\n",
              "      <td>0.175439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.563380</td>\n",
              "      <td>0.091093</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.091093</td>\n",
              "      <td>0.166976</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.403170</td>\n",
              "      <td>0.140688</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.140688</td>\n",
              "      <td>0.246673</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='494' max='494' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [494/494 00:21]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/33593020f507d72099bd84ea6cd2296feb424fecd62d4a8edcc2a02899af6e29.38339d84e6e392addd730fd85fae32652c4cc7c5423633d6fa73e5f7937bbc38\n",
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/tokenizer_config.json from cache at None\n",
            "loading configuration file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/858852fd2471ce39075378592ddc87f5a6551e64c6825d1b92c8dab9318e0fc3.03ff9e9f998b9a9d40647a2148a202e3fb3d568dc0f170dda9dda194bab4d5dd\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"allenai/scibert_scivocab_uncased\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "loading configuration file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/858852fd2471ce39075378592ddc87f5a6551e64c6825d1b92c8dab9318e0fc3.03ff9e9f998b9a9d40647a2148a202e3fb3d568dc0f170dda9dda194bab4d5dd\n",
            "Model config BertConfig {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/de14937a851e8180a2bc5660c0041d385f8a0c62b1b2ccafa46df31043a2390c.74830bb01a0ffcdeaed8be9916312726d0c4cd364ac6fc15b375f789eaff4cbb\n",
            "Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 600\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 2\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 16\n",
            "  Total optimization steps = 54\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [54/54 02:51, Epoch 2/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.930266</td>\n",
              "      <td>0.315789</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.315789</td>\n",
              "      <td>0.480000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.231984</td>\n",
              "      <td>0.146761</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.146761</td>\n",
              "      <td>0.255958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.503397</td>\n",
              "      <td>0.090081</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.090081</td>\n",
              "      <td>0.165274</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='494' max='494' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [494/494 00:21]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/33593020f507d72099bd84ea6cd2296feb424fecd62d4a8edcc2a02899af6e29.38339d84e6e392addd730fd85fae32652c4cc7c5423633d6fa73e5f7937bbc38\n",
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/tokenizer_config.json from cache at None\n",
            "loading configuration file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/858852fd2471ce39075378592ddc87f5a6551e64c6825d1b92c8dab9318e0fc3.03ff9e9f998b9a9d40647a2148a202e3fb3d568dc0f170dda9dda194bab4d5dd\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"allenai/scibert_scivocab_uncased\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "loading configuration file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/858852fd2471ce39075378592ddc87f5a6551e64c6825d1b92c8dab9318e0fc3.03ff9e9f998b9a9d40647a2148a202e3fb3d568dc0f170dda9dda194bab4d5dd\n",
            "Model config BertConfig {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/de14937a851e8180a2bc5660c0041d385f8a0c62b1b2ccafa46df31043a2390c.74830bb01a0ffcdeaed8be9916312726d0c4cd364ac6fc15b375f789eaff4cbb\n",
            "Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 800\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 2\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 16\n",
            "  Total optimization steps = 75\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='75' max='75' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [75/75 03:30, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.198618</td>\n",
              "      <td>0.178138</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.178138</td>\n",
              "      <td>0.302405</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.425952</td>\n",
              "      <td>0.183198</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.183198</td>\n",
              "      <td>0.309666</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.755382</td>\n",
              "      <td>0.160931</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.160931</td>\n",
              "      <td>0.277245</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='494' max='494' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [494/494 00:21]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/33593020f507d72099bd84ea6cd2296feb424fecd62d4a8edcc2a02899af6e29.38339d84e6e392addd730fd85fae32652c4cc7c5423633d6fa73e5f7937bbc38\n",
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/tokenizer_config.json from cache at None\n",
            "loading configuration file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/858852fd2471ce39075378592ddc87f5a6551e64c6825d1b92c8dab9318e0fc3.03ff9e9f998b9a9d40647a2148a202e3fb3d568dc0f170dda9dda194bab4d5dd\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"allenai/scibert_scivocab_uncased\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "loading configuration file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/858852fd2471ce39075378592ddc87f5a6551e64c6825d1b92c8dab9318e0fc3.03ff9e9f998b9a9d40647a2148a202e3fb3d568dc0f170dda9dda194bab4d5dd\n",
            "Model config BertConfig {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/de14937a851e8180a2bc5660c0041d385f8a0c62b1b2ccafa46df31043a2390c.74830bb01a0ffcdeaed8be9916312726d0c4cd364ac6fc15b375f789eaff4cbb\n",
            "Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 1002\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 2\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 16\n",
            "  Total optimization steps = 93\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='93' max='93' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [93/93 04:07, Epoch 2/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.885952</td>\n",
              "      <td>0.288462</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.288462</td>\n",
              "      <td>0.447761</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.320527</td>\n",
              "      <td>0.096154</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.096154</td>\n",
              "      <td>0.175439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.472891</td>\n",
              "      <td>0.181174</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.181174</td>\n",
              "      <td>0.306769</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 988\n",
            "  Batch size = 2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='494' max='494' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [494/494 00:21]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##tss"
      ],
      "metadata": {
        "id": "_XLt-CBHwzzV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"allenai/scibert_scivocab_uncased\"\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "model = BertForSequenceClassification.from_pretrained(model_name,num_labels =2 )\n",
        "\n",
        "recall_list_tss=[]\n",
        "acc_list_tss=[]\n",
        "pre_list_tss=[]\n",
        "\n",
        "\n",
        "X_val_tokenized = tokenizer(X_val, padding=True, truncation=True, max_length=512)\n",
        "val_dataset = Dataset(X_val_tokenized, y_val)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "72a424f19f344ac387cd0f131a74f7f0",
            "41dbf93bc41240fc82c72eb9d3226945",
            "70d851bb347a4f398b5d3d0aff80c0e1",
            "fa90e562054b46029c9145a0873d1044",
            "3201f95041ab4fca98e58a59523363ce",
            "5adc3f3c1cbe482082f0c4fb68ff0573",
            "bd1b46128fc04a82b8fa6de5cce01cae",
            "6f8f6d1e31c446acb7366cfb15214fb4",
            "c773f55197444e4a841b375471800538",
            "3df4d77ca046409f871db6fef723b605",
            "80da9225a4e74599b46283c1608a068a",
            "6eb6769b37a24f16bd31bc2d6fb95aaf",
            "4a765184d512433b97c9b1b8f7ecd500",
            "55f499e696f543e1a955a83e7b4f5548",
            "454ac0d3075641d5a68ce1703fdafe26",
            "821238f121e24715b0cd531fc00d609d",
            "fe964b16ce704a84a844709862293b94",
            "76d9510cec234c578bc13de8b1a79e2a",
            "258e3736096c48bf99e5194dc6b0fe12",
            "1fdd53df6eed4cd9bac44968ec43ff1c",
            "5298b410e37d44a4859e150c5a9df420",
            "8c4e4bf572724c40a7124b949424f41c",
            "5b41175a729946c99ef5b7f4756b37c8",
            "8f1fd21fbb974456a2661aa956d35e25",
            "e42e5b3b3ec649da9eb6bcd4ba201416",
            "f0e1d67acb9d4463a24d41922aea5179",
            "751393aad27248b39dc01c19b0b979bd",
            "32be2537c3c34c0ebea6a2abf53b78ce",
            "296fcec3a6e74755b39a250eadc61fdf",
            "d92d526d0140441ab7f3c3f837dc299a",
            "f130c10de737429998e6cb5326f89068",
            "d118a4ae383641c3930484e8a2b9a864",
            "38c50512d6f04c9696dacf9f9d303da4"
          ]
        },
        "id": "1n5w5G7ew16p",
        "outputId": "fa7ce4de-7362-479b-cc53-1d31d349526e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/223k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "72a424f19f344ac387cd0f131a74f7f0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/385 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6eb6769b37a24f16bd31bc2d6fb95aaf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/422M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5b41175a729946c99ef5b7f4756b37c8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(train_list_tss)):\n",
        "\n",
        "  tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "  model = BertForSequenceClassification.from_pretrained(model_name,num_labels =2 )\n",
        "\n",
        "\n",
        "  X_train = train_list_tss[i]\n",
        "  y_train = train_label_tss[i]\n",
        "  X_train_tokenized = tokenizer(X_train, padding=True, truncation=True, max_length=512)\n",
        "  train_dataset = Dataset(X_train_tokenized, y_train)\n",
        "\n",
        "  args = TrainingArguments(\n",
        "    output_dir=\"output\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    per_device_train_batch_size=2,\n",
        "    per_device_eval_batch_size=2,\n",
        "    num_train_epochs=3,\n",
        "    seed=0,\n",
        "    overwrite_output_dir=True,\n",
        "    learning_rate=3e-5,\n",
        "    gradient_accumulation_steps=16\n",
        "\n",
        "    \n",
        "  )\n",
        "\n",
        "  trainer_sci = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "  \n",
        "  \n",
        "  )\n",
        "\n",
        "  trainer_sci.train()\n",
        "  res = trainer_sci.evaluate()\n",
        "  recall_list_tss.append(res['eval_recall'])\n",
        "  acc_list_tss.append(res['eval_accuracy'])\n",
        "  pre_list_tss.append(res['eval_precision'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zViKLjMzz410",
        "outputId": "230a7c33-5921-4b10-ff02-22fba84c1ea8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 200\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 2\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 16\n",
            "  Total optimization steps = 18\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [18/18 01:16, Epoch 2/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.662617</td>\n",
              "      <td>0.577114</td>\n",
              "      <td>0.559524</td>\n",
              "      <td>0.494737</td>\n",
              "      <td>0.525140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.679320</td>\n",
              "      <td>0.582090</td>\n",
              "      <td>0.547009</td>\n",
              "      <td>0.673684</td>\n",
              "      <td>0.603774</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.689461</td>\n",
              "      <td>0.567164</td>\n",
              "      <td>0.533898</td>\n",
              "      <td>0.663158</td>\n",
              "      <td>0.591549</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='101' max='101' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [101/101 00:07]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/33593020f507d72099bd84ea6cd2296feb424fecd62d4a8edcc2a02899af6e29.38339d84e6e392addd730fd85fae32652c4cc7c5423633d6fa73e5f7937bbc38\n",
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/tokenizer_config.json from cache at None\n",
            "loading configuration file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/858852fd2471ce39075378592ddc87f5a6551e64c6825d1b92c8dab9318e0fc3.03ff9e9f998b9a9d40647a2148a202e3fb3d568dc0f170dda9dda194bab4d5dd\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"allenai/scibert_scivocab_uncased\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "loading configuration file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/858852fd2471ce39075378592ddc87f5a6551e64c6825d1b92c8dab9318e0fc3.03ff9e9f998b9a9d40647a2148a202e3fb3d568dc0f170dda9dda194bab4d5dd\n",
            "Model config BertConfig {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/de14937a851e8180a2bc5660c0041d385f8a0c62b1b2ccafa46df31043a2390c.74830bb01a0ffcdeaed8be9916312726d0c4cd364ac6fc15b375f789eaff4cbb\n",
            "Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 400\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 2\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 16\n",
            "  Total optimization steps = 36\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [36/36 02:22, Epoch 2/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.667405</td>\n",
              "      <td>0.537313</td>\n",
              "      <td>0.506757</td>\n",
              "      <td>0.789474</td>\n",
              "      <td>0.617284</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.674292</td>\n",
              "      <td>0.557214</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.063158</td>\n",
              "      <td>0.118812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.657699</td>\n",
              "      <td>0.567164</td>\n",
              "      <td>0.540000</td>\n",
              "      <td>0.568421</td>\n",
              "      <td>0.553846</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='101' max='101' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [101/101 00:07]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/33593020f507d72099bd84ea6cd2296feb424fecd62d4a8edcc2a02899af6e29.38339d84e6e392addd730fd85fae32652c4cc7c5423633d6fa73e5f7937bbc38\n",
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/tokenizer_config.json from cache at None\n",
            "loading configuration file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/858852fd2471ce39075378592ddc87f5a6551e64c6825d1b92c8dab9318e0fc3.03ff9e9f998b9a9d40647a2148a202e3fb3d568dc0f170dda9dda194bab4d5dd\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"allenai/scibert_scivocab_uncased\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "loading configuration file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/858852fd2471ce39075378592ddc87f5a6551e64c6825d1b92c8dab9318e0fc3.03ff9e9f998b9a9d40647a2148a202e3fb3d568dc0f170dda9dda194bab4d5dd\n",
            "Model config BertConfig {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/de14937a851e8180a2bc5660c0041d385f8a0c62b1b2ccafa46df31043a2390c.74830bb01a0ffcdeaed8be9916312726d0c4cd364ac6fc15b375f789eaff4cbb\n",
            "Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 600\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 2\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 16\n",
            "  Total optimization steps = 54\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [54/54 03:23, Epoch 2/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.672764</td>\n",
              "      <td>0.527363</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.473684</td>\n",
              "      <td>0.486486</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.661286</td>\n",
              "      <td>0.562189</td>\n",
              "      <td>0.539326</td>\n",
              "      <td>0.505263</td>\n",
              "      <td>0.521739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.646449</td>\n",
              "      <td>0.592040</td>\n",
              "      <td>0.559633</td>\n",
              "      <td>0.642105</td>\n",
              "      <td>0.598039</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='101' max='101' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [101/101 00:07]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/33593020f507d72099bd84ea6cd2296feb424fecd62d4a8edcc2a02899af6e29.38339d84e6e392addd730fd85fae32652c4cc7c5423633d6fa73e5f7937bbc38\n",
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/tokenizer_config.json from cache at None\n",
            "loading configuration file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/858852fd2471ce39075378592ddc87f5a6551e64c6825d1b92c8dab9318e0fc3.03ff9e9f998b9a9d40647a2148a202e3fb3d568dc0f170dda9dda194bab4d5dd\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"allenai/scibert_scivocab_uncased\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "loading configuration file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/858852fd2471ce39075378592ddc87f5a6551e64c6825d1b92c8dab9318e0fc3.03ff9e9f998b9a9d40647a2148a202e3fb3d568dc0f170dda9dda194bab4d5dd\n",
            "Model config BertConfig {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/de14937a851e8180a2bc5660c0041d385f8a0c62b1b2ccafa46df31043a2390c.74830bb01a0ffcdeaed8be9916312726d0c4cd364ac6fc15b375f789eaff4cbb\n",
            "Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 801\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 2\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 16\n",
            "  Total optimization steps = 75\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='75' max='75' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [75/75 04:27, Epoch 2/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.672256</td>\n",
              "      <td>0.567164</td>\n",
              "      <td>0.526667</td>\n",
              "      <td>0.831579</td>\n",
              "      <td>0.644898</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.656920</td>\n",
              "      <td>0.611940</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.715789</td>\n",
              "      <td>0.635514</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.648091</td>\n",
              "      <td>0.641791</td>\n",
              "      <td>0.590551</td>\n",
              "      <td>0.789474</td>\n",
              "      <td>0.675676</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 201\n",
            "  Batch size = 2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='101' max='101' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [101/101 00:07]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Result"
      ],
      "metadata": {
        "id": "RKBvp5YGwa9k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##988"
      ],
      "metadata": {
        "id": "plA6AqNEwc3I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "recall_list"
      ],
      "metadata": {
        "id": "koxsySqxZ3fS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3b10ab1-c645-4b74-e8e9-152e338ea28a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0,\n",
              " 0.14068825910931174,\n",
              " 0.09008097165991903,\n",
              " 0.16093117408906882,\n",
              " 0.1811740890688259]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(range(2,11,2),recall_list)"
      ],
      "metadata": {
        "id": "S9oqnOjNbvZo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "b6ecc7b0-9ce8-4f92-c639-bc2a6cf78ccc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f63c923e9d0>]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#p_1 = (recall_list[1]-recall_list[0])/recall_list[0]\n",
        "p_2 = (recall_list[2]-recall_list[1])/recall_list[1]\n",
        "p_3 = (recall_list[3]-recall_list[2])/recall_list[2]\n",
        "p_4 = (recall_list[4]-recall_list[3])/recall_list[3]\n",
        "p_5 = (recall_list[4]-recall_list[1])/recall_list[1]\n",
        "#print('First progress: ' +str(p_1))\n",
        "print('Second progress: ' +str(p_2))\n",
        "print('Third progress: ' +str(p_3))\n",
        "print('Fourth progress: ' +str(p_4))\n",
        "print('Final progress: ' +str(p_5))"
      ],
      "metadata": {
        "id": "q5SHwNzDcjUq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fb44f68-78e0-4422-f656-7870d58d640d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Second progress: -0.35971223021582727\n",
            "Third progress: 0.7865168539325841\n",
            "Fourth progress: 0.12578616352201255\n",
            "Final progress: 0.28776978417266186\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##tss"
      ],
      "metadata": {
        "id": "l8cbsOv5wrFa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "recall_list_tss,acc_list_tss,pre_list_tss"
      ],
      "metadata": {
        "id": "-JlXvCzNZ7mO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb3f8da6-5c09-453e-8f09-7c3121e58380"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([0.6631578947368421,\n",
              "  0.5684210526315789,\n",
              "  0.6421052631578947,\n",
              "  0.7894736842105263],\n",
              " [0.5671641791044776,\n",
              "  0.5671641791044776,\n",
              "  0.5920398009950248,\n",
              "  0.6417910447761194],\n",
              " [0.5338983050847458, 0.54, 0.5596330275229358, 0.5905511811023622])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(range(2,9,2),recall_list_tss)\n",
        "plt.plot(range(2,9,2),acc_list_tss)\n",
        "plt.plot(range(2,9,2),pre_list_tss)"
      ],
      "metadata": {
        "id": "GJ0_7J02cTQT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "49fc982d-55b5-400c-93d6-7c4be5e9d765"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f4ec127b190>]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p_1_t = (recall_list_tss[1]-recall_list_tss[0])/recall_list_tss[0]\n",
        "p_2_t = (recall_list_tss[2]-recall_list_tss[1])/recall_list_tss[1]\n",
        "p_3_t = (recall_list_tss[3]-recall_list_tss[2])/recall_list_tss[2]\n",
        "p_4_t = (recall_list_tss[3]-recall_list_tss[0])/recall_list_tss[0]\n",
        "\n",
        "print('First progress: ' +str(p_1_t))\n",
        "print('Second progress: ' +str(p_2_t))\n",
        "print('Third progress: ' +str(p_3_t))\n",
        "print('Final progress: ' +str(p_4_t))"
      ],
      "metadata": {
        "id": "NA4nfiwgdRFz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c396f86e-498f-496d-c512-ae0476b1ad55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First progress: -0.14285714285714282\n",
            "Second progress: 0.12962962962962965\n",
            "Third progress: 0.2295081967213115\n",
            "Final progress: 0.19047619047619058\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p_1_t = (acc_list_tss[1]-acc_list_tss[0])/acc_list_tss[0]\n",
        "p_2_t = (acc_list_tss[2]-acc_list_tss[1])/acc_list_tss[1]\n",
        "p_3_t = (acc_list_tss[3]-acc_list_tss[2])/acc_list_tss[2]\n",
        "p_4_t = (acc_list_tss[3]-acc_list_tss[0])/acc_list_tss[0]\n",
        "\n",
        "print('First progress: ' +str(p_1_t))\n",
        "print('Second progress: ' +str(p_2_t))\n",
        "print('Third progress: ' +str(p_3_t))\n",
        "print('Final progress: ' +str(p_4_t))"
      ],
      "metadata": {
        "id": "nJC5KVoPdnVe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f4894a7-8ca7-40ef-d16f-362ce1dffe60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First progress: 0.0\n",
            "Second progress: 0.043859649122807015\n",
            "Third progress: 0.08403361344537814\n",
            "Final progress: 0.13157894736842105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p_1_t = (pre_list_tss[1]-pre_list_tss[0])/pre_list_tss[0]\n",
        "p_2_t = (pre_list_tss[2]-pre_list_tss[1])/pre_list_tss[1]\n",
        "p_3_t = (pre_list_tss[3]-pre_list_tss[2])/pre_list_tss[2]\n",
        "p_4_t = (pre_list_tss[3]-pre_list_tss[0])/pre_list_tss[0]\n",
        "\n",
        "print('First progress: ' +str(p_1_t))\n",
        "print('Second progress: ' +str(p_2_t))\n",
        "print('Third progress: ' +str(p_3_t))\n",
        "print('Final progress: ' +str(p_4_t))"
      ],
      "metadata": {
        "id": "RDycHBradnlA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e2020c1-88d8-41f7-9873-9c43e013b36b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First progress: 0.011428571428571456\n",
            "Second progress: 0.03635745837580689\n",
            "Third progress: 0.055247192461597996\n",
            "Final progress: 0.10611173603299574\n"
          ]
        }
      ]
    }
  ]
}